{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEI Conference 2012 #\n",
    "\n",
    "Le programme actuel a pour but de récupérer les abstracts de chaque conférence de la TEI Conference 2012, de les normaliser puis de les analyser via des méthodes de machine learning.\n",
    "\n",
    "## Etape 1 : le téléchargement. ##\n",
    "\n",
    "L'étape actuelle consiste à télécharger depuis le site web les données des abstracts puis de créer :\n",
    "- Un fichier csv listant le titre, les auteurs, l'université d'origine et le nom de l'abstract dans le cache\n",
    "- Un cache dans lequel les textes sont stockés en format texte brut.\n",
    "\n",
    "Nous n'avons pas besoin d'une phase de normalisation (Etape 2 dans les autres années) car nous n'avons pas de format XML utilisé. La page HTML est directement parsée et le texte brut en est extrait sans étapes intermédiaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Les packages ###\n",
    "\n",
    "Il faut installer les packages ci-dessous en ne le lançant qu'une fois. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "#Créer un certificat SSL pour sécuriser l'accès au site internet.\n",
    "import ssl \n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Téléchargement et stockage ###\n",
    "\n",
    "En lançant la case ci-dessous, vous téléchargez le contenu dans la page web, puis :\n",
    "- Le contenu est trié et un document csv est créé, contenant le titre de tous les abstracts, le nom des auteurs, l'université de rattachement si elle existe et le nom de l'abstract dans le cache.\n",
    "- Tous les abstracts sont stockés dans un cache au format .txt\n",
    "\n",
    "Le titre des abstracts dans le cache a ce format : paper-2012-1, où seul le dernier chiffre change entre les abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 560.74it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 4506.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecriture du csv terminée\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "entiers = ['1', '2', '3', '4', '5', '6', '7', '8', '9']#liste permettant d'écarter plus tard dans le texte les chiffres gênants et inutiles\n",
    "\n",
    "content = urlopen('https://tei-c.org/Vault/MembersMeetings/2012/teiconference/program/papers/#mads')\n",
    "HTML = content.read()\n",
    "# La suite de code en .replace consiste à corriger manuellement des erreurs et des irrégularités dans le code HTML\n",
    "# Je prends le HTML, le transforme de bytes en str, et j'y amène des corrections. Autrement, c'est impossible à traiter logiquement\n",
    "HTML = HTML.decode('UTF-8')\n",
    "HTML = HTML.replace('<p><a name=\"grad\"></a><br />', '')\n",
    "HTML = HTML.replace('<strong>Conversation, Translation', '<p><a name=\"grad\"></a><strong>Conversation, Translation')\n",
    "HTML = HTML.replace('<p><a name=\"encfin\"></a></p>', '')\n",
    "HTML = HTML.replace('<p><strong>Encoding Financial', '<p><a name=\"encfin\"></a><strong>Encoding Financial')\n",
    "HTML = HTML.replace('<p><a name=\"xpoint\"></a><strong>Rebooting TEI XPointers</strong><br />', '<p><a name=\"xpoint\"></a><strong>Rebooting TEI XPointers</strong><br /></p>')\n",
    "HTML = HTML.replace('<strong><span style=\"text-decoration: underline\">Hugh Cayless', '<p><strong><span style=\"text-decoration: underline\">Hugh Cayless')\n",
    "HTML = HTML.replace('<strong><a name=\"ets\"></a>', '<a name=\"ets\"></a><strong>')\n",
    "HTML = HTML.replace('<strong><a name=\"librarysupport\"></a>', '<a name=\"librarysupport\"></a><strong>')\n",
    "HTML = HTML.replace('<p><a name=\"mads\">', '<hr/><p><a name=\"mads\">')\n",
    "\n",
    "#Je crée mon cache et un de ses sous-dossiers\n",
    "if not os.path.exists(\"./cache2012\"):\n",
    "    os.makedirs(\"./cache2012\")\n",
    "if not os.path.exists(\"./cache2012/cacheTXT\"):\n",
    "    os.makedirs(\"./cache2012/cacheTXT\")\n",
    "Path = './cache2012/cacheTXT/'\n",
    "\n",
    "\n",
    "masterList = []\n",
    "\n",
    "#Je vais trier l'information, en obtenant des strings. J'utilise la balise <hr/> qui sépare chaque abstract\n",
    "soup = BeautifulSoup(HTML, 'html.parser')\n",
    "liste_des_abstracts = {}\n",
    "i = 1\n",
    "j = 0\n",
    "for hr in tqdm(soup.find_all(\"hr\")):\n",
    "    texte = []\n",
    "    for item in hr.find_next_siblings():\n",
    "        liste_nom_direct = []\n",
    "        liste_nom_indirect = []\n",
    "        liste_institution = []\n",
    "        if item.name == \"hr\":\n",
    "            i = 1\n",
    "            break\n",
    "        if item.name == \"p\":\n",
    "            if i == 1: #la seule logique est celle de la suite des <p> : le premier est le titre, le 2e les auteur.es, le 3e est l'université s'il y en a une. Je crée donc un index suivi\n",
    "                if item.string == None:\n",
    "                    if len(item.contents) == 1: #item.contents est une liste où chaque élément est un couple de balise ouvrante/fermante, item.string est une str. Seul le couple de balise contenant le texte m'intéresse.\n",
    "                        titre = item.string\n",
    "                    elif len(item.contents) == 2:\n",
    "                        titre_tags = item.contents[1]\n",
    "                        titre = titre_tags.string\n",
    "                    elif len(item.contents) == 3:\n",
    "                        titre_tags = item.contents[1]\n",
    "                        titre = titre_tags.string\n",
    "                else:\n",
    "                    i = i - 1 #permet de sauter une ligne si la première ligne ne contient pas le nom de l'auteur\n",
    "            if i == 2:\n",
    "                for elem in item.contents: #Le problème consiste ici à trouver les balises comportant le nom de l'auteur, car elles sont entourées de balises parasites qui ne m'intéressent pas\n",
    "                    if elem.string != None: #permet d'écarter les balises ne contenant pas de texte\n",
    "                        if len(elem.string) > 2:\n",
    "                            if elem.string[-2] not in entiers: #permet d'écarter les chiffres renvoyant à une note de base de page\n",
    "                                nom_direct = elem.string\n",
    "                                liste_nom_direct.append(nom_direct)#permet de relever les différents noms dans le cas d'auteurs multiples\n",
    "                    else:\n",
    "                        for souselem in elem.contents: #permet de trouver les balises contenues dans des balises\n",
    "                            if souselem.string not in entiers:\n",
    "                                nom_indirect = souselem.string\n",
    "                                liste_nom_indirect.append(nom_indirect)\n",
    "                noms_indirect = ' '.join(liste_nom_indirect)\n",
    "                noms_direct = ' '.join(liste_nom_direct)\n",
    "                noms = noms_direct + ' ' + noms_indirect  #Je réunis ici les noms trouvés par toutes les manières dans une seule str\n",
    "                noms = noms.replace('2,1', '') #un élément perturbateur que je n'arrivais à dégager est retiré\n",
    "            if i == 3:\n",
    "                for elem in item.contents: #je vais ensuite trier par le contenu pour sélectionner les éléments intéressants concernant la provenance universitaire\n",
    "                    if \"Universi\" in elem or \"Ecole\" in elem or \"ILIT\" in elem or \"Institut\" in elem or \"College\" in elem: #permet de savoir si l'élément étudié contient les termes usuels désignant une université dans les langues européennes et nord-américaines\n",
    "                        institution = elem\n",
    "                        liste_institution.append(institution)\n",
    "                    else:\n",
    "                        if \"Texas A&M University\" in noms: #je recherche et corrige une erreur dans l'encodage que je n'arrivais pas à corriger : l'université était encodé comme un nom\n",
    "                            noms = noms.replace(\"Texas A&M University\", \"\")\n",
    "                            institution = \"Texas A&M University\"\n",
    "                            liste_institution.append(institution)\n",
    "                        else:\n",
    "                            institutions = ' ' #certains auteurs ne sont pas rattachés à une université. Je mets un espace vide pour qu'il y ait quand même une case vide dans le tableau.\n",
    "                institutions = ' '.join(liste_institution)\n",
    "            else:\n",
    "                if item.string != None: #permet de relever toutes les balises contenant directement du texte. Les autres balises \"déchets\" contiennent les noms d'auteurs, les titres, les adresses mails, et quelques éléments éparses dont la complexité pour les attraper ne vaut pas leur valeur et leur importance.\n",
    "                    paragraphe = item.string\n",
    "                    texte.append(paragraphe)\n",
    "            i += 1\n",
    "    liste_finale = [] #j'instancie la liste qui regroupe les éléments d'autorité\n",
    "    titre_dans_cache = \"paper-2012-{}\".format(j)\n",
    "    j += 1\n",
    "    abstract = \" \".join(texte)\n",
    "    with open('./cache2012/cacheTXT/%s.txt' % titre_dans_cache, 'w', encoding='UTF-8') as docTXT: #j'écris dans un cache les abstracts avec leur titre\n",
    "        docTXT.write(titre)\n",
    "        docTXT.write('\\n')\n",
    "        docTXT.write(abstract)\n",
    "    liste_finale.append(titre)\n",
    "    liste_finale.append(noms)\n",
    "    liste_finale.append(institutions)\n",
    "    liste_finale.append(titre_dans_cache) #permet de relier aisément l'abstract et son nom dans le cache\n",
    "    masterList.append(liste_finale) #liste regroupant les informations d'un abstract\n",
    "    \n",
    "    \n",
    "#je stocke la liste des infos de chaque abstract dans un csv\n",
    "with open('./cache2012/TEI2012.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    print(\"Ecriture du csv terminée\")\n",
    "    for abstract in tqdm(masterList):\n",
    "        writer.writerow(abstract)\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

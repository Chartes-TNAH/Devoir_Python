{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEI Conference 2019 #\n",
    "## Etape 2 : Normalisation des textes et préparation à l'analyse ##\n",
    "\n",
    "Le but de cette deuxième partie du traitement est de normaliser les documents pour qu'ils soient tous semblables au moment de l'analyse. Cette chaîne de traitement va notamment produire des fichiers en texte brut à partir des abstracts en XML. J'ai choisis d'inclure les titres des ouvrages dans les abstracts, ce qui n'est pas le cas du document original. Cette décision est motivée par l'idée qu'un titre est une partie de choix du texte, et l'exclure lors d'une analyse textuelle serait une erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les packages ###\n",
    "\n",
    "Voici les packages dont nous aurons besoin. Il faut lancer la cellule ci-dessous une seule fois par lancement de ce notebook-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from lxml import etree\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un dossier dans le cache ###\n",
    "\n",
    "Avec la cellule ci-dessous, on initie un chemin relatif dans le dossier Python et on crée le dossier qui recevra les fichiers en texte brut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = \"./cache2019/cacheXML/\"\n",
    "Path_output = \"./cache2019/cacheTXT/\"\n",
    "filelist = os.listdir(Path)\n",
    "if not os.path.exists(\"./cache2019/cacheTXT\"):\n",
    "    os.makedirs(\"./cache2019/cacheTXT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des fichiers .txt ###\n",
    "\n",
    "Les fichiers en XML enregistrés auparavant sont lus un par un dans la boucle for, le titre est stocké dans une variable et remis dans sa forme originale (les ' _ ' sont remplacés par des espaces comme c'était le cas initialement) pour être réutilisé plus loin.\n",
    "Ensuite, le body du document XML est nettoyé de toutes ses balises et ses espaces (tabulations, retour à la ligne, etc...) en trop sont retirés.\n",
    "Le titre est ajouté dans le body, car dans une étude statistique des mots employés, il m'a semblé que le titre est un espace de choix souvent très éloquent pour connaître le thème d'un texte, et il a donc de plein droit sa place dans les éléments analysés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:00<00:00, 190.56it/s]\n"
     ]
    }
   ],
   "source": [
    "number = 1 # J'initialise un compteur qui servira d'identifiants à l'abstract.\n",
    "dict_noms_abstract = {} # J'instancie un dictionnaire où la clé est l'identifiant complet de l'abstract et la valeur est le titre de l'abstract. Cela permettra d'ajouter une colonne au csv de correspondance avec le code des abstracts.\n",
    "for abstract in tqdm(filelist):\n",
    "    if abstract.endswith(\".xml\"): # C'est une sécurité, pour ne pas piocher n'importe quoi dans le cache, au cas où.\n",
    "        titre = abstract # abstract est une str, et c'est le titre du fichier xml. Il va être nettoyé.\n",
    "        titre = titre.replace(\".xml\", \"\")\n",
    "        titre = titre.replace(\"_\", \" \")\n",
    "        try: #permet d'éviter les erreurs qui bloqueraient tout.\n",
    "            with open(Path + abstract, \"r\", encoding=\"UTF-8\") as y: #Ici, on nettoie le texte de ses balises, car elles n'ont aucun intérêt dans un usage d'analyse statistique sémantique.\n",
    "                tree = etree.parse(y) \n",
    "                notags = etree.tostring(tree, encoding='utf8', method='text') #notags est une str géante en ASCII.\n",
    "                year = 2019\n",
    "                abstract = \"paper-{0}-{1}.txt\".format(year, number) #Ceci est l'identifiant unique du document texte .txt\n",
    "                input_name = abstract # input_name est également une str, mais que l'on va directement ajouter dans le document.\n",
    "                input_name = input_name.replace(\".txt\", \"\")\n",
    "                notags = notags.decode('UTF-8') \n",
    "                liste_mots = notags.split() # l'enchaînement .split / .join permet de retirer les espaces inutiles laissés par la suppression des balises\n",
    "                texte = ' '.join(liste_mots)\n",
    "                dict_noms_abstract[titre] = input_name\n",
    "                with open(Path_output + abstract, \"w\", encoding=\"UTF-8\") as z:\n",
    "                    titre = titre + \" \"\n",
    "                    z.write(str(titre))\n",
    "                    z.write(str(texte))\n",
    "                number += 1\n",
    "        except Exception:\n",
    "            raise\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout d'une grille de correspondance ###\n",
    "\n",
    "Afin de pouvoir retrouver l'abstract à partir des métadonnées stockées dans le fichier csv, il faut ajouter une colonne constituée des identifiants des abstracts.\n",
    "Pour cela, un dictionnaire a été construit ( dict_noms_abstract ) où la clé est le titre réel de l'abstract (celui donné par l'auteur et stocké dans le csv) et où la valeur est l'identifiant que j'ai attribué à chaque abstract dans le cache.\n",
    "Ne pouvant ajouter dans le document d'origine cette colonne, je suis obligé de copier le document, puis supprimer l'ancien et renommer le nouveau avec le nom de l'ancien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cache2019/TEI2019.csv', 'r') as csvinput:\n",
    "    with open('./cache2019/TEI2019-2.csv', 'w') as csvoutput:\n",
    "        writer = csv.writer(csvoutput, lineterminator='\\n')\n",
    "        reader = csv.reader(csvinput)\n",
    "        ensemble_du_document = [] # J'instancie une liste qui recevra tous les éléments du csv d'origine + la valeur correspondante du dictionnaire\n",
    "        for row in reader:\n",
    "            if row[2] in dict_noms_abstract:\n",
    "                row.append(dict_noms_abstract[row[2]])\n",
    "                ensemble_du_document.append(row)\n",
    "        writer.writerows(ensemble_du_document)\n",
    "\n",
    "if os.path.exists('./cache2019/TEI2019.csv'):\n",
    "    os.remove('./cache2019/TEI2019.csv')\n",
    "else:\n",
    "    print(\"Fichier inexistant\")\n",
    "\n",
    "if os.path.exists('./cache2019/TEI2019-2.csv'):\n",
    "    os.rename('./cache2019/TEI2019-2.csv', './cache2019/TEI2019.csv')\n",
    "else:\n",
    "    print(\"Fichier inexistant\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

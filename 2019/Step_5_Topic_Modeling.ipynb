{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEI Conference 2019 #\n",
    "\n",
    "## Etape 5 : Topic Modeling ##\n",
    "\n",
    "Jusqu'à maintenant, nous avons fait de la classification non supervisée, où l'ordinateur distribuait librement chaque document en fonction de la répartition de ses mots.\n",
    "\n",
    "Nous allons ici développer un peu cela en faisant du topic modeling : cette fois-ci, chaque mot est assimilé à un sujet (ou plus précisément à une variété de sujets dont la proximité est donnée sous la forme d'une coefficient relatif à chacun des sujets), et l'addition de chacun de ces coefficients pour chaque mot détermine pour chaque abstract un sujet (ou plutôt une liste de thèmes dont la proximité est indiquée sous la forme d'un coefficient). Grâce à cela, on peut déterminer des clusters fondés non plus la répétitivité de certains termes ou de certaines constructions, mais sur les champs lexicaux utilisés.\n",
    "\n",
    "Nous nous appuierons pour cela sur divers librairies qu'il convient d'importer.\n",
    "\n",
    "## Les packages ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# SpaCy pour la lemmatisation\n",
    "import spacy\n",
    "\n",
    "# Librairies pour la représentation en schéma\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Active le chargement pour Gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "#Permet d'utiliser LDA Mallet dans la seconde partie de l'analyse\n",
    "import git\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les stopwords ##\n",
    "\n",
    "Je définis des stopwords, c'est à dire la liste de mots qui ne doivent pas être pris en compte, ces mots étant généralement des mots grammaticaux. Les mots grammaticaux sont généralement très nombreux mais portent un très faible poids sémantique. Il faut donc les retirer pour éviter qu'ils n'occultent les autres mots à cause de leur surreprésentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use']) #permet d'ajouter certains termes que j'ai décrété"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choisir son corpus ##\n",
    "\n",
    "Il faut activer l'une des deux cellules (au choix) pour charger en mémoire le corpus traité de la manière que vous voulez.\n",
    "\n",
    "Le meilleur choix pour un premier test est de choisir le texte lemmatisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour utiliser les textes stemmés, c'est ici\n",
    "import os\n",
    "documents = []\n",
    "Path = \"./cache2019/cacheSTEM/\"\n",
    "filelist = os.listdir(Path) #filelist est une liste regroupant tous les chemins vers les différents abstracts.\n",
    "\n",
    "for abstract in filelist:\n",
    "    with open(Path + abstract, \"r\", encoding=\"UTF-8\") as y:\n",
    "        texte = y.read()\n",
    "        documents.append(texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour utiliser les textes lemmatisés, c'est ici\n",
    "import os\n",
    "documents = []\n",
    "Path = \"./cache2019/cacheLEM/\"\n",
    "filelist = os.listdir(Path) #filelist est une liste regroupant tous les chemins vers les différents abstracts.\n",
    "\n",
    "for abstract in filelist:\n",
    "    with open(Path + abstract, \"r\", encoding=\"UTF-8\") as y:\n",
    "        texte = y.read()\n",
    "        documents.append(texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling partie 1 : définir des topic ##\n",
    "\n",
    "### Séquençage et nettoyage ###\n",
    "\n",
    "Tout d'abord, je définis une fonction qui séquence chaque abstract en mot et retire la ponctuation. C'est l'étape du préprocessing, c'est à dire formatter le document afin de le rendre lisible par gensim. Gensim a sa propre méthode de séquençage, que nous utiliserons. Nous avons déjà lemmatisé les documents, mais il est utile de le refaire, car cette fois-ci nous utiliserons le lemmatiseur intégré à Gensim, qui permet alors de rendre un document utilisable par Gensim.\n",
    "\n",
    "Chaque document, sous la forme d'une str, devient une liste de str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['use', 'machine', 'learn', 'for', 'the', 'automated', 'classification', 'of', 'stage', 'directions', 'in', 'tei', 'encode', 'drama', 'corpora', 'authors', 'daria', 'maximova', 'national', 'research', 'university', 'higher', 'school', 'of', 'economics', 'moscow', 'ru', 'frank', 'fischer', 'dariah', 'eu', 'and', 'national', 'research', 'university', 'higher', 'school', 'of', 'economics', 'moscow', 'ru', 'abstract', 'the', 'lt', 'stage', 'gt', 'tag', 'be', 'core', 'element', 'for', 'the', 'encoding', 'of', 'drama', 'the', 'tei', 'guideline', 'suggest', 'nine', 'value', 'for', 'pron', 'type', 'attribute', 'which', 'be', 'widely', 'use', 'in', 'large', 'corpus', 'such', 'as', 'the', 'french', 'theatre', 'classique', 'the', 'shakespeare', 'folger', 'library', 'or', 'the', 'swedish', 'dramawebben', 'this', 'paper', 'introduce', 'an', 'approach', 'to', 'automatically', 'assign', 'stage', 'direction', 'type', 'to', 'the', 'tei', 'encoded', 'russian', 'drama', 'corpus', 'rusdracor', 'https', 'dracor', 'org', 'the', 'corpu', 'currently', 'feature', 'play', 'range', 'from', 'mid', 'th', 'to', 'mid', 'th', 'century', 'which', 'make', 'for', 'stage', 'direction', 'with', 'token', 'pron', 'select', 'play', 'comprise', 'stage', 'direction', 'to', 'represent', 'the', 'breadth', 'of', 'the', 'corpus', 'for', 'the', 'manual', 'annotation', 'pron', 'establish', 'clear', 'set', 'of', 'rule', 'to', 'identify', 'the', 'stage', 'direction', 'type', 'propose', 'by', 'the', 'tei', 'guideline', 'https', 'www', 'tei', 'org', 'release', 'doc', 'tei', 'doc', 'en', 'html', 'ref', 'stage', 'html', 'follow', 'the', 'annotation', 'of', 'pron', 'subcorpu', 'pron', 'develop', 'tool', 'for', 'the', 'classification', 'of', 'the', 'remain', 'play', 'without', 'human', 'interference', 'for', 'the', 'conversion', 'of', 'stage', 'direction', 'into', 'feature', 'vector', 'pron', 'use', 'morphological', 'and', 'semantic', 'datum', 'pron', 'tool', 'in', 'pron', 'current', 'state', 'be', 'able', 'to', 'classify', 'different', 'type', 'with', 'an', 'score', 'of', 'approx', 'which', 'mean', 'that', 'out', 'of', 'stage', 'direction', 'of', 'any', 'give', 'type', 'be', 'assign', 'correctly', 'pron', 'work', 'will', 'inform', 'dedicated', 'analysis', 'of', 'stage', 'direction', 'which', 'after', 'preliminary', 'study', 'by', 'sperantov', 'and', 'detken', 'will', 'be', 'base', 'on', 'large', 'corpus', 'allow', 'for', 'description', 'of', 'the', 'evolvement', 'of', 'stage', 'direction', 'over', 'year']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(documents):\n",
    "    for document in documents:\n",
    "        yield(gensim.utils.simple_preprocess(str(document), deacc=True))  # deacc=True retire la ponctuation\n",
    "\n",
    "data_words = list(sent_to_words(documents)) #je lemmatise les abstracts et les stock dans une variable\n",
    "\n",
    "print(data_words[:1]) #Voici à quoi ressemble un extrait du corpus lemmatisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire les bigrammes et les trigrammes ###\n",
    "\n",
    "Nous allons maintenant construire les bigrammes et les trigrammes, c'est à dire rassembler les mots par groupe de 2 ou 3 en fonction de leur ressemblance sémantique, permettant de dégager ainsi des débuts de regroupement.\n",
    "\n",
    "Nous créons donc les modèles pour créer les bigrammes et les trigrammes, qui donnent une liste de mots assignés à chaque mot un à un. Nous testons à la fin un exemple de la liste de mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use', 'machine', 'learn', 'for', 'the', 'automated', 'classification', 'of', 'stage', 'directions', 'in', 'tei', 'encode', 'drama', 'corpora', 'authors', 'daria', 'maximova', 'national', 'research', 'university', 'higher', 'school', 'of', 'economics', 'moscow', 'ru', 'frank', 'fischer', 'dariah', 'eu', 'and', 'national', 'research', 'university', 'higher', 'school', 'of', 'economics', 'moscow', 'ru', 'abstract', 'the', 'lt', 'stage', 'gt', 'tag', 'be', 'core', 'element', 'for', 'the', 'encoding', 'of', 'drama', 'the', 'tei', 'guideline', 'suggest', 'nine', 'value', 'for', 'pron', 'type', 'attribute', 'which', 'be', 'widely', 'use', 'in', 'large', 'corpus', 'such', 'as', 'the', 'french', 'theatre', 'classique', 'the', 'shakespeare', 'folger', 'library', 'or', 'the', 'swedish', 'dramawebben', 'this', 'paper', 'introduce', 'an', 'approach', 'to', 'automatically', 'assign', 'stage_direction', 'type', 'to', 'the', 'tei', 'encoded', 'russian', 'drama', 'corpus', 'rusdracor', 'https', 'dracor', 'org', 'the', 'corpu', 'currently', 'feature', 'play', 'range', 'from', 'mid', 'th', 'to', 'mid', 'th_century', 'which', 'make', 'for', 'stage_direction', 'with', 'token', 'pron', 'select', 'play', 'comprise', 'stage_direction', 'to', 'represent', 'the', 'breadth', 'of', 'the', 'corpus', 'for', 'the', 'manual', 'annotation', 'pron', 'establish', 'clear', 'set', 'of', 'rule', 'to', 'identify', 'the', 'stage_direction', 'type', 'propose', 'by', 'the', 'tei', 'guideline', 'https_www', 'tei', 'org', 'release', 'doc', 'tei', 'doc', 'en', 'html', 'ref', 'stage', 'html', 'follow', 'the', 'annotation', 'of', 'pron', 'subcorpu', 'pron', 'develop', 'tool', 'for', 'the', 'classification', 'of', 'the', 'remain', 'play', 'without', 'human', 'interference', 'for', 'the', 'conversion', 'of', 'stage_direction', 'into', 'feature', 'vector', 'pron', 'use', 'morphological', 'and', 'semantic', 'datum', 'pron', 'tool', 'in', 'pron', 'current_state', 'be', 'able', 'to', 'classify', 'different', 'type', 'with', 'an', 'score', 'of', 'approx', 'which', 'mean', 'that', 'out', 'of', 'stage_direction', 'of', 'any', 'give', 'type', 'be', 'assign', 'correctly', 'pron', 'work', 'will', 'inform', 'dedicated', 'analysis', 'of', 'stage_direction', 'which', 'after', 'preliminary', 'study', 'by', 'sperantov', 'and', 'detken', 'will', 'be', 'base', 'on', 'large', 'corpus', 'allow', 'for', 'description', 'of', 'the', 'evolvement', 'of', 'stage_direction', 'over', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Construit les modèles bigramme et trigramme\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # plus le paramètre threshold est haut, plus il est difficile de construire des groupes de mots\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# On applique la méthode et les modèles dans une variable\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Un exemple d'une trigrammes avec le premier mot.\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous insérons ensuite les modèles dans des fonctions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis ensuite nous l'appliquons à notre set de textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['machine', 'learn', 'automate', 'classification', 'stage', 'direction', 'encode', 'high', 'school', 'economic', 'high', 'school', 'economic', 'stage', 'core', 'element', 'encode', 'drama', 'guideline', 'suggest', 'value', 'pron', 'type', 'attribute', 'widely', 'large', 'paper', 'introduce', 'approach', 'automatically', 'assign', 'stage_direction', 'type', 'encode', 'russian', 'drama', 'currently', 'feature', 'play', 'range', 'mid', 'make', 'stage_direction', 'token', 'select', 'play', 'comprise', 'stage_direction', 'represent', 'manual', 'annotation', 'pron', 'establish', 'clear', 'set', 'rule', 'identify', 'stage_direction', 'type', 'propose', 'guideline', 'stage', 'develop', 'tool', 'classification', 'remain', 'play', 'human', 'interference', 'conversion', 'stage_direction', 'feature', 'vector', 'morphological', 'able', 'classify', 'different', 'type', 'score', 'approx', 'mean', 'stage_direction', 'give', 'type', 'assign', 'correctly', 'pron', 'work', 'inform', 'dedicated', 'analysis', 'stage_direction', 'preliminary', 'study', 'sperantov', 'base', 'large', 'allow', 'description', 'evolvement', 'stage_direction', 'year']]\n"
     ]
    }
   ],
   "source": [
    "# On retire les stop words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# On forme les bigrammes\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# On lemmatise le texte grâce à spacy. J'utilise le corpus d'entraînement le plus petit à notre disposition.\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Je ne lemmatise qu'en ne gardant les noms, les adjectifs, les verbes et les adverbes\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Exemple du résultat sur le premier abstract\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, les mots de chaque texte sont encodés sous la forme de tuple où le premier entier est son identifiant et où le second est son nombre d'occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 2), (26, 1), (27, 3), (28, 1), (29, 1), (30, 2), (31, 1), (32, 2), (33, 2), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 3), (49, 1), (50, 3), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 3), (63, 8), (64, 1), (65, 1), (66, 1), (67, 1), (68, 5), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Je crée le dictionnaire dans lequel est stocké chaque mot différent en clé et un identifiant (nombre entier) en valeur\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# J'associe le corpus à une variable lemmatisé\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Je crée une liste avec à l'intérieur une liste de deux entiers où le premier représente un mot (la valeur de la clé du dictionnaire id2word) et le second est son nombre d'occurence\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Visualisation un peu barbare sur le premier corpus\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux le comprendre, voici une visualisation adaptée à un être humain :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('able', 1),\n",
       "  ('allow', 1),\n",
       "  ('analysis', 1),\n",
       "  ('annotation', 1),\n",
       "  ('approach', 1),\n",
       "  ('approx', 1),\n",
       "  ('assign', 2),\n",
       "  ('attribute', 1),\n",
       "  ('automate', 1),\n",
       "  ('automatically', 1),\n",
       "  ('base', 1),\n",
       "  ('classification', 2),\n",
       "  ('classify', 1),\n",
       "  ('clear', 1),\n",
       "  ('comprise', 1),\n",
       "  ('conversion', 1),\n",
       "  ('core', 1),\n",
       "  ('correctly', 1),\n",
       "  ('currently', 1),\n",
       "  ('dedicated', 1),\n",
       "  ('description', 1),\n",
       "  ('develop', 1),\n",
       "  ('different', 1),\n",
       "  ('direction', 1),\n",
       "  ('drama', 2),\n",
       "  ('economic', 2),\n",
       "  ('element', 1),\n",
       "  ('encode', 3),\n",
       "  ('establish', 1),\n",
       "  ('evolvement', 1),\n",
       "  ('feature', 2),\n",
       "  ('give', 1),\n",
       "  ('guideline', 2),\n",
       "  ('high', 2),\n",
       "  ('human', 1),\n",
       "  ('identify', 1),\n",
       "  ('inform', 1),\n",
       "  ('interference', 1),\n",
       "  ('introduce', 1),\n",
       "  ('large', 2),\n",
       "  ('learn', 1),\n",
       "  ('machine', 1),\n",
       "  ('make', 1),\n",
       "  ('manual', 1),\n",
       "  ('mean', 1),\n",
       "  ('mid', 1),\n",
       "  ('morphological', 1),\n",
       "  ('paper', 1),\n",
       "  ('play', 3),\n",
       "  ('preliminary', 1),\n",
       "  ('pron', 3),\n",
       "  ('propose', 1),\n",
       "  ('range', 1),\n",
       "  ('remain', 1),\n",
       "  ('represent', 1),\n",
       "  ('rule', 1),\n",
       "  ('russian', 1),\n",
       "  ('school', 2),\n",
       "  ('score', 1),\n",
       "  ('select', 1),\n",
       "  ('set', 1),\n",
       "  ('sperantov', 1),\n",
       "  ('stage', 3),\n",
       "  ('stage_direction', 8),\n",
       "  ('study', 1),\n",
       "  ('suggest', 1),\n",
       "  ('token', 1),\n",
       "  ('tool', 1),\n",
       "  ('type', 5),\n",
       "  ('value', 1),\n",
       "  ('vector', 1),\n",
       "  ('widely', 1),\n",
       "  ('work', 1),\n",
       "  ('year', 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voici une version un peu plus lisible. C'est purement de la term-frequency, à l'état brut.\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire l'attribution des sujets ###\n",
    "\n",
    "La LDA (latent Dirichlet Allocation) est une méthode permettant de définir que si certains thèmes sont observés dans un corpus, nous pouvons alors dire que chacun des mots du corpus peuvent être attribués à l'un de ces thèmes.\n",
    "\n",
    "Nous allons appliquer l'algorithme LDA de Gensim à notre corpus en souhaitant 8 topics dans lequel les corpus seront rangés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je construis mon algorithme de LDA\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1, #update_every détermine avec quelle régularité il faut remettre le modèle à jour\n",
    "                                           chunksize=100, #chunksize définit le nombre de documents à utiliser dans chaque passage\n",
    "                                           passes=10, #passes est le nombre total de passage\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons alors trouver les mots clés les plus pertinents de chaque cluster que la machine a trouvé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.017*\"text\" + 0.014*\"bibliographic\" + 0.013*\"odd\" + 0.010*\"record\" + '\n",
      "  '0.009*\"pron\" + 0.009*\"network\" + 0.008*\"work\" + 0.008*\"create\" + '\n",
      "  '0.007*\"project\" + 0.007*\"encode\"'),\n",
      " (1,\n",
      "  '0.037*\"text\" + 0.022*\"paper\" + 0.014*\"line\" + 0.013*\"pron\" + '\n",
      "  '0.009*\"edition\" + 0.008*\"project\" + 0.008*\"datum\" + 0.007*\"model\" + '\n",
      "  '0.007*\"watermark\" + 0.007*\"graph\"'),\n",
      " (2,\n",
      "  '0.015*\"text\" + 0.011*\"transformation\" + 0.010*\"punctuation\" + 0.008*\"also\" '\n",
      "  '+ 0.008*\"information\" + 0.008*\"edition\" + 0.008*\"database\" + 0.007*\"pron\" + '\n",
      "  '0.007*\"access\" + 0.006*\"encode\"'),\n",
      " (3,\n",
      "  '0.012*\"pron\" + 0.010*\"text\" + 0.009*\"element\" + 0.009*\"token\" + '\n",
      "  '0.008*\"write\" + 0.008*\"digital\" + 0.007*\"stage_direction\" + 0.006*\"fair\" + '\n",
      "  '0.006*\"principle\" + 0.006*\"encode\"'),\n",
      " (4,\n",
      "  '0.028*\"text\" + 0.019*\"encode\" + 0.018*\"event\" + 0.011*\"performance\" + '\n",
      "  '0.008*\"work\" + 0.007*\"guideline\" + 0.007*\"model\" + 0.006*\"online\" + '\n",
      "  '0.006*\"theatrical_performance\" + 0.006*\"correspondence\"'),\n",
      " (5,\n",
      "  '0.020*\"pron\" + 0.014*\"text\" + 0.011*\"encode\" + 0.009*\"project\" + '\n",
      "  '0.008*\"process\" + 0.008*\"also\" + 0.008*\"element\" + 0.007*\"datum\" + '\n",
      "  '0.006*\"work\" + 0.006*\"document\"'),\n",
      " (6,\n",
      "  '0.016*\"text\" + 0.011*\"quality\" + 0.009*\"high\" + 0.008*\"document\" + '\n",
      "  '0.008*\"create\" + 0.008*\"ontology\" + 0.008*\"pointer\" + 0.007*\"work\" + '\n",
      "  '0.007*\"edition\" + 0.007*\"account\"'),\n",
      " (7,\n",
      "  '0.024*\"text\" + 0.014*\"guideline\" + 0.012*\"pron\" + 0.011*\"element\" + '\n",
      "  '0.010*\"type\" + 0.010*\"paper\" + 0.009*\"format\" + 0.008*\"example\" + '\n",
      "  '0.008*\"access\" + 0.008*\"structure\"')]\n"
     ]
    }
   ],
   "source": [
    "# J'affiche les mot-clés des 8 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critique du calcul : le score de cohérence ###\n",
    "\n",
    "La perplexité et le score de cohérence permettent de définir si les groupes générés par topic sont cohérents, c'est à dire s'il y a trop ou pas assez de groupes, et si les groupes sont vraiment représentés par ce topic, si ce topic est vraiment au coeur des textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.29600057928434\n",
      "\n",
      "Coherence Score:  0.26502737897608397\n"
     ]
    }
   ],
   "source": [
    "# Je calcule la Perplexité\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # permet de savoir si le modèle est bon. Plus c'est bas, mieux c'est.\n",
    "\n",
    "# Je calcule le score de cohérence.\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation ###\n",
    "\n",
    "Grâce à cette carte interactive, nous pouvons visualiser la répartition des thèmes et des mots-clés dans chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el34181404518837940088045166998\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el34181404518837940088045166998_data = {\"mdsDat\": {\"x\": [-0.016189248402604977, 0.01317446999130724, 0.025221044830073775, -0.16190416719791711, 0.0680490972931845, 0.0665374939110173, -0.0008145994647869453, 0.005925909039725996], \"y\": [-0.02180059255508071, -0.12923945215199853, -0.047689801331068205, 0.025068413107622554, 0.05146520457155425, 0.04685855301778201, 0.06754125002470104, 0.007796425316487372], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [50.39642333984375, 17.01350975036621, 7.693997859954834, 7.204809665679932, 4.719014644622803, 4.509252548217773, 4.432285785675049, 4.030705451965332]}, \"tinfo\": {\"Term\": [\"text\", \"encode\", \"paper\", \"odd\", \"work\", \"guideline\", \"pron\", \"database\", \"edition\", \"element\", \"create\", \"record\", \"event\", \"also\", \"access\", \"document\", \"transformation\", \"format\", \"bibliographic\", \"type\", \"information\", \"model\", \"structure\", \"example\", \"line\", \"project\", \"ontology\", \"token\", \"process\", \"way\", \"rhyme\", \"novel\", \"eltec\", \"title\", \"night\", \"poem\", \"parliamentary\", \"image\", \"periodical\", \"population\", \"begin\", \"less\", \"female\", \"entire\", \"comity\", \"diagnostic\", \"typically\", \"check\", \"site\", \"distant_reade\", \"header\", \"label\", \"update\", \"european\", \"scheme\", \"third\", \"dynamic\", \"ontological\", \"encoder\", \"view\", \"component\", \"end\", \"error\", \"build\", \"process\", \"tag\", \"source\", \"pron\", \"also\", \"page\", \"project\", \"editor\", \"form\", \"require\", \"encode\", \"provide\", \"time\", \"value\", \"element\", \"xml\", \"work\", \"document\", \"datum\", \"level\", \"make\", \"text\", \"file\", \"collection\", \"database\", \"different\", \"example\", \"available\", \"watermark\", \"graph\", \"genetic\", \"mold\", \"weight\", \"edge\", \"cmif\", \"fig\", \"lineation\", \"speak\", \"haentjen\", \"custom\", \"deletion\", \"registration\", \"motive\", \"gloss\", \"highly\", \"hinkelmann\", \"semantic_web\", \"maker\", \"chinese\", \"interlinear\", \"phonetic\", \"denote\", \"attach\", \"standardized\", \"complicate\", \"outline\", \"winnifre\", \"capacity\", \"geographical\", \"revision\", \"paper\", \"wish\", \"line\", \"edition\", \"text\", \"ontology\", \"character\", \"customization\", \"present\", \"module\", \"main\", \"represent\", \"annotation\", \"description\", \"model\", \"project\", \"datum\", \"different\", \"pron\", \"describe\", \"link\", \"record\", \"method\", \"allow\", \"make\", \"encode\", \"information\", \"type\", \"exist\", \"document\", \"base\", \"pedagogy\", \"examine\", \"egxml\", \"teaching\", \"uncertainty\", \"log\", \"lite\", \"additionally\", \"teach\", \"academic\", \"poorly\", \"namespace\", \"highlighting\", \"evolve\", \"haaf\", \"cayless\", \"engage\", \"partnership\", \"evolution\", \"distinctive_feature\", \"objectification\", \"lifecycle\", \"evaluate\", \"refine\", \"manual\", \"methodology\", \"close\", \"rigorous\", \"sale\", \"collaborative\", \"object\", \"certain\", \"guideline\", \"type\", \"conference\", \"format\", \"explore\", \"text\", \"change\", \"user\", \"example\", \"structure\", \"access\", \"introduce\", \"element\", \"paper\", \"research\", \"server\", \"pron\", \"look\", \"possible\", \"place\", \"online\", \"encode\", \"current\", \"material\", \"need\", \"however\", \"also\", \"include\", \"textual\", \"exist\", \"base\", \"stage_direction\", \"regular_expression\", \"underline\", \"inscription\", \"tokenize\", \"notational\", \"fair\", \"orcid\", \"default\", \"searchable\", \"classification\", \"cognitive\", \"stance\", \"artifact\", \"iip\", \"findable\", \"usable\", \"tokenized\", \"unary\", \"lining\", \"precede\", \"school\", \"realist\", \"condition\", \"notation\", \"fairly\", \"intentional\", \"satlow\", \"textuality\", \"guide\", \"correctly\", \"role\", \"debate\", \"token\", \"archival\", \"rend\", \"write\", \"principle\", \"theory\", \"digital\", \"mean\", \"order\", \"element\", \"pron\", \"type\", \"text\", \"textual\", \"datum\", \"attribute\", \"file\", \"encode\", \"set\", \"word\", \"document\", \"information\", \"however\", \"work\", \"format\", \"advantage\", \"rendition\", \"theatrical_performance\", \"event\", \"promptbook\", \"performance\", \"dramatic\", \"tibetan\", \"quarterly\", \"theatrical\", \"press\", \"recreate\", \"music\", \"reuse\", \"playhouse\", \"doctrinal\", \"chichester\", \"fall\", \"agent\", \"prompt\", \"seifert\", \"sakya\", \"illustrious\", \"raise\", \"correspdesc\", \"prompter\", \"watch\", \"thread\", \"handbook\", \"invite\", \"chronological\", \"simulate\", \"encoding_initiative\", \"background\", \"evidence\", \"connection\", \"correspondence\", \"situation\", \"hold\", \"discussion\", \"online\", \"workshop\", \"problematic\", \"consideration\", \"history\", \"arise\", \"encode\", \"apply\", \"vary\", \"text\", \"deal\", \"artefact\", \"problem\", \"develop\", \"guideline\", \"question\", \"work\", \"literary\", \"model\", \"address\", \"specific\", \"feature\", \"example\", \"way\", \"edition\", \"pron\", \"include\", \"source\", \"also\", \"underdeveloped\", \"interaction\", \"experimental\", \"eoa\", \"citation\", \"bibliographic\", \"sig\", \"tutorial\", \"network\", \"session\", \"incomplete\", \"strict\", \"stategie\", \"vague\", \"solicit\", \"phenomena\", \"enforce\", \"interreligious\", \"abbasid\", \"monograph\", \"bug\", \"schemata\", \"interpretive\", \"syriac\", \"oral\", \"christian\", \"spear\", \"shortcome\", \"subsequent\", \"funde\", \"country\", \"functional\", \"domain\", \"activity\", \"exactly\", \"odd\", \"analysis\", \"relationship\", \"record\", \"layer\", \"interpretation\", \"relax\", \"primary_source\", \"japanese\", \"infrastructure\", \"group\", \"create\", \"moreover\", \"requirement\", \"researcher\", \"text\", \"way\", \"format\", \"work\", \"pron\", \"project\", \"model\", \"encode\", \"base\", \"structure\", \"different\", \"scholar\", \"paper\", \"element\", \"file\", \"edition\", \"access\", \"type\", \"provide\", \"tool\", \"content\", \"produce\", \"uri\", \"latex\", \"bookkeepe\", \"linkable\", \"teidata\", \"pointer\", \"quality\", \"attestation\", \"xsl\", \"fromthepage\", \"informal\", \"statistic\", \"enumerate\", \"mapping\", \"account\", \"taxonomy\", \"indian\", \"behaviour\", \"lawyer\", \"hassle\", \"bundle\", \"rescue\", \"impressive\", \"dialogic\", \"consequential\", \"prerequisite\", \"compliance\", \"indology\", \"pain\", \"fortunately\", \"typology\", \"freely\", \"editorial\", \"ongoing\", \"financial\", \"graz\", \"utilise\", \"high\", \"historical\", \"print\", \"ontology\", \"mechanism\", \"powerful\", \"attempt\", \"create\", \"resource\", \"attribute\", \"text\", \"edition\", \"document\", \"work\", \"type\", \"book\", \"make\", \"odd\", \"category\", \"paper\", \"model\", \"pron\", \"digital\", \"project\", \"encode\", \"process\", \"datum\", \"punctuation\", \"medieval\", \"valuable\", \"actor\", \"subsequently\", \"footnote\", \"recognize\", \"paradigm\", \"philology\", \"readability\", \"digitally\", \"universal\", \"intermediate\", \"attest\", \"substitute\", \"epistemology\", \"travel\", \"interpretative\", \"tangle\", \"taste\", \"heavily\", \"profile\", \"port\", \"docx\", \"bit\", \"digitisation\", \"lettre\", \"launch\", \"philological\", \"vyvoje\", \"span\", \"prepare\", \"approximately\", \"transformation\", \"platform\", \"electronic\", \"program\", \"lead\", \"modern\", \"transform\", \"sign\", \"edition\", \"database\", \"information\", \"world\", \"access\", \"reference\", \"annotation\", \"also\", \"available\", \"text\", \"compare\", \"old\", \"research\", \"online\", \"possible\", \"editor\", \"format\", \"pron\", \"encode\", \"web\", \"process\", \"paper\", \"datum\", \"output\", \"part\", \"system\", \"letter\", \"provide\"], \"Freq\": [249.0, 120.0, 72.0, 26.0, 64.0, 34.0, 195.0, 38.0, 37.0, 80.0, 37.0, 29.0, 13.0, 73.0, 40.0, 60.0, 17.0, 40.0, 12.0, 42.0, 42.0, 50.0, 39.0, 45.0, 56.0, 89.0, 19.0, 21.0, 65.0, 39.0, 32.28184509277344, 18.154407501220703, 14.371171951293945, 13.423622131347656, 14.307836532592773, 32.3801155090332, 12.498682022094727, 11.528443336486816, 9.625919342041016, 9.624780654907227, 9.622504234313965, 9.619309425354004, 8.670519828796387, 8.666231155395508, 8.664471626281738, 8.663334846496582, 7.723651885986328, 7.720954895019531, 16.298561096191406, 6.771760940551758, 6.769920825958252, 12.425165176391602, 5.8271098136901855, 5.822048664093018, 5.816626071929932, 5.811899662017822, 6.665331840515137, 5.795781135559082, 24.809057235717773, 9.907299995422363, 17.22942352294922, 17.01850700378418, 10.572422981262207, 37.49919891357422, 54.29922103881836, 23.81568717956543, 36.249210357666016, 129.85267639160156, 52.02210998535156, 25.812744140625, 59.10971450805664, 25.767728805541992, 23.96030616760254, 23.84697723388672, 73.40740966796875, 34.815330505371094, 29.577913284301758, 19.132217407226562, 49.71432876586914, 21.028095245361328, 41.18244552612305, 38.632022857666016, 48.728858947753906, 29.05745506286621, 33.983238220214844, 91.3857192993164, 29.646272659301758, 26.754627227783203, 25.876636505126953, 29.413875579833984, 24.91234588623047, 22.78555679321289, 15.815421104431152, 14.94534683227539, 7.9666337966918945, 7.087332248687744, 6.2169928550720215, 5.343788146972656, 5.336055755615234, 4.473093509674072, 3.6089048385620117, 3.6052825450897217, 3.6007583141326904, 3.6004014015197754, 3.600701332092285, 3.598710060119629, 3.596952199935913, 3.5079429149627686, 2.729069232940674, 2.7281811237335205, 2.7277557849884033, 2.7261853218078613, 2.715153455734253, 2.707519292831421, 2.5978548526763916, 2.5753233432769775, 4.415288925170898, 5.342287063598633, 1.8605577945709229, 1.8587132692337036, 1.8583043813705444, 1.856524109840393, 3.5989487171173096, 10.585582733154297, 47.62759017944336, 3.5988290309906006, 29.908872604370117, 18.780073165893555, 81.14163208007812, 10.590413093566895, 8.862533569335938, 7.972572326660156, 12.300064086914062, 4.4729838371276855, 6.975599765777588, 14.562582015991211, 9.707240104675293, 14.079456329345703, 15.84182071685791, 18.53426170349121, 17.63471794128418, 13.412294387817383, 27.522972106933594, 11.240104675292969, 8.859027862548828, 9.725375175476074, 8.733570098876953, 8.856403350830078, 11.019339561462402, 14.00490951538086, 9.912740707397461, 9.715523719787598, 8.829939842224121, 9.490358352661133, 8.313238143920898, 4.6044416427612305, 3.1050639152526855, 3.100268840789795, 3.0976455211639404, 7.434250831604004, 2.3502440452575684, 2.348428726196289, 2.346273183822632, 5.353405952453613, 1.6016141176223755, 1.5997201204299927, 1.5983532667160034, 1.5982952117919922, 1.598930835723877, 1.5986380577087402, 1.5974329710006714, 1.5967174768447876, 1.5965546369552612, 1.5940320491790771, 3.858823537826538, 1.5843220949172974, 1.5693355798721313, 2.3502092361450195, 2.3482656478881836, 2.3510329723358154, 3.1044747829437256, 2.352151393890381, 2.3492329120635986, 0.850418210029602, 0.8473852276802063, 6.632675647735596, 4.609020233154297, 13.626941680908203, 9.874273300170898, 3.105001449584961, 8.942476272583008, 3.1074562072753906, 23.352622985839844, 5.276692867279053, 5.291501998901367, 8.364686965942383, 7.649059772491455, 7.655255317687988, 3.8115737438201904, 10.535853385925293, 9.845462799072266, 5.330677032470703, 3.8552188873291016, 11.74231243133545, 3.8185062408447266, 4.974072456359863, 3.830308437347412, 3.852529764175415, 7.097352027893066, 3.8617982864379883, 3.8617372512817383, 3.811330556869507, 4.05106782913208, 4.241709232330322, 4.022853374481201, 3.927332878112793, 3.865239143371582, 3.8696045875549316, 6.071328639984131, 4.594391822814941, 3.0930168628692627, 3.7114710807800293, 3.0910181999206543, 3.04245924949646, 5.96083927154541, 3.006685972213745, 2.3426966667175293, 2.342069625854492, 2.3371167182922363, 2.322061538696289, 2.3160653114318848, 2.3105082511901855, 2.3113033771514893, 2.2931888103485107, 2.2694499492645264, 1.592431664466858, 1.5922861099243164, 1.591961145401001, 1.5891053676605225, 1.587005853652954, 1.5812212228775024, 1.5762834548950195, 1.5747289657592773, 1.5750283002853394, 1.567326307296753, 1.5636522769927979, 3.060133218765259, 2.2992911338806152, 2.3435921669006348, 3.082153558731079, 3.055297374725342, 8.340479850769043, 3.020446300506592, 2.3426997661590576, 7.600549697875977, 5.9423508644104, 3.7502076625823975, 7.21192741394043, 4.508924961090088, 5.3304290771484375, 8.444499015808105, 11.384096145629883, 5.382526874542236, 9.375422477722168, 5.10526704788208, 5.526182174682617, 3.889277458190918, 4.703401565551758, 5.6791462898254395, 3.8484745025634766, 3.8493425846099854, 4.457468509674072, 3.8575220108032227, 3.654270648956299, 3.6119742393493652, 3.3067257404327393, 3.0971431732177734, 3.0955731868743896, 3.946636438369751, 11.00948715209961, 2.659003734588623, 6.524050712585449, 3.3050730228424072, 1.3692270517349243, 1.3696576356887817, 1.369694471359253, 1.3687907457351685, 1.366378903388977, 2.658003568649292, 0.7253276109695435, 0.7254646420478821, 0.7251949906349182, 0.7254093289375305, 0.7253559231758118, 0.7250410318374634, 0.7253426313400269, 0.7251489162445068, 0.724943220615387, 0.7249312996864319, 0.7249011397361755, 0.725100576877594, 0.7251816987991333, 0.7250945568084717, 0.7251102924346924, 0.7250670790672302, 0.7250003814697266, 0.7247357964515686, 0.7250684499740601, 1.3693090677261353, 1.366938829421997, 2.0165061950683594, 2.0139007568359375, 3.946270704269409, 1.3706557750701904, 2.0188333988189697, 3.307551860809326, 3.950605630874634, 2.6605772972106934, 1.3694978952407837, 0.9771400094032288, 3.3090054988861084, 1.3684958219528198, 11.517277717590332, 3.3132641315460205, 1.3685753345489502, 17.35330581665039, 2.015446424484253, 1.3702428340911865, 3.309187173843384, 3.3714489936828613, 3.9715232849121094, 2.232091188430786, 4.625387191772461, 2.661390542984009, 3.9695825576782227, 2.017613410949707, 2.6690495014190674, 2.6693427562713623, 2.8920209407806396, 2.719287395477295, 2.6630523204803467, 3.4957056045532227, 2.696615695953369, 2.670365810394287, 2.186394214630127, 1.9962596893310547, 1.3641544580459595, 1.3640904426574707, 1.3638324737548828, 1.361838459968567, 8.414375305175781, 1.358156681060791, 2.0037014484405518, 5.224979877471924, 1.9958223104476929, 0.7226400971412659, 0.7224781513214111, 0.7224639058113098, 0.7224076986312866, 0.7223442196846008, 0.7223946452140808, 0.7223300933837891, 0.7222705483436584, 0.7222374677658081, 0.7223107218742371, 0.7222673296928406, 0.7222188115119934, 0.722139298915863, 0.7220957279205322, 0.722061276435852, 0.7220337390899658, 0.7220079302787781, 0.7220556139945984, 0.7219406962394714, 0.7218591570854187, 2.6331515312194824, 2.003525972366333, 1.3624533414840698, 2.6394710540771484, 1.3655648231506348, 7.805343151092529, 3.292980909347534, 3.2876064777374268, 5.862789630889893, 2.006007432937622, 1.3640257120132446, 1.364056944847107, 2.0081288814544678, 1.9896122217178345, 2.009613513946533, 2.004851818084717, 4.58938455581665, 1.3625234365463257, 2.004441261291504, 2.003549337387085, 9.753077507019043, 3.9547603130340576, 3.9464449882507324, 4.600536823272705, 5.307743072509766, 3.977264642715454, 3.298529624938965, 3.976627826690674, 2.6545450687408447, 2.665905237197876, 2.665911912918091, 2.0142874717712402, 2.0463662147521973, 2.032027244567871, 2.0276901721954346, 2.0258431434631348, 2.023916006088257, 2.0234310626983643, 2.0200164318084717, 2.0187649726867676, 2.0162711143493652, 2.0150952339172363, 3.2383873462677, 2.6070449352264404, 2.606947898864746, 1.9749246835708618, 1.974116563796997, 4.505093097686768, 6.410287380218506, 1.344780445098877, 1.3436105251312256, 1.3439069986343384, 1.3437780141830444, 1.3429614305496216, 1.3428932428359985, 1.3429999351501465, 3.9090566635131836, 1.9747248888015747, 0.7121406197547913, 0.7120493054389954, 0.7119550704956055, 0.7119003534317017, 0.7119592428207397, 0.7119290232658386, 0.7118982076644897, 0.7119250297546387, 0.7118570804595947, 0.7119299173355103, 0.7119221687316895, 0.7118772268295288, 0.711830198764801, 0.711794912815094, 2.6093242168426514, 1.3447288274765015, 3.239567756652832, 1.9790552854537964, 1.3442381620407104, 1.343291997909546, 1.3443870544433594, 5.156467914581299, 3.8777153491973877, 3.24491286277771, 4.522552013397217, 1.3446775674819946, 1.3461905717849731, 1.9785858392715454, 4.529621601104736, 3.249636173248291, 3.269603729248047, 9.185587882995605, 3.9291610717773438, 4.559081554412842, 3.942929744720459, 3.277919054031372, 1.9954499006271362, 3.267749547958374, 2.6149773597717285, 1.980086326599121, 3.308363437652588, 2.640536308288574, 2.748924732208252, 2.0235118865966797, 2.0396182537078857, 2.03725528717041, 2.0315022468566895, 2.026766777038574, 5.0014519691467285, 1.307884931564331, 1.3048652410507202, 1.3011841773986816, 1.3004341125488281, 2.5229737758636475, 0.6925069093704224, 0.6924961805343628, 0.6924172043800354, 0.6924195289611816, 0.6923566460609436, 0.6923363208770752, 0.6922105550765991, 0.6921064257621765, 0.6919833421707153, 0.6919867992401123, 0.6919580698013306, 0.6918479800224304, 0.6917974948883057, 0.6917353272438049, 0.6893107295036316, 0.6892114877700806, 0.6890057921409607, 0.688614010810852, 0.6890343427658081, 0.6888985633850098, 0.688941240310669, 0.6889232397079468, 0.6887937188148499, 0.6883547902107239, 1.3033021688461304, 2.521636724472046, 1.296047329902649, 5.6185383796691895, 2.5250027179718018, 1.912007212638855, 1.2999967336654663, 1.3056695461273193, 2.5355796813964844, 1.299168586730957, 1.9293360710144043, 4.3786234855651855, 4.356621265411377, 4.379239559173584, 1.3000924587249756, 3.760784387588501, 2.5362775325775146, 2.5321290493011475, 4.390854835510254, 3.1639182567596436, 7.564591884613037, 1.3043724298477173, 1.299014687538147, 2.525571584701538, 1.9205169677734375, 2.5507099628448486, 2.554263114929199, 2.54355525970459, 3.867647171020508, 3.1998987197875977, 1.9297548532485962, 2.5599138736724854, 2.546780824661255, 2.564809799194336, 1.9260121583938599, 1.9256343841552734, 1.937777042388916, 1.9291390180587769, 1.9402985572814941], \"Total\": [249.0, 120.0, 72.0, 26.0, 64.0, 34.0, 195.0, 38.0, 37.0, 80.0, 37.0, 29.0, 13.0, 73.0, 40.0, 60.0, 17.0, 40.0, 12.0, 42.0, 42.0, 50.0, 39.0, 45.0, 56.0, 89.0, 19.0, 21.0, 65.0, 39.0, 33.16426086425781, 18.875181198120117, 15.0574312210083, 14.103837966918945, 15.040460586547852, 34.062068939208984, 13.158402442932129, 12.193066596984863, 10.285449028015137, 10.284661293029785, 10.284918785095215, 10.283550262451172, 9.329086303710938, 9.327146530151367, 9.326827049255371, 9.32608413696289, 8.374443054199219, 8.3732328414917, 17.84834861755371, 7.4193644523620605, 7.4181718826293945, 13.784509658813477, 6.466884613037109, 6.465137004852295, 6.464163303375244, 6.462021350860596, 7.41151762008667, 6.456273555755615, 27.70888328552246, 11.097310066223145, 19.43705940246582, 19.252010345458984, 11.854389190673828, 43.94264221191406, 65.72749328613281, 29.302709579467773, 46.681121826171875, 195.9220733642578, 73.27411651611328, 33.66564178466797, 89.15088653564453, 33.7696647644043, 31.318923950195312, 31.148876190185547, 120.91988372802734, 49.2611198425293, 40.54608917236328, 24.263978958129883, 80.9844970703125, 27.41578483581543, 64.34148406982422, 60.89573669433594, 83.02235412597656, 42.573429107666016, 55.20293045043945, 249.11196899414062, 45.87338638305664, 39.31460952758789, 38.53038024902344, 50.32621765136719, 45.49762725830078, 36.220947265625, 16.517269134521484, 15.637941360473633, 8.626859664916992, 7.747938632965088, 6.8721466064453125, 5.995494365692139, 5.9911346435546875, 5.1191864013671875, 4.245913982391357, 4.245051860809326, 4.2429609298706055, 4.242549419403076, 4.24296760559082, 4.242273330688477, 4.242341995239258, 4.22203254699707, 3.366431474685669, 3.366140604019165, 3.365908622741699, 3.365478038787842, 3.3645501136779785, 3.362474203109741, 3.3349225521087646, 3.3290610313415527, 5.729926586151123, 6.94877290725708, 2.490750312805176, 2.4903531074523926, 2.490157127380371, 2.4897353649139404, 4.888812065124512, 14.76870059967041, 72.60639953613281, 5.195286750793457, 56.96162414550781, 37.31214141845703, 249.11196899414062, 19.898862838745117, 16.01017189025879, 14.404662132263184, 26.6708984375, 6.717536449432373, 12.60206413269043, 36.89506912231445, 21.292020797729492, 37.920692443847656, 50.34032440185547, 89.15088653564453, 83.02235412597656, 50.32621765136719, 195.9220733642578, 36.3918342590332, 23.588991165161133, 29.26314353942871, 23.518545150756836, 29.00993537902832, 55.20293045043945, 120.91988372802734, 42.26690673828125, 42.051231384277344, 29.959674835205078, 60.89573669433594, 34.83721160888672, 5.276348114013672, 3.7601706981658936, 3.758470296859741, 3.7635610103607178, 9.256058692932129, 3.005801200866699, 3.0063605308532715, 3.0062646865844727, 6.987567901611328, 2.24826979637146, 2.2483479976654053, 2.247252941131592, 2.2471721172332764, 2.2488186359405518, 2.2485339641571045, 2.249410390853882, 2.2492945194244385, 2.2492923736572266, 2.2493526935577393, 5.470218658447266, 2.251870632171631, 2.248892307281494, 3.623807907104492, 3.6506593227386475, 3.7562899589538574, 5.052576541900635, 3.9582340717315674, 3.9601545333862305, 1.4918818473815918, 1.4920016527175903, 11.825996398925781, 8.301979064941406, 34.17184829711914, 42.051231384277344, 6.625921249389648, 40.12316131591797, 6.885776042938232, 249.11196899414062, 19.370573043823242, 19.60866355895996, 45.49762725830078, 39.15765380859375, 40.38202667236328, 11.338932991027832, 80.9844970703125, 72.60639953613281, 25.162097930908203, 12.160755157470703, 195.9220733642578, 12.15479564666748, 29.50803565979004, 13.311464309692383, 14.256675720214844, 120.91988372802734, 15.158699989318848, 15.353655815124512, 20.55803871154785, 34.86175537109375, 73.27411651611328, 41.50576400756836, 42.11646270751953, 29.959674835205078, 34.83721160888672, 6.75963830947876, 5.25782585144043, 3.7517783641815186, 4.505690097808838, 3.7526252269744873, 3.746866464614868, 7.385984420776367, 3.7517521381378174, 2.9967713356018066, 2.9976985454559326, 2.9959466457366943, 2.996934652328491, 2.996098756790161, 2.9953794479370117, 2.997396945953369, 2.9976038932800293, 2.9977974891662598, 2.243717908859253, 2.2439463138580322, 2.243917942047119, 2.243500232696533, 2.2415261268615723, 2.243622303009033, 2.2428314685821533, 2.242811679840088, 2.2437193393707275, 2.2416112422943115, 2.2436399459838867, 4.396076679229736, 3.866302967071533, 3.949733018875122, 5.385156631469727, 5.3539910316467285, 21.572507858276367, 5.660829067230225, 3.952146053314209, 22.885852813720703, 18.843372344970703, 9.860328674316406, 38.45400619506836, 16.510108947753906, 23.319028854370117, 80.9844970703125, 195.9220733642578, 42.051231384277344, 249.11196899414062, 42.11646270751953, 83.02235412597656, 21.719146728515625, 45.87338638305664, 120.91988372802734, 26.91298484802246, 29.28346061706543, 60.89573669433594, 42.26690673828125, 34.86175537109375, 64.34148406982422, 40.12316131591797, 13.85612678527832, 18.491025924682617, 4.621557235717773, 13.688603401184082, 3.326146364212036, 9.121837615966797, 4.850832939147949, 2.0299646854400635, 2.0310089588165283, 2.0311317443847656, 2.0313022136688232, 2.03205943107605, 4.2803144454956055, 1.3828856945037842, 1.383344054222107, 1.382935881614685, 1.3833805322647095, 1.383406162261963, 1.3828579187393188, 1.3834537267684937, 1.3832201957702637, 1.3829160928726196, 1.3829216957092285, 1.3828774690628052, 1.3833073377609253, 1.383553385734558, 1.3834202289581299, 1.383460521697998, 1.3833829164505005, 1.3833580017089844, 1.3828662633895874, 1.3835158348083496, 2.7878918647766113, 2.788702964782715, 4.58528470993042, 4.586158752441406, 10.765463829040527, 2.984520435333252, 5.152756214141846, 10.793635368347168, 14.256675720214844, 8.899723052978516, 3.6027371883392334, 2.169461727142334, 13.862539291381836, 3.739426612854004, 120.91988372802734, 16.09954071044922, 3.8607115745544434, 249.11196899414062, 7.474113941192627, 3.9388458728790283, 19.121274948120117, 23.031940460205078, 34.17184829711914, 10.391700744628906, 64.34148406982422, 16.61444091796875, 50.34032440185547, 9.110784530639648, 29.538633346557617, 31.40938949584961, 45.49762725830078, 39.06842803955078, 37.31214141845703, 195.9220733642578, 41.50576400756836, 46.681121826171875, 73.27411651611328, 2.6723062992095947, 2.025139331817627, 2.0252459049224854, 2.0252585411071777, 2.0265254974365234, 12.54218864440918, 2.0266807079315186, 3.426762580871582, 9.321648597717285, 3.6266674995422363, 1.380490779876709, 1.3804806470870972, 1.3804802894592285, 1.3805115222930908, 1.3804244995117188, 1.3805292844772339, 1.3805094957351685, 1.380456805229187, 1.3804280757904053, 1.380590796470642, 1.3805556297302246, 1.3805817365646362, 1.3804651498794556, 1.3804130554199219, 1.3804209232330322, 1.3804547786712646, 1.3804259300231934, 1.380584955215454, 1.3805861473083496, 1.3805080652236938, 5.227027893066406, 4.27299690246582, 2.8885936737060547, 6.405447006225586, 2.9787707328796387, 26.28899383544922, 9.594901084899902, 10.48161792755127, 29.26314353942871, 6.212156772613525, 3.535078763961792, 3.7329390048980713, 6.900516033172607, 6.97114372253418, 7.727894306182861, 8.39765739440918, 37.78093719482422, 4.415378093719482, 9.036043167114258, 9.049046516418457, 249.11196899414062, 39.06842803955078, 40.12316131591797, 64.34148406982422, 195.9220733642578, 89.15088653564453, 50.34032440185547, 120.91988372802734, 34.83721160888672, 39.15765380859375, 50.32621765136719, 11.84929370880127, 72.60639953613281, 80.9844970703125, 45.87338638305664, 37.31214141845703, 40.38202667236328, 42.051231384277344, 49.2611198425293, 23.059825897216797, 20.24016761779785, 18.68022918701172, 3.9184813499450684, 3.279958724975586, 3.2821455001831055, 2.644974708557129, 2.645768880844116, 6.144837856292725, 8.922971725463867, 2.007948160171509, 2.007866382598877, 2.0089213848114014, 2.008890390396118, 2.008960723876953, 2.0089731216430664, 2.009143114089966, 6.926244735717773, 3.5995092391967773, 1.371843934059143, 1.3717930316925049, 1.3717718124389648, 1.371710181236267, 1.3718714714050293, 1.3718130588531494, 1.3718191385269165, 1.371903657913208, 1.3717947006225586, 1.3719388246536255, 1.371923804283142, 1.3718794584274292, 1.3718189001083374, 1.371770977973938, 5.034883975982666, 2.7613155841827393, 7.58198356628418, 4.397715091705322, 2.88484787940979, 2.8856260776519775, 2.961109161376953, 15.608726501464844, 14.995725631713867, 11.668534278869629, 19.898862838745117, 3.5160770416259766, 3.716233730316162, 7.183684825897217, 37.78093719482422, 20.463111877441406, 21.719146728515625, 249.11196899414062, 37.31214141845703, 60.89573669433594, 64.34148406982422, 42.051231384277344, 8.03316879272461, 55.20293045043945, 26.28899383544922, 9.130461692810059, 72.60639953613281, 50.34032440185547, 195.9220733642578, 38.45400619506836, 89.15088653564453, 120.91988372802734, 65.72749328613281, 83.02235412597656, 5.677276611328125, 1.9713021516799927, 1.9720044136047363, 1.9729746580123901, 1.9719829559326172, 4.165651321411133, 1.3535000085830688, 1.3535571098327637, 1.3535888195037842, 1.3536349534988403, 1.3536262512207031, 1.3536300659179688, 1.3536851406097412, 1.3537538051605225, 1.3537797927856445, 1.353818416595459, 1.3538410663604736, 1.3538970947265625, 1.3539197444915771, 1.3539774417877197, 1.3540868759155273, 1.3544032573699951, 1.354475498199463, 1.3537540435791016, 1.3546316623687744, 1.3543901443481445, 1.3545492887496948, 1.3545353412628174, 1.3544838428497314, 1.3536219596862793, 2.845691680908203, 6.195807933807373, 2.9260685443878174, 17.946395874023438, 7.527805328369141, 5.755929470062256, 3.4788312911987305, 3.5730059146881104, 10.450885772705078, 3.882723093032837, 8.238699913024902, 37.31214141845703, 38.53038024902344, 42.26690673828125, 4.6374406814575195, 40.38202667236328, 18.362863540649414, 21.292020797729492, 73.27411651611328, 36.220947265625, 249.11196899414062, 5.4930644035339355, 5.484104633331299, 25.162097930908203, 14.256675720214844, 29.50803565979004, 33.7696647644043, 40.12316131591797, 195.9220733642578, 120.91988372802734, 17.466842651367188, 65.72749328613281, 72.60639953613281, 83.02235412597656, 17.622608184814453, 17.757749557495117, 29.952539443969727, 20.322967529296875, 49.2611198425293], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.30620002746582, -5.881700038909912, -6.1153998374938965, -6.183599948883057, -6.119900226593018, -5.303100109100342, -6.255000114440918, -6.3358001708984375, -6.516200065612793, -6.516300201416016, -6.516600131988525, -6.516900062561035, -6.620699882507324, -6.621200084686279, -6.621399879455566, -6.621600151062012, -6.736400127410889, -6.736700057983398, -5.98960018157959, -6.8678998947143555, -6.868199825286865, -6.260900020599365, -7.018099784851074, -7.019000053405762, -7.019899845123291, -7.0208001136779785, -6.883699893951416, -7.023499965667725, -5.569499969482422, -6.487400054931641, -5.934000015258789, -5.946400165557861, -6.422399997711182, -5.156300067901611, -4.786200046539307, -5.610300064086914, -5.190199851989746, -3.914299964904785, -4.828999996185303, -5.529799938201904, -4.701300144195557, -5.531499862670898, -5.604300022125244, -5.609000205993652, -4.484600067138672, -5.230599880218506, -5.393599987030029, -5.8292999267578125, -4.8744001388549805, -5.734799861907959, -5.062699794769287, -5.1265997886657715, -4.894400119781494, -5.411399841308594, -5.254799842834473, -4.265600204467773, -5.391300201416016, -5.49399995803833, -5.527299880981445, -5.399199962615967, -5.565299987792969, -5.6545000076293945, -4.933800220489502, -4.990300178527832, -5.619500160217285, -5.736400127410889, -5.867499828338623, -6.018799781799316, -6.020299911499023, -6.196700096130371, -6.411300182342529, -6.412300109863281, -6.413599967956543, -6.413700103759766, -6.413599967956543, -6.4141998291015625, -6.414700031280518, -6.439700126647949, -6.690800189971924, -6.691100120544434, -6.691299915313721, -6.691800117492676, -6.695899963378906, -6.698699951171875, -6.740099906921387, -6.748799800872803, -6.209700107574463, -6.019100189208984, -7.07390022277832, -7.074900150299072, -7.075099945068359, -7.076000213623047, -6.414100170135498, -5.335299968719482, -3.8313000202178955, -6.414100170135498, -4.296599864959717, -4.76200008392334, -3.2985999584198, -5.334799766540527, -5.512899875640869, -5.61870002746582, -5.185100078582764, -6.196700096130371, -5.752299785614014, -5.016300201416016, -5.421899795532227, -5.050000190734863, -4.93209981918335, -4.775100231170654, -4.824900150299072, -5.098599910736084, -4.379700183868408, -5.275300025939941, -5.513299942016602, -5.420000076293945, -5.527599811553955, -5.513599872589111, -5.295100212097168, -5.055300235748291, -5.400899887084961, -5.421000003814697, -5.516600131988525, -5.444499969482422, -5.576900005340576, -5.374199867248535, -5.768099784851074, -5.769700050354004, -5.770500183105469, -4.895100116729736, -6.0467000007629395, -6.047399997711182, -6.048399925231934, -5.223400115966797, -6.430200099945068, -6.431399822235107, -6.432199954986572, -6.432199954986572, -6.43179988861084, -6.432000160217285, -6.432799816131592, -6.433199882507324, -6.433300018310547, -6.434899806976318, -5.55079984664917, -6.440999984741211, -6.450500011444092, -6.0467000007629395, -6.047500133514404, -6.046299934387207, -5.7683000564575195, -6.045899868011475, -6.047100067138672, -7.063199996948242, -7.066800117492676, -5.009200096130371, -5.373199939727783, -4.289100170135498, -4.611199855804443, -5.768199920654297, -4.710400104522705, -5.767399787902832, -3.750499963760376, -5.2378997802734375, -5.235099792480469, -4.777200222015381, -4.866600036621094, -4.865799903869629, -5.5630998611450195, -4.54640007019043, -4.614200115203857, -5.227700233459473, -5.551799774169922, -4.438000202178955, -5.561299800872803, -5.296899795532227, -5.558199882507324, -5.552499771118164, -4.941500186920166, -5.550000190734863, -5.550099849700928, -5.563199996948242, -5.502200126647949, -5.456200122833252, -5.509200096130371, -5.533199787139893, -5.549200057983398, -5.547999858856201, -5.031899929046631, -5.310699939727783, -5.706299781799316, -5.524099826812744, -5.706999778747559, -5.722799777984619, -5.050300121307373, -5.7347002029418945, -5.9842000007629395, -5.984499931335449, -5.986599922180176, -5.993000030517578, -5.99560022354126, -5.998000144958496, -5.997700214385986, -6.005499839782715, -6.015999794006348, -6.370200157165527, -6.370299816131592, -6.370500087738037, -6.372300148010254, -6.373600006103516, -6.377299785614014, -6.38040018081665, -6.381400108337402, -6.381199836730957, -6.386099815368652, -6.388500213623047, -5.7170000076293945, -6.002900123596191, -5.983799934387207, -5.70989990234375, -5.718599796295166, -4.714399814605713, -5.730100154876709, -5.9842000007629395, -4.807300090789795, -5.053400039672852, -5.513700008392334, -4.859799861907959, -5.329400062561035, -5.162099838256836, -4.702000141143799, -4.403299808502197, -5.152299880981445, -4.597400188446045, -5.2052001953125, -5.125999927520752, -5.47730016708374, -5.287199974060059, -5.098700046539307, -5.487800121307373, -5.487599849700928, -5.34089994430542, -5.485499858856201, -5.539599895477295, -5.551199913024902, -5.639500141143799, -5.704999923706055, -5.70550012588501, -5.0395002365112305, -4.013599872589111, -5.4344000816345215, -4.536799907684326, -5.216899871826172, -6.098100185394287, -6.097799777984619, -6.097799777984619, -6.098400115966797, -6.100200176239014, -5.434800148010254, -6.733500003814697, -6.73330020904541, -6.733699798583984, -6.733399868011475, -6.733399868011475, -6.73390007019043, -6.733500003814697, -6.733699798583984, -6.734000205993652, -6.734000205993652, -6.734099864959717, -6.733799934387207, -6.733699798583984, -6.733799934387207, -6.733799934387207, -6.733799934387207, -6.73390007019043, -6.734300136566162, -6.733799934387207, -6.0980000495910645, -6.099800109863281, -5.710999965667725, -5.712299823760986, -5.039599895477295, -6.097099781036377, -5.709799766540527, -5.216100215911865, -5.03849983215332, -5.433800220489502, -6.097899913787842, -6.435500144958496, -5.215700149536133, -6.098599910736084, -3.9684998989105225, -5.214399814605713, -6.098599910736084, -3.5585999488830566, -5.71150016784668, -6.097400188446045, -5.21560001373291, -5.197000026702881, -5.033199787139893, -5.609399795532227, -4.880799770355225, -5.433499813079834, -5.033699989318848, -5.710400104522705, -5.430600166320801, -5.430500030517578, -5.350399971008301, -5.4120001792907715, -5.4328999519348145, -5.160799980163574, -5.420300006866455, -5.430099964141846, -5.630099773406982, -5.675600051879883, -6.056300163269043, -6.056399822235107, -6.056600093841553, -6.058000087738037, -4.2368998527526855, -6.060699939727783, -5.671899795532227, -4.713399887084961, -5.67579984664917, -6.691699981689453, -6.69189977645874, -6.691999912261963, -6.691999912261963, -6.6921000480651855, -6.6921000480651855, -6.6921000480651855, -6.692200183868408, -6.692299842834473, -6.692200183868408, -6.692200183868408, -6.692299842834473, -6.692399978637695, -6.692500114440918, -6.692500114440918, -6.692599773406982, -6.692599773406982, -6.692500114440918, -6.692699909210205, -6.692800045013428, -5.39870023727417, -5.671999931335449, -6.057600021362305, -5.396299839019775, -6.055300235748291, -4.312099933624268, -5.175099849700928, -5.176700115203857, -4.598199844360352, -5.6707000732421875, -6.056399822235107, -6.056399822235107, -5.6697001457214355, -5.678899765014648, -5.668900012969971, -5.671299934387207, -4.843100070953369, -6.057499885559082, -5.671500205993652, -5.671999931335449, -4.089300155639648, -4.992000102996826, -4.994100093841553, -4.840700149536133, -4.697700023651123, -4.986299991607666, -5.173399925231934, -4.986400127410889, -5.390600204467773, -5.386300086975098, -5.386300086975098, -5.666600227355957, -5.6508002281188965, -5.657800197601318, -5.659999847412109, -5.660900115966797, -5.661799907684326, -5.662099838256836, -5.66379976272583, -5.664400100708008, -5.665599822998047, -5.666200160980225, -5.174600124359131, -5.39139986038208, -5.391499996185303, -5.669099807739258, -5.66949987411499, -4.844399929046631, -4.491799831390381, -6.053400039672852, -6.054299831390381, -6.054100036621094, -6.054200172424316, -6.054800033569336, -6.054800033569336, -6.054800033569336, -4.986400127410889, -5.6691999435424805, -6.6890997886657715, -6.689300060272217, -6.6894001960754395, -6.689499855041504, -6.6894001960754395, -6.6894001960754395, -6.689499855041504, -6.6894001960754395, -6.689499855041504, -6.6894001960754395, -6.6894001960754395, -6.689499855041504, -6.689599990844727, -6.689599990844727, -5.390600204467773, -6.053500175476074, -5.174200057983398, -5.666999816894531, -6.053800106048584, -6.054500102996826, -6.053699970245361, -4.709400177001953, -4.9944000244140625, -5.172599792480469, -4.84060001373291, -6.053500175476074, -6.0524001121521, -5.667300224304199, -4.839000225067139, -5.17110013961792, -5.164999961853027, -4.131999969482422, -4.981200218200684, -4.832499980926514, -4.977700233459473, -5.162399768829346, -5.65880012512207, -5.165599822998047, -5.388400077819824, -5.666500091552734, -5.153200149536133, -5.378699779510498, -5.338399887084961, -5.644800186157227, -5.636899948120117, -5.6381001472473145, -5.640900135040283, -5.643199920654297, -4.644999980926514, -5.986299991607666, -5.98859977722168, -5.991399765014648, -5.992000102996826, -5.32919979095459, -6.622099876403809, -6.622099876403809, -6.622200012207031, -6.622200012207031, -6.622300148010254, -6.622399806976318, -6.622499942779541, -6.622700214385986, -6.622900009155273, -6.622900009155273, -6.622900009155273, -6.6230998039245605, -6.6230998039245605, -6.623199939727783, -6.626699924468994, -6.6269001960754395, -6.627200126647949, -6.627799987792969, -6.627099990844727, -6.627299785614014, -6.627299785614014, -6.627299785614014, -6.627500057220459, -6.6280999183654785, -5.989799976348877, -5.329800128936768, -5.9953999519348145, -4.528600215911865, -5.328400135040283, -5.606500148773193, -5.992300033569336, -5.98799991607666, -5.3242998123168945, -5.993000030517578, -5.597499847412109, -4.777900218963623, -4.7829999923706055, -4.7778000831604, -5.992199897766113, -4.930099964141846, -5.323999881744385, -5.3256001472473145, -4.775199890136719, -5.10290002822876, -4.231200218200684, -5.988999843597412, -5.993100166320801, -5.328199863433838, -5.602099895477295, -5.318299770355225, -5.31689977645874, -5.321100234985352, -4.9019999504089355, -5.091599941253662, -5.597300052642822, -5.314700126647949, -5.319900035858154, -5.31279993057251, -5.5991997718811035, -5.599400043487549, -5.593100070953369, -5.597599983215332, -5.591800212860107], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.65829998254776, 0.6463000178337097, 0.6385999917984009, 0.6358000040054321, 0.6352999806404114, 0.6345999836921692, 0.6338000297546387, 0.6291999816894531, 0.6190000176429749, 0.6189000010490417, 0.6187000274658203, 0.6184999942779541, 0.6119999885559082, 0.6118000149726868, 0.6115999817848206, 0.6115000247955322, 0.6043999791145325, 0.6040999889373779, 0.5943999886512756, 0.5939000248908997, 0.5938000082969666, 0.5813999772071838, 0.5810999870300293, 0.5805000066757202, 0.5796999931335449, 0.579200029373169, 0.5791000127792358, 0.5773000121116638, 0.5746999979019165, 0.5717999935150146, 0.5647000074386597, 0.5619000196456909, 0.5708000063896179, 0.5267000198364258, 0.4941999912261963, 0.4778999984264374, 0.43230000138282776, 0.27390000224113464, 0.3427000045776367, 0.4196000099182129, 0.2743000090122223, 0.4147999882698059, 0.4174000024795532, 0.4180999994277954, 0.18610000610351562, 0.33820000290870667, 0.36980000138282776, 0.44760000705718994, 0.1973000019788742, 0.41999998688697815, 0.23909999430179596, 0.23019999265670776, 0.15240000188350677, 0.30329999327659607, 0.20010000467300415, -0.3176000118255615, 0.24869999289512634, 0.3003999888896942, 0.2870999872684479, 0.14820000529289246, 0.08299999684095383, 0.22169999778270721, 1.7276999950408936, 1.7259000539779663, 1.691499948501587, 1.6820000410079956, 1.6710000038146973, 1.6561000347137451, 1.655400037765503, 1.636199951171875, 1.6086000204086304, 1.607800006866455, 1.6069999933242798, 1.6069999933242798, 1.6069999933242798, 1.606600046157837, 1.6060999631881714, 1.5858999490737915, 1.5613000392913818, 1.5609999895095825, 1.5608999729156494, 1.5605000257492065, 1.5566999912261963, 1.5544999837875366, 1.521399974822998, 1.5144000053405762, 1.5104999542236328, 1.5082999467849731, 1.4795000553131104, 1.478600025177002, 1.4785000085830688, 1.4776999950408936, 1.464900016784668, 1.438099980354309, 1.3494999408721924, 1.4040000438690186, 1.1268999576568604, 1.0845999717712402, 0.6495000123977661, 1.1404000520706177, 1.179800033569336, 1.1796000003814697, 0.9972000122070312, 1.3645000457763672, 1.1797000169754028, 0.8414999842643738, 0.9857000112533569, 0.7803999781608582, 0.6150000095367432, 0.2004999965429306, 0.22190000116825104, 0.4487999975681305, -0.1914999932050705, 0.5963000059127808, 0.7918000221252441, 0.6696000099182129, 0.7804999947547913, 0.5846999883651733, 0.1597999930381775, -0.3846000134944916, 0.32100000977516174, 0.3059999942779541, 0.5494999885559082, -0.0877000018954277, 0.3382999897003174, 2.428499937057495, 2.373300075531006, 2.3722000122070312, 2.369999885559082, 2.3454999923706055, 2.318700075149536, 2.317699909210205, 2.3169000148773193, 2.29830002784729, 2.225600004196167, 2.224400043487549, 2.2239999771118164, 2.2239999771118164, 2.2237000465393066, 2.223599910736084, 2.2225000858306885, 2.222100019454956, 2.2219998836517334, 2.220400094985962, 2.2158000469207764, 2.213099956512451, 2.204900026321411, 2.131700038909912, 2.123500108718872, 2.0961999893188477, 2.077699899673462, 2.044300079345703, 2.0425000190734863, 2.002700090408325, 1.9989999532699585, 1.9864000082015991, 1.9763000011444092, 1.645400047302246, 1.1158000230789185, 1.8068000078201294, 1.063599944114685, 1.7690999507904053, 0.19750000536441803, 1.264299988746643, 1.2548999786376953, 0.8711000084877014, 0.9316999912261963, 0.9017000198364258, 1.4744999408721924, 0.5253000259399414, 0.5666999816894531, 1.0128999948501587, 1.4158999919891357, -0.24979999661445618, 1.4069000482559204, 0.7843000292778015, 1.319000005722046, 1.2561999559402466, -0.27070000767707825, 1.1972999572753906, 1.184499979019165, 0.8794999718666077, 0.4122999906539917, -0.28450000286102295, 0.23090000450611115, 0.1923000067472458, 0.5169000029563904, 0.36719998717308044, 2.5230000019073486, 2.495500087738037, 2.437299966812134, 2.436500072479248, 2.436500072479248, 2.4221999645233154, 2.4159998893737793, 2.4089999198913574, 2.384200096130371, 2.3835999965667725, 2.3821001052856445, 2.3752999305725098, 2.372999906539917, 2.370800018310547, 2.370500087738037, 2.362600088119507, 2.352099895477295, 2.2874999046325684, 2.287400007247925, 2.2871999740600586, 2.285599946975708, 2.285099983215332, 2.2804999351501465, 2.2778000831604004, 2.2767999172210693, 2.276599884033203, 2.272599935531616, 2.2692999839782715, 2.268199920654297, 2.1106998920440674, 2.1085000038146973, 2.0724000930786133, 2.069499969482422, 1.6800999641418457, 2.0023000240325928, 2.1075000762939453, 1.5281000137329102, 1.4764000177383423, 1.663699984550476, 0.9567000269889832, 1.3324999809265137, 1.1546000242233276, 0.36970001459121704, -0.2151000052690506, 0.5746999979019165, -0.649399995803833, 0.5202999711036682, -0.07919999957084656, 0.9104999899864197, 0.35280001163482666, -0.4278999865055084, 0.6855000257492065, 0.6013000011444092, 0.015799999237060547, 0.23639999330043793, 0.3749000132083893, -0.24950000643730164, 0.13439999520778656, 1.132200002670288, 0.8431000113487244, 2.895699977874756, 2.8357999324798584, 2.829699993133545, 2.718400001525879, 2.6698999404907227, 2.6598000526428223, 2.659600019454956, 2.659600019454956, 2.658799886703491, 2.6566998958587646, 2.5771000385284424, 2.4082999229431152, 2.408099889755249, 2.4079999923706055, 2.4079999923706055, 2.407900094985962, 2.407900094985962, 2.407900094985962, 2.4077999591827393, 2.4077000617980957, 2.4077000617980957, 2.4077000617980957, 2.407599925994873, 2.407599925994873, 2.407599925994873, 2.407599925994873, 2.4075000286102295, 2.4075000286102295, 2.4075000286102295, 2.4075000286102295, 2.342600107192993, 2.34060001373291, 2.232100009918213, 2.230600118637085, 2.049999952316284, 2.275399923324585, 2.1166000366210938, 1.8708000183105469, 1.7702000141143799, 1.8460999727249146, 2.0862998962402344, 2.25600004196167, 1.621000051498413, 2.0483999252319336, 0.7023000121116638, 1.4726999998092651, 2.0164999961853027, 0.3894999921321869, 1.7430000305175781, 1.9976999759674072, 1.2994999885559082, 1.1319999694824219, 0.9013000130653381, 1.5154999494552612, 0.42089998722076416, 1.222100019454956, 0.5134000182151794, 1.5460000038146973, 0.6496000289916992, 0.5882999897003174, 0.29789999127388, 0.3885999917984009, 0.41370001435279846, -0.972599983215332, 0.3197000026702881, 0.1923999935388565, -0.45840001106262207, 2.8073999881744385, 2.703900098800659, 2.7037999629974365, 2.7035999298095703, 2.7016000747680664, 2.699899911880493, 2.6988000869750977, 2.5624001026153564, 2.52020001411438, 2.501800060272217, 2.4518001079559326, 2.4514999389648438, 2.4514999389648438, 2.4514000415802, 2.4514000415802, 2.4514000415802, 2.4512999057769775, 2.4512999057769775, 2.451200008392334, 2.451200008392334, 2.451200008392334, 2.4511001110076904, 2.4511001110076904, 2.4511001110076904, 2.4509999752044678, 2.450900077819824, 2.450900077819824, 2.450900077819824, 2.450700044631958, 2.450700044631958, 2.4133999347686768, 2.341599941253662, 2.347599983215332, 2.2125000953674316, 2.3190999031066895, 1.8846999406814575, 2.029599905014038, 1.9395999908447266, 1.4912999868392944, 1.9687000513076782, 2.146699905395508, 2.0922999382019043, 1.8645999431610107, 1.8451999425888062, 1.7520999908447266, 1.666700005531311, 0.9909999966621399, 1.92330002784729, 1.5931999683380127, 1.5913000106811523, -0.1412999927997589, 0.8086000084877014, 0.7799000144004822, 0.460999995470047, -0.5095000267028809, -0.010700000450015068, 0.37369999289512634, -0.3156999945640564, 0.5246000289916992, 0.41200000047683716, 0.16110000014305115, 1.3270000219345093, -0.4699000120162964, -0.5861999988555908, -0.019899999722838402, 0.18569999933242798, 0.10570000112056732, 0.0649000033736229, -0.0949999988079071, 0.6633999943733215, 0.7925999760627747, 0.8722000122070312, 2.925600051879883, 2.8866000175476074, 2.8859000205993652, 2.8241000175476074, 2.8234000205993652, 2.8059000968933105, 2.7855000495910645, 2.715399980545044, 2.7144999504089355, 2.714200019836426, 2.714200019836426, 2.7135000228881836, 2.7135000228881836, 2.7135000228881836, 2.5441999435424805, 2.515899896621704, 2.460599899291992, 2.4605000019073486, 2.460400104522705, 2.460400104522705, 2.4602999687194824, 2.4602999687194824, 2.4602999687194824, 2.4602999687194824, 2.4602999687194824, 2.4602999687194824, 2.4602999687194824, 2.460200071334839, 2.460200071334839, 2.460200071334839, 2.4590001106262207, 2.396699905395508, 2.265899896621704, 2.3178000450134277, 2.35260009765625, 2.351599931716919, 2.3266000747680664, 2.008699893951416, 1.763700008392334, 1.836400032043457, 1.6346999406814575, 2.155100107192993, 2.100800037384033, 1.826799988746643, 0.9951000213623047, 1.2762000560760498, 1.2226999998092651, -0.18400000035762787, 0.8654000163078308, 0.5242000222206116, 0.3240000009536743, 0.5645999908447266, 1.7235000133514404, 0.28929999470710754, 0.8083999752998352, 1.5878000259399414, 0.027699999511241913, 0.16840000450611115, -1.1503000259399414, 0.17159999907016754, -0.661300003528595, -0.9672999978065491, -0.3605000078678131, -0.5964000225067139, 3.0845000743865967, 2.8008999824523926, 2.79830002784729, 2.7950000762939453, 2.7948999404907227, 2.7098000049591064, 2.541100025177002, 2.5409998893737793, 2.5408999919891357, 2.5408999919891357, 2.540800094604492, 2.540800094604492, 2.5404999256134033, 2.540299892425537, 2.54010009765625, 2.54010009765625, 2.54010009765625, 2.539900064468384, 2.539799928665161, 2.539599895477295, 2.5360000133514404, 2.5357000827789307, 2.5353000164031982, 2.5353000164031982, 2.5352001190185547, 2.5352001190185547, 2.5352001190185547, 2.535099983215332, 2.5350000858306885, 2.5350000858306885, 2.430299997329712, 2.312299966812134, 2.396899938583374, 2.0499000549316406, 2.1189000606536865, 2.1092000007629395, 2.226900100708008, 2.2044999599456787, 1.7949999570846558, 2.1164000034332275, 1.759600043296814, 1.068600058555603, 1.031499981880188, 0.944100022315979, 1.9394999742507935, 0.8374999761581421, 1.231600046157837, 1.0820000171661377, 0.39649999141693115, 0.7734000086784363, -0.2831999957561493, 1.7734999656677246, 1.7710000276565552, 0.9124000072479248, 1.2065999507904053, 0.7628999948501587, 0.6294000148773193, 0.4528000056743622, -0.7138000130653381, -0.42080000042915344, 1.0082999467849731, -0.034299999475479126, -0.13899999856948853, -0.26600000262260437, 0.9975000023841858, 0.9897000193595886, 0.4731999933719635, 0.8565999865531921, -0.023099999874830246]}, \"token.table\": {\"Topic\": [6, 3, 1, 2, 3, 5, 6, 7, 8, 1, 4, 7, 8, 1, 3, 6, 8, 8, 3, 1, 2, 3, 4, 5, 6, 8, 1, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 4, 5, 6, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 7, 8, 1, 8, 1, 4, 1, 4, 5, 1, 5, 4, 2, 8, 1, 2, 7, 8, 7, 1, 3, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 5, 1, 2, 3, 4, 5, 6, 1, 7, 1, 3, 6, 8, 1, 2, 4, 7, 7, 6, 1, 2, 3, 4, 7, 8, 7, 2, 1, 3, 7, 3, 2, 3, 4, 6, 1, 2, 3, 5, 6, 1, 2, 3, 4, 8, 1, 5, 2, 6, 5, 6, 4, 1, 3, 2, 4, 3, 1, 2, 4, 5, 6, 7, 8, 1, 1, 2, 3, 8, 7, 2, 1, 2, 7, 4, 1, 3, 1, 5, 7, 2, 5, 1, 2, 3, 6, 7, 1, 4, 5, 2, 4, 5, 6, 8, 1, 6, 1, 2, 3, 4, 6, 7, 8, 1, 2, 3, 6, 8, 2, 1, 2, 3, 6, 1, 2, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 7, 8, 1, 4, 5, 4, 2, 2, 1, 2, 3, 5, 6, 8, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 7, 1, 2, 3, 4, 6, 7, 8, 1, 2, 3, 4, 5, 7, 8, 8, 1, 3, 5, 6, 1, 1, 3, 5, 1, 2, 3, 4, 6, 7, 8, 8, 2, 6, 2, 5, 1, 2, 1, 2, 3, 5, 6, 7, 8, 1, 2, 3, 7, 8, 1, 2, 7, 3, 2, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 4, 6, 3, 5, 1, 3, 8, 6, 3, 1, 7, 6, 8, 1, 8, 1, 3, 8, 5, 6, 1, 5, 3, 3, 1, 6, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 8, 6, 1, 2, 3, 5, 4, 8, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 2, 7, 4, 1, 8, 1, 2, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 7, 4, 7, 7, 1, 5, 6, 6, 2, 2, 5, 2, 2, 2, 7, 1, 6, 2, 4, 1, 3, 4, 5, 6, 8, 3, 2, 5, 7, 1, 8, 1, 2, 4, 7, 3, 2, 2, 1, 2, 5, 6, 7, 8, 1, 5, 6, 7, 1, 2, 5, 6, 1, 2, 3, 4, 6, 7, 8, 4, 5, 1, 7, 1, 2, 3, 4, 5, 6, 7, 8, 6, 7, 7, 7, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 6, 4, 4, 6, 2, 8, 3, 4, 6, 8, 6, 6, 1, 2, 3, 4, 8, 5, 2, 6, 1, 5, 7, 8, 7, 1, 2, 3, 6, 1, 5, 8, 1, 1, 2, 3, 5, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 1, 2, 3, 4, 5, 6, 8, 2, 4, 1, 2, 3, 5, 6, 7, 7, 3, 1, 2, 5, 3, 1, 3, 6, 8, 1, 2, 3, 7, 8, 1, 2, 3, 4, 6, 7, 8, 2, 3, 4, 7, 1, 2, 3, 6, 1, 2, 4, 5, 6, 7, 4, 7, 8, 1, 2, 3, 4, 8, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 6, 8, 1, 2, 6, 2, 6, 2, 6, 7, 2, 1, 5, 3, 1, 2, 3, 4, 7, 1, 2, 5, 6, 1, 4, 4, 1, 2, 3, 4, 5, 8, 3, 1, 6, 7, 1, 5, 8, 2, 7, 1, 2, 3, 5, 6, 8, 1, 1, 2, 5, 6, 7, 6, 4, 1, 2, 3, 4, 7, 8, 2, 1, 2, 3, 4, 7, 8, 1, 2, 3, 4, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 8, 1, 1, 2, 3, 6, 7, 8, 3, 3, 1, 5, 1, 6, 8, 8, 2, 1, 2, 3, 4, 5, 6, 7, 8, 3, 6, 8, 5, 1, 2, 1, 7, 3, 1, 8, 1, 2, 3, 4, 6, 8, 1, 4, 7, 4, 1, 4, 6, 7, 8, 7, 1, 2, 3, 5, 6, 7, 8, 5, 1, 2, 5, 6, 1, 4, 8, 1, 2, 5, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 5, 8, 1, 2, 3, 4, 6, 7, 8, 1, 2, 3, 4, 6, 8, 4, 8, 1, 2, 3, 4, 6, 7, 8, 5, 5, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 8, 1, 2, 7, 5, 1, 2, 4, 5, 8, 5, 8, 4, 8, 1, 2, 5, 6, 7, 5, 1, 2, 3, 5, 6, 7, 8, 3, 6, 2, 4, 1, 2, 5, 6, 7, 8, 1, 4, 6, 1, 4, 1, 3, 4, 8, 1, 2, 3, 4, 8, 1, 2, 3, 6, 1, 6, 7, 7, 1, 2, 3, 5, 6, 7, 8, 1, 5, 6, 1, 2, 3, 4, 6, 7, 8, 5, 1, 2, 5, 1, 1, 3, 2, 3, 4, 5, 3, 4, 6, 1, 1, 2, 3, 6, 7, 8, 4, 4, 5, 2, 1, 3, 1, 6, 1, 2, 3, 4, 5, 6, 7, 8, 6, 6, 1, 2, 8, 5, 1, 2, 1, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 2, 8, 2, 6, 1, 2, 3, 5, 6, 7, 8, 4, 4, 1, 2, 6, 7, 6, 1, 2, 3, 5, 6, 6, 8, 8, 6, 1, 2, 4, 5, 6, 7, 8, 1, 3, 4, 5, 7, 8, 8, 1, 7, 1, 3, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 4, 6, 5, 5, 1, 2, 4, 5, 1, 5, 5, 1, 2, 5, 7, 8, 1, 1, 2, 3, 4, 4, 4, 1, 2, 4, 5, 6, 8, 1, 8, 1, 2, 4, 7, 8, 8, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 7, 4, 1, 3, 6, 4, 8, 1, 7, 4, 1, 2, 3, 8, 1, 7, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 5, 1, 4, 8, 5, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 6, 7, 8, 2, 2, 1, 2, 1, 2, 3, 4, 5, 8, 1, 2, 4, 5, 6, 7, 8, 1, 2, 5, 1, 3, 8, 1, 2, 4, 6, 8, 1, 3, 4, 6, 7, 8, 7], \"Freq\": [0.7244129776954651, 0.8895729780197144, 0.4457428455352783, 0.1733444482088089, 0.19810794293880463, 0.02476349286735058, 0.04952698573470116, 0.02476349286735058, 0.09905397146940231, 0.14437837898731232, 0.14437837898731232, 0.5775135159492493, 0.14437837898731232, 0.15611712634563446, 0.3122342526912689, 0.4683513939380646, 0.15611712634563446, 0.5068488717079163, 0.6652774214744568, 0.21952006220817566, 0.21952006220817566, 0.10976003110408783, 0.10976003110408783, 0.21952006220817566, 0.10976003110408783, 0.10976003110408783, 0.6495321393013, 0.14434048533439636, 0.21651072800159454, 0.7231400609016418, 0.3791804313659668, 0.3102385401725769, 0.10341284424066544, 0.06894189864397049, 0.034470949321985245, 0.034470949321985245, 0.06894189864397049, 0.034470949321985245, 0.709663987159729, 0.08188430219888687, 0.05458953604102135, 0.013647384010255337, 0.027294768020510674, 0.013647384010255337, 0.027294768020510674, 0.05458953604102135, 0.31266605854034424, 0.2084440439939499, 0.10422202199697495, 0.31266605854034424, 0.10422202199697495, 0.23482975363731384, 0.4696595072746277, 0.04696594923734665, 0.0939318984746933, 0.04696594923734665, 0.14089785516262054, 0.3726814389228821, 0.06211357191205025, 0.06211357191205025, 0.1242271438241005, 0.18634071946144104, 0.06211357191205025, 0.06211357191205025, 0.3417554795742035, 0.3417554795742035, 0.3533051311969757, 0.5299577116966248, 0.2674206793308258, 0.2674206793308258, 0.2674206793308258, 0.5077629685401917, 0.2538814842700958, 0.6676950454711914, 0.6980892419815063, 0.1745223104953766, 0.27840864658355713, 0.4176129698753357, 0.27840864658355713, 0.738686740398407, 0.49802082777023315, 0.5064655542373657, 0.09208464622497559, 0.18416929244995117, 0.04604232311248779, 0.13812696933746338, 0.04604232311248779, 0.6349917054176331, 0.05521666631102562, 0.08282499760389328, 0.05521666631102562, 0.02760833315551281, 0.02760833315551281, 0.02760833315551281, 0.08282499760389328, 0.35858964920043945, 0.35858964920043945, 0.48798394203186035, 0.22963950037956238, 0.11481975018978119, 0.028704937547445297, 0.057409875094890594, 0.08611481636762619, 0.9722974300384521, 0.7289729118347168, 0.15946179628372192, 0.15946179628372192, 0.6378471851348877, 0.7382080554962158, 0.3734516203403473, 0.2489677518606186, 0.1244838759303093, 0.2489677518606186, 0.9140362739562988, 0.7243460416793823, 0.8420067429542542, 0.04551387578248978, 0.02275693789124489, 0.02275693789124489, 0.02275693789124489, 0.02275693789124489, 0.7289312481880188, 0.8032982349395752, 0.6571409106254578, 0.10952349007129669, 0.21904698014259338, 0.8891218900680542, 0.12045320868492126, 0.6022660136222839, 0.24090641736984253, 0.12045320868492126, 0.5678716897964478, 0.05162470042705536, 0.2581234872341156, 0.05162470042705536, 0.05162470042705536, 0.18738088011741638, 0.5621426105499268, 0.062460292130708694, 0.12492058426141739, 0.062460292130708694, 0.955425500869751, 0.7228668928146362, 0.8916496634483337, 0.7243989706039429, 0.7231357097625732, 0.4934554100036621, 0.6675686240196228, 0.25263792276382446, 0.5052758455276489, 0.8345664739608765, 0.6673485636711121, 0.6702405214309692, 0.686767578125, 0.20348669588565826, 0.025435836985707283, 0.025435836985707283, 0.025435836985707283, 0.025435836985707283, 0.025435836985707283, 0.9649583697319031, 0.3640955090522766, 0.1820477545261383, 0.1820477545261383, 0.1820477545261383, 0.7289034724235535, 0.8029708862304688, 0.874617874622345, 0.05144811049103737, 0.05144811049103737, 0.8917299509048462, 0.4527672231197357, 0.4527672231197357, 0.4360947906970978, 0.4360947906970978, 0.7289720773696899, 0.4609438180923462, 0.4609438180923462, 0.5434737801551819, 0.19762682914733887, 0.09881341457366943, 0.09881341457366943, 0.04940670728683472, 0.25318166613578796, 0.5063633322715759, 0.722905158996582, 0.3715585470199585, 0.09288963675498962, 0.3715585470199585, 0.09288963675498962, 0.09288963675498962, 0.38262662291526794, 0.5739399194717407, 0.5293675065040588, 0.1323418766260147, 0.052936747670173645, 0.026468373835086823, 0.1323418766260147, 0.1323418766260147, 0.026468373835086823, 0.5277497172355652, 0.1319374293088913, 0.2638748586177826, 0.06596871465444565, 0.06596871465444565, 0.9428293108940125, 0.20826590061187744, 0.5553757548332214, 0.13884393870830536, 0.06942196935415268, 0.6747921705245972, 0.18167482316493988, 0.025953546166419983, 0.10381418466567993, 0.5902025103569031, 0.21680907905101776, 0.04817979410290718, 0.07226969301700592, 0.012044948525726795, 0.012044948525726795, 0.02408989705145359, 0.03613484650850296, 0.2675902545452118, 0.1337951272726059, 0.1337951272726059, 0.2675902545452118, 0.1337951272726059, 0.1337951272726059, 0.1867765486240387, 0.5603296756744385, 0.1867765486240387, 0.667384922504425, 0.9427363872528076, 0.9011549949645996, 0.49461644887924194, 0.30226561427116394, 0.05495738238096237, 0.05495738238096237, 0.027478691190481186, 0.027478691190481186, 0.44830405712127686, 0.36919155716896057, 0.10548330843448639, 0.052741654217243195, 0.026370827108621597, 0.34734371304512024, 0.17367185652256012, 0.1302538961172104, 0.08683592826128006, 0.1302538961172104, 0.04341796413064003, 0.04341796413064003, 0.04341796413064003, 0.9650352597236633, 0.7289141416549683, 0.5762404203414917, 0.25831466913223267, 0.03974071890115738, 0.01987035945057869, 0.05961107462644577, 0.01987035945057869, 0.01987035945057869, 0.5201018452644348, 0.1300254613161087, 0.0780152752995491, 0.1820356547832489, 0.0260050930082798, 0.0520101860165596, 0.7387563586235046, 0.7383396625518799, 0.4632359445095062, 0.09264719486236572, 0.27794158458709717, 0.09264719486236572, 0.9434770345687866, 0.1828080415725708, 0.7312321662902832, 0.7230993509292603, 0.6404389142990112, 0.14779359102249146, 0.01642150990664959, 0.06568603962659836, 0.01642150990664959, 0.0821075513958931, 0.01642150990664959, 0.7386866211891174, 0.3461892306804657, 0.3461892306804657, 0.20615015923976898, 0.6184504628181458, 0.9444759488105774, 0.8339595794677734, 0.1340046375989914, 0.5092176198959351, 0.02680092677474022, 0.08040278404951096, 0.05360185354948044, 0.10720370709896088, 0.10720370709896088, 0.7699217796325684, 0.08883712440729141, 0.059224750846624374, 0.029612375423312187, 0.08883712440729141, 0.26378321647644043, 0.26378321647644043, 0.39567482471466064, 0.7981970906257629, 0.3474677801132202, 0.1737338900566101, 0.1737338900566101, 0.3474677801132202, 0.6174021363258362, 0.09878434240818024, 0.13582846522331238, 0.09878434240818024, 0.01234804280102253, 0.02469608560204506, 0.01234804280102253, 0.9297734498977661, 0.6037055253982544, 0.11577913910150528, 0.05788956955075264, 0.049619629979133606, 0.09923925995826721, 0.03307975456118584, 0.01653987728059292, 0.024809814989566803, 0.9022377133369446, 0.03608950972557068, 0.03608950972557068, 0.03608950972557068, 0.3586939573287964, 0.3586939573287964, 0.8830246925354004, 0.051942627876996994, 0.051942627876996994, 0.7243702411651611, 0.8891676664352417, 0.9649253487586975, 0.49776673316955566, 0.49376413226127625, 0.7386515140533447, 0.9279263615608215, 0.08435694128274918, 0.9280545711517334, 0.551905632019043, 0.2759528160095215, 0.8035882115364075, 0.14610694348812103, 0.43617793917655945, 0.43617793917655945, 0.8891446590423584, 0.8893558382987976, 0.33570894598960876, 0.33570894598960876, 0.7978361248970032, 0.5494791865348816, 0.08791667222976685, 0.1758333444595337, 0.04395833611488342, 0.06593750417232513, 0.02197916805744171, 0.04395833611488342, 0.4339165985584259, 0.30040380358695984, 0.13351279497146606, 0.033378198742866516, 0.033378198742866516, 0.033378198742866516, 0.033378198742866516, 0.4937672019004822, 0.14522691071033478, 0.14522691071033478, 0.4356807470321655, 0.14522691071033478, 0.8123493790626526, 0.13539156317710876, 0.8913770914077759, 0.7228534817695618, 0.4775642156600952, 0.19102567434310913, 0.09551283717155457, 0.09551283717155457, 0.09551283717155457, 0.03183761239051819, 0.9647247195243835, 0.7813741564750671, 0.6539739370346069, 0.08719652891159058, 0.06539739668369293, 0.10899566113948822, 0.021799132227897644, 0.04359826445579529, 0.021799132227897644, 0.021799132227897644, 0.3466387391090393, 0.3466387391090393, 0.6671995520591736, 0.24005849659442902, 0.7201755046844482, 0.7663098573684692, 0.06385915726423264, 0.09578873217105865, 0.03192957863211632, 0.03192957863211632, 0.32400238513946533, 0.12461630254983902, 0.22430934011936188, 0.07476978003978729, 0.024923261255025864, 0.09969304502010345, 0.04984652251005173, 0.07476978003978729, 0.7289846539497375, 0.3621462285518646, 0.3621462285518646, 0.4977795481681824, 0.23402778804302216, 0.23402778804302216, 0.4680555760860443, 0.7243710160255432, 0.9273362755775452, 0.8181946873664856, 0.2045486718416214, 0.9474110007286072, 0.9592055678367615, 0.3465452492237091, 0.3465452492237091, 0.7144849896430969, 0.23816165328025818, 0.25864502787590027, 0.5172900557518005, 0.38043010234832764, 0.40969395637512207, 0.05852770805358887, 0.11705541610717773, 0.029263854026794434, 0.029263854026794434, 0.8894684314727783, 0.942737877368927, 0.722865641117096, 0.7290169596672058, 0.94362872838974, 0.7385050654411316, 0.3203336298465729, 0.25626689195632935, 0.12813344597816467, 0.3203336298465729, 0.890007495880127, 0.8911513686180115, 0.8912283778190613, 0.2000570148229599, 0.26674267649650574, 0.13337133824825287, 0.06668566912412643, 0.26674267649650574, 0.06668566912412643, 0.5049579739570618, 0.2164105623960495, 0.14427371323108673, 0.07213685661554337, 0.19407089054584503, 0.19407089054584503, 0.38814178109169006, 0.19407089054584503, 0.5163251161575317, 0.1434236466884613, 0.11473891884088516, 0.11473891884088516, 0.02868472971022129, 0.05736945942044258, 0.02868472971022129, 0.667245626449585, 0.7231067419052124, 0.9841658473014832, 0.7289590835571289, 0.5300468802452087, 0.1686512678861618, 0.09637215733528137, 0.048186078667640686, 0.07227911800146103, 0.024093039333820343, 0.024093039333820343, 0.024093039333820343, 0.7243800759315491, 0.7289459109306335, 0.7289270162582397, 0.4977872371673584, 0.4968425929546356, 0.23659171164035797, 0.047318343073129654, 0.09463668614625931, 0.023659171536564827, 0.023659171536564827, 0.09463668614625931, 0.25880271196365356, 0.12940135598182678, 0.25880271196365356, 0.25880271196365356, 0.8877663612365723, 0.892215371131897, 0.49379318952560425, 0.8922001719474792, 0.7387242317199707, 0.282879114151001, 0.282879114151001, 0.282879114151001, 0.7386085987091064, 0.7243934869766235, 0.7243978977203369, 0.35276687145233154, 0.08819171786308289, 0.35276687145233154, 0.17638343572616577, 0.08819171786308289, 0.7228786945343018, 0.5737939476966858, 0.2868969738483429, 0.8705424070358276, 0.07254520058631897, 0.9146456718444824, 0.7382605671882629, 0.7289842367172241, 0.3219493627548218, 0.1609746813774109, 0.1609746813774109, 0.3219493627548218, 0.27987638115882874, 0.27987638115882874, 0.27987638115882874, 0.9724268317222595, 0.49205413460731506, 0.29523247480392456, 0.04920541122555733, 0.04920541122555733, 0.09841082245111465, 0.7382529377937317, 0.6811760663986206, 0.16442179679870605, 0.023488828912377357, 0.023488828912377357, 0.023488828912377357, 0.023488828912377357, 0.023488828912377357, 0.023488828912377357, 0.8893266916275024, 0.35111358761787415, 0.5266703963279724, 0.035111360251903534, 0.017555680125951767, 0.017555680125951767, 0.017555680125951767, 0.017555680125951767, 0.9420822262763977, 0.8912981748580933, 0.3815339207649231, 0.3815339207649231, 0.08478531241416931, 0.042392656207084656, 0.042392656207084656, 0.042392656207084656, 0.7561509013175964, 0.6652562022209167, 0.7222632169723511, 0.06018860265612602, 0.18056580424308777, 0.6653800010681152, 0.49363231658935547, 0.3290882110595703, 0.08227205276489258, 0.08227205276489258, 0.2380562424659729, 0.5554645657539368, 0.07935208082199097, 0.07935208082199097, 0.07935208082199097, 0.6159093379974365, 0.1992647796869278, 0.054344940930604935, 0.018114980310201645, 0.018114980310201645, 0.054344940930604935, 0.018114980310201645, 0.89140385389328, 0.5324402451515198, 0.2662201225757599, 0.49772462248802185, 0.45591747760772705, 0.26052427291870117, 0.26052427291870117, 0.06513106822967529, 0.4239826798439026, 0.18170686066150665, 0.302844762802124, 0.060568951070308685, 0.060568951070308685, 0.060568951070308685, 0.5688157677650452, 0.2844078838825226, 0.5072789192199707, 0.4677160084247589, 0.38267672061920166, 0.08503927290439606, 0.04251963645219803, 0.04251963645219803, 0.5937564969062805, 0.1979188174009323, 0.3774310350418091, 0.3178366422653198, 0.03972958028316498, 0.01986479014158249, 0.07945916056632996, 0.05959437042474747, 0.05959437042474747, 0.01986479014158249, 0.09568566828966141, 0.38274267315864563, 0.19137133657932281, 0.09568566828966141, 0.09568566828966141, 0.2870570123195648, 0.14886409044265747, 0.5954563617706299, 0.14886409044265747, 0.9034661054611206, 0.724327564239502, 0.45296233892440796, 0.22648116946220398, 0.22648116946220398, 0.9428754448890686, 0.23362769186496735, 0.7008830904960632, 0.8899754881858826, 0.5350704789161682, 0.14592832326889038, 0.1945710927248001, 0.09728554636240005, 0.04864277318120003, 0.2145543247461319, 0.10727716237306595, 0.10727716237306595, 0.5363858342170715, 0.9308225512504578, 0.8917378187179565, 0.8006690740585327, 0.9536332488059998, 0.08455947041511536, 0.5919163227081299, 0.1691189408302307, 0.08455947041511536, 0.08455947041511536, 0.8881505131721497, 0.5705809593200684, 0.3043098449707031, 0.11411619931459427, 0.5470355153083801, 0.1823451668024063, 0.1823451668024063, 0.4547816216945648, 0.4547816216945648, 0.07014258205890656, 0.1402851641178131, 0.2805703282356262, 0.2805703282356262, 0.07014258205890656, 0.1402851641178131, 0.9293286800384521, 0.050254128873348236, 0.55279541015625, 0.10050825774669647, 0.050254128873348236, 0.2512706518173218, 0.7244167327880859, 0.7996264100074768, 0.21441715955734253, 0.343067467212677, 0.08576686680316925, 0.21441715955734253, 0.042883433401584625, 0.08576686680316925, 0.8030989766120911, 0.6241981983184814, 0.056745290756225586, 0.056745290756225586, 0.11349058151245117, 0.056745290756225586, 0.11349058151245117, 0.7723007202148438, 0.11881549656391144, 0.02970387414097786, 0.05940774828195572, 0.02970387414097786, 0.7289592027664185, 0.08263734728097916, 0.6610987782478333, 0.13772889971733093, 0.013772890903055668, 0.013772890903055668, 0.027545781806111336, 0.04131867364048958, 0.04131867364048958, 0.7387940883636475, 0.9119648337364197, 0.6194478869438171, 0.16894032061100006, 0.05631344020366669, 0.05631344020366669, 0.05631344020366669, 0.11262688040733337, 0.8891685605049133, 0.9476251006126404, 0.21925406157970428, 0.7673892378807068, 0.972247302532196, 0.7243598699569702, 0.7382886409759521, 0.7387768030166626, 0.8995711207389832, 0.2253696471452713, 0.2253696471452713, 0.3004928529262543, 0.07512321323156357, 0.07512321323156357, 0.07512321323156357, 0.07512321323156357, 0.07512321323156357, 0.3985225260257721, 0.1328408420085907, 0.3985225260257721, 0.7228859663009644, 0.9394614100456238, 0.029358169063925743, 0.16273821890354156, 0.8136911392211914, 0.8895419836044312, 0.9723217487335205, 0.7382931709289551, 0.5761142373085022, 0.06777814775705338, 0.16944536566734314, 0.03388907387852669, 0.03388907387852669, 0.10166721791028976, 0.26908963918685913, 0.26908963918685913, 0.26908963918685913, 0.891464114189148, 0.1613994538784027, 0.1613994538784027, 0.1613994538784027, 0.1613994538784027, 0.48419836163520813, 0.7288954854011536, 0.26245835423469543, 0.4499286115169525, 0.1499761939048767, 0.03749404847621918, 0.03749404847621918, 0.03749404847621918, 0.03749404847621918, 0.4922950267791748, 0.14491669833660126, 0.4347500801086426, 0.14491669833660126, 0.2898333966732025, 0.6368286609649658, 0.3184143304824829, 0.05306905880570412, 0.4285028278827667, 0.17140112817287445, 0.08570056408643723, 0.25710171461105347, 0.08570056408643723, 0.3137865960597992, 0.20919106900691986, 0.10459553450345993, 0.10459553450345993, 0.1568932980298996, 0.052297767251729965, 0.052297767251729965, 0.27756673097610474, 0.27756673097610474, 0.27756673097610474, 0.8215740323066711, 0.03042866662144661, 0.045643001794815063, 0.015214333310723305, 0.015214333310723305, 0.03042866662144661, 0.045643001794815063, 0.4817928075790405, 0.21413013339042664, 0.10706506669521332, 0.10706506669521332, 0.10706506669521332, 0.7383325695991516, 0.5749056935310364, 0.2874528467655182, 0.6617993712425232, 0.21312183141708374, 0.03365081548690796, 0.011216938495635986, 0.044867753982543945, 0.022433876991271973, 0.011216938495635986, 0.7228286862373352, 0.9019446969032288, 0.7227765917778015, 0.663529098033905, 0.14291396737098694, 0.061248842626810074, 0.05614477023482323, 0.015312210656702518, 0.02552035078406334, 0.015312210656702518, 0.02041628025472164, 0.7104994654655457, 0.06089995428919792, 0.06089995428919792, 0.020299986004829407, 0.040599972009658813, 0.040599972009658813, 0.040599972009658813, 0.040599972009658813, 0.8807039856910706, 0.11207028478384018, 0.11207028478384018, 0.6724216938018799, 0.49236610531806946, 0.4811531901359558, 0.0962306410074234, 0.1924612820148468, 0.1924612820148468, 0.0962306410074234, 0.7231298685073853, 0.7387515902519226, 0.8914156556129456, 0.738825261592865, 0.37589946389198303, 0.34172677993774414, 0.03417268022894859, 0.20503607392311096, 0.03417268022894859, 0.49211159348487854, 0.2722886800765991, 0.21783095598220825, 0.1633732169866562, 0.05445773899555206, 0.05445773899555206, 0.10891547799110413, 0.1633732169866562, 0.547846257686615, 0.2739231288433075, 0.9428907036781311, 0.9509634375572205, 0.2862153649330139, 0.19081023335456848, 0.09540511667728424, 0.2862153649330139, 0.09540511667728424, 0.09540511667728424, 0.2678854465484619, 0.2678854465484619, 0.2678854465484619, 0.253027081489563, 0.506054162979126, 0.7030437588691711, 0.0540802888572216, 0.1622408628463745, 0.0540802888572216, 0.5420778393745422, 0.40655839443206787, 0.02710389345884323, 0.02710389345884323, 0.02710389345884323, 0.7704932689666748, 0.16051943600177765, 0.0642077773809433, 0.03210388869047165, 0.6640074253082275, 0.22133581340312958, 0.11066790670156479, 0.7289623022079468, 0.4371654689311981, 0.11922693997621536, 0.1987115740776062, 0.03974231332540512, 0.03974231332540512, 0.03974231332540512, 0.11922693997621536, 0.6630532741546631, 0.11050888150930405, 0.2210177630186081, 0.5375526547431946, 0.09773684293031693, 0.09773684293031693, 0.04886842146515846, 0.04886842146515846, 0.14660526812076569, 0.04886842146515846, 0.7231255769729614, 0.2031322866678238, 0.744818389415741, 0.0677107647061348, 0.9648941159248352, 0.25251540541648865, 0.5050308108329773, 0.185695618391037, 0.185695618391037, 0.5570868849754333, 0.7231096625328064, 0.6702943444252014, 0.8914086222648621, 0.724332332611084, 0.9281943440437317, 0.1687864363193512, 0.4219660758972168, 0.0843932181596756, 0.1687864363193512, 0.0843932181596756, 0.0843932181596756, 0.8922492265701294, 0.6671785116195679, 0.7229506969451904, 0.8912897706031799, 0.657853901386261, 0.3289269506931305, 0.2757352292537689, 0.5514704585075378, 0.5201950073242188, 0.1486271470785141, 0.037156786769628525, 0.1486271470785141, 0.037156786769628525, 0.037156786769628525, 0.07431357353925705, 0.037156786769628525, 0.7243306636810303, 0.4934176206588745, 0.6068918704986572, 0.12137837707996368, 0.24275675415992737, 0.7227962017059326, 0.8964414596557617, 0.05602759122848511, 0.3350622057914734, 0.3350622057914734, 0.7244148254394531, 0.7711896896362305, 0.02142193540930748, 0.04284387081861496, 0.04284387081861496, 0.06426580995321274, 0.02142193540930748, 0.04284387081861496, 0.02142193540930748, 0.3514084219932556, 0.3514084219932556, 0.9422735571861267, 0.7244141101837158, 0.6093714833259583, 0.13541588187217712, 0.06770794093608856, 0.10156191140413284, 0.03385397046804428, 0.03385397046804428, 0.03385397046804428, 0.8876214623451233, 0.6675347089767456, 0.14391030371189117, 0.7195515036582947, 0.7243855595588684, 0.4977698028087616, 0.7243853807449341, 0.4852180480957031, 0.2043023258447647, 0.2043023258447647, 0.02553779073059559, 0.07661337405443192, 0.7243300080299377, 0.5071038007736206, 0.7386725544929504, 0.7244208455085754, 0.6009507179260254, 0.16693075001239777, 0.06677230447530746, 0.03338615223765373, 0.03338615223765373, 0.03338615223765373, 0.06677230447530746, 0.8190369009971619, 0.034126535058021545, 0.034126535058021545, 0.034126535058021545, 0.06825307011604309, 0.7385962009429932, 0.7385647296905518, 0.27781563997268677, 0.5556312799453735, 0.14311130344867706, 0.7155565619468689, 0.7971174120903015, 0.7559239268302917, 0.3652975857257843, 0.32515498995780945, 0.09232795983552933, 0.03612833097577095, 0.06824240833520889, 0.040142592042684555, 0.03612833097577095, 0.032114073634147644, 0.5223610401153564, 0.1424621045589447, 0.09497474133968353, 0.11871842294931412, 0.023743685334920883, 0.023743685334920883, 0.047487370669841766, 0.023743685334920883, 0.6824266910552979, 0.22747555375099182, 0.49233636260032654, 0.8655091524124146, 0.4056659936904907, 0.10141649842262268, 0.4056659936904907, 0.10141649842262268, 0.9285020232200623, 0.7228251099586487, 0.4926193952560425, 0.7398987412452698, 0.1726430356502533, 0.0493265837430954, 0.0246632918715477, 0.0246632918715477, 0.9217349290847778, 0.23177647590637207, 0.3244870901107788, 0.046355295926332474, 0.3708423674106598, 0.799440324306488, 0.8913776278495789, 0.5637509822845459, 0.21682730317115784, 0.043365463614463806, 0.043365463614463806, 0.08673092722892761, 0.043365463614463806, 0.5151023864746094, 0.2575511932373047, 0.4457719624042511, 0.16716448962688446, 0.05572149530053139, 0.05572149530053139, 0.3343289792537689, 0.7386391162872314, 0.29182061553001404, 0.5836412310600281, 0.23780515789985657, 0.23780515789985657, 0.23780515789985657, 0.11890257894992828, 0.023780517280101776, 0.04756103456020355, 0.07134155184030533, 0.023780517280101776, 0.9552873969078064, 0.3972286283969879, 0.5958428978919983, 0.8912869095802307, 0.10803734511137009, 0.75626140832901, 0.7484171986579895, 0.7996208071708679, 0.7387542724609375, 0.9278037548065186, 0.765602707862854, 0.667156457901001, 0.4079829156398773, 0.2549893260002136, 0.2549893260002136, 0.050997864454984665, 0.33771130442619324, 0.33771130442619324, 0.7243691682815552, 0.5070982575416565, 0.7830537557601929, 0.04121335595846176, 0.04121335595846176, 0.08242671191692352, 0.04121335595846176, 0.04121335595846176, 0.2590196132659912, 0.2590196132659912, 0.2590196132659912, 0.9011192917823792, 0.09011192619800568, 0.7387586832046509, 0.7228461503982544, 0.968683123588562, 0.511922299861908, 0.127980574965477, 0.07678834348917007, 0.051192231476306915, 0.07678834348917007, 0.10238446295261383, 0.025596115738153458, 0.28625667095184326, 0.3435079753398895, 0.057251330465078354, 0.057251330465078354, 0.057251330465078354, 0.057251330465078354, 0.11450266093015671, 0.873089611530304, 0.803162157535553, 0.19248215854167938, 0.7699286341667175, 0.5805324912071228, 0.13659587502479553, 0.03414896875619888, 0.13659587502479553, 0.03414896875619888, 0.06829793751239777, 0.6372249722480774, 0.07771036028862, 0.062168288975954056, 0.07771036028862, 0.07771036028862, 0.062168288975954056, 0.015542072243988514, 0.4494521915912628, 0.2247260957956314, 0.3370891511440277, 0.43127235770225525, 0.21563617885112762, 0.21563617885112762, 0.3495609164237976, 0.1747804582118988, 0.3495609164237976, 0.0873902291059494, 0.0436951145529747, 0.7659820914268494, 0.10942601412534714, 0.03647533804178238, 0.03647533804178238, 0.03647533804178238, 0.03647533804178238, 0.4980411231517792], \"Term\": [\"abbasid\", \"academic\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"account\", \"account\", \"account\", \"account\", \"activity\", \"activity\", \"activity\", \"activity\", \"actor\", \"additionally\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"advantage\", \"advantage\", \"advantage\", \"agent\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"annotation\", \"annotation\", \"annotation\", \"annotation\", \"annotation\", \"annotation\", \"apply\", \"apply\", \"apply\", \"apply\", \"apply\", \"apply\", \"apply\", \"approximately\", \"approximately\", \"archival\", \"archival\", \"arise\", \"arise\", \"arise\", \"artefact\", \"artefact\", \"artifact\", \"attach\", \"attach\", \"attempt\", \"attempt\", \"attempt\", \"attest\", \"attestation\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"background\", \"background\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"begin\", \"behaviour\", \"bibliographic\", \"bibliographic\", \"bibliographic\", \"bit\", \"book\", \"book\", \"book\", \"book\", \"bookkeepe\", \"bug\", \"build\", \"build\", \"build\", \"build\", \"build\", \"build\", \"bundle\", \"capacity\", \"category\", \"category\", \"category\", \"cayless\", \"certain\", \"certain\", \"certain\", \"certain\", \"change\", \"change\", \"change\", \"change\", \"change\", \"character\", \"character\", \"character\", \"character\", \"character\", \"check\", \"chichester\", \"chinese\", \"christian\", \"chronological\", \"citation\", \"classification\", \"close\", \"close\", \"cmif\", \"cognitive\", \"collaborative\", \"collection\", \"collection\", \"collection\", \"collection\", \"collection\", \"collection\", \"collection\", \"comity\", \"compare\", \"compare\", \"compare\", \"compare\", \"compliance\", \"complicate\", \"component\", \"component\", \"component\", \"condition\", \"conference\", \"conference\", \"connection\", \"connection\", \"consequential\", \"consideration\", \"consideration\", \"content\", \"content\", \"content\", \"content\", \"content\", \"correctly\", \"correctly\", \"correspdesc\", \"correspondence\", \"correspondence\", \"correspondence\", \"correspondence\", \"correspondence\", \"country\", \"country\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"current\", \"current\", \"current\", \"current\", \"current\", \"custom\", \"customization\", \"customization\", \"customization\", \"customization\", \"database\", \"database\", \"database\", \"database\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"debate\", \"debate\", \"debate\", \"default\", \"deletion\", \"denote\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"description\", \"description\", \"description\", \"description\", \"description\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"diagnostic\", \"dialogic\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"digitally\", \"digitisation\", \"discussion\", \"discussion\", \"discussion\", \"discussion\", \"distant_reade\", \"distinctive_feature\", \"distinctive_feature\", \"doctrinal\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document\", \"docx\", \"domain\", \"domain\", \"dramatic\", \"dramatic\", \"dynamic\", \"edge\", \"edition\", \"edition\", \"edition\", \"edition\", \"edition\", \"edition\", \"edition\", \"editor\", \"editor\", \"editor\", \"editor\", \"editor\", \"editorial\", \"editorial\", \"editorial\", \"egxml\", \"electronic\", \"electronic\", \"electronic\", \"electronic\", \"element\", \"element\", \"element\", \"element\", \"element\", \"element\", \"element\", \"eltec\", \"encode\", \"encode\", \"encode\", \"encode\", \"encode\", \"encode\", \"encode\", \"encode\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoding_initiative\", \"encoding_initiative\", \"end\", \"end\", \"end\", \"enforce\", \"engage\", \"entire\", \"enumerate\", \"eoa\", \"epistemology\", \"error\", \"error\", \"european\", \"evaluate\", \"evaluate\", \"event\", \"event\", \"evidence\", \"evidence\", \"evolution\", \"evolve\", \"exactly\", \"exactly\", \"examine\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"experimental\", \"explore\", \"explore\", \"explore\", \"explore\", \"fair\", \"fair\", \"fairly\", \"fall\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"female\", \"fig\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"financial\", \"financial\", \"findable\", \"footnote\", \"footnote\", \"form\", \"form\", \"form\", \"form\", \"form\", \"format\", \"format\", \"format\", \"format\", \"format\", \"format\", \"format\", \"format\", \"fortunately\", \"freely\", \"freely\", \"fromthepage\", \"functional\", \"functional\", \"functional\", \"funde\", \"genetic\", \"geographical\", \"geographical\", \"gloss\", \"graph\", \"graz\", \"graz\", \"group\", \"group\", \"guide\", \"guide\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"haaf\", \"haentjen\", \"handbook\", \"hassle\", \"header\", \"heavily\", \"high\", \"high\", \"high\", \"high\", \"highlighting\", \"highly\", \"hinkelmann\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"history\", \"history\", \"history\", \"history\", \"hold\", \"hold\", \"hold\", \"hold\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"iip\", \"illustrious\", \"image\", \"impressive\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"incomplete\", \"indian\", \"indology\", \"informal\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"infrastructure\", \"infrastructure\", \"infrastructure\", \"infrastructure\", \"inscription\", \"intentional\", \"interaction\", \"interlinear\", \"intermediate\", \"interpretation\", \"interpretation\", \"interpretation\", \"interpretative\", \"interpretive\", \"interreligious\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"invite\", \"japanese\", \"japanese\", \"label\", \"label\", \"latex\", \"launch\", \"lawyer\", \"layer\", \"layer\", \"layer\", \"layer\", \"lead\", \"lead\", \"lead\", \"less\", \"letter\", \"letter\", \"letter\", \"letter\", \"letter\", \"lettre\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"lifecycle\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"lineation\", \"lining\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"linkable\", \"lite\", \"literary\", \"literary\", \"literary\", \"log\", \"look\", \"look\", \"look\", \"look\", \"main\", \"main\", \"main\", \"main\", \"main\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"maker\", \"manual\", \"manual\", \"mapping\", \"material\", \"material\", \"material\", \"material\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mechanism\", \"mechanism\", \"medieval\", \"method\", \"method\", \"method\", \"method\", \"method\", \"methodology\", \"methodology\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modern\", \"modern\", \"modern\", \"modern\", \"modern\", \"modern\", \"module\", \"module\", \"module\", \"mold\", \"monograph\", \"moreover\", \"moreover\", \"moreover\", \"motive\", \"music\", \"music\", \"namespace\", \"need\", \"need\", \"need\", \"need\", \"need\", \"network\", \"network\", \"network\", \"network\", \"night\", \"notation\", \"notational\", \"novel\", \"object\", \"object\", \"object\", \"object\", \"object\", \"objectification\", \"odd\", \"odd\", \"odd\", \"old\", \"old\", \"old\", \"ongoing\", \"ongoing\", \"online\", \"online\", \"online\", \"online\", \"online\", \"online\", \"ontological\", \"ontology\", \"ontology\", \"ontology\", \"ontology\", \"ontology\", \"oral\", \"orcid\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"outline\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"page\", \"page\", \"page\", \"page\", \"page\", \"pain\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paradigm\", \"parliamentary\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"partnership\", \"pedagogy\", \"performance\", \"performance\", \"periodical\", \"phenomena\", \"philological\", \"philology\", \"phonetic\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"platform\", \"platform\", \"platform\", \"playhouse\", \"poem\", \"poem\", \"pointer\", \"pointer\", \"poorly\", \"population\", \"port\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"powerful\", \"powerful\", \"powerful\", \"precede\", \"prepare\", \"prepare\", \"prepare\", \"prepare\", \"prepare\", \"prerequisite\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"press\", \"primary_source\", \"primary_source\", \"primary_source\", \"primary_source\", \"principle\", \"principle\", \"principle\", \"print\", \"print\", \"print\", \"print\", \"print\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problematic\", \"problematic\", \"problematic\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"produce\", \"produce\", \"produce\", \"produce\", \"produce\", \"profile\", \"program\", \"program\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"prompt\", \"promptbook\", \"prompter\", \"pron\", \"pron\", \"pron\", \"pron\", \"pron\", \"pron\", \"pron\", \"pron\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"punctuation\", \"quality\", \"quality\", \"quality\", \"quarterly\", \"question\", \"question\", \"question\", \"question\", \"question\", \"raise\", \"readability\", \"realist\", \"recognize\", \"record\", \"record\", \"record\", \"record\", \"record\", \"recreate\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"refine\", \"refine\", \"registration\", \"regular_expression\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"relax\", \"relax\", \"relax\", \"rend\", \"rend\", \"rendition\", \"rendition\", \"rendition\", \"rendition\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"require\", \"require\", \"require\", \"require\", \"requirement\", \"requirement\", \"requirement\", \"rescue\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"researcher\", \"researcher\", \"researcher\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"reuse\", \"revision\", \"revision\", \"revision\", \"rhyme\", \"rigorous\", \"rigorous\", \"role\", \"role\", \"role\", \"sakya\", \"sale\", \"satlow\", \"schemata\", \"scheme\", \"scholar\", \"scholar\", \"scholar\", \"scholar\", \"scholar\", \"scholar\", \"school\", \"searchable\", \"seifert\", \"semantic_web\", \"server\", \"server\", \"session\", \"session\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shortcome\", \"sig\", \"sign\", \"sign\", \"sign\", \"simulate\", \"site\", \"site\", \"situation\", \"situation\", \"solicit\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"span\", \"span\", \"speak\", \"spear\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"stage_direction\", \"stance\", \"standardized\", \"standardized\", \"stategie\", \"statistic\", \"strict\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"subsequent\", \"subsequently\", \"substitute\", \"syriac\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"tangle\", \"taste\", \"taxonomy\", \"taxonomy\", \"teach\", \"teach\", \"teaching\", \"teidata\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"textual\", \"textual\", \"textual\", \"textual\", \"textual\", \"textual\", \"textual\", \"textual\", \"textuality\", \"textuality\", \"theatrical\", \"theatrical_performance\", \"theory\", \"theory\", \"theory\", \"theory\", \"third\", \"thread\", \"tibetan\", \"time\", \"time\", \"time\", \"time\", \"time\", \"title\", \"token\", \"token\", \"token\", \"token\", \"tokenize\", \"tokenized\", \"tool\", \"tool\", \"tool\", \"tool\", \"tool\", \"tool\", \"transform\", \"transform\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"travel\", \"tutorial\", \"tutorial\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"typically\", \"typology\", \"typology\", \"unary\", \"uncertainty\", \"uncertainty\", \"underdeveloped\", \"underline\", \"universal\", \"update\", \"uri\", \"usable\", \"user\", \"user\", \"user\", \"user\", \"utilise\", \"utilise\", \"vague\", \"valuable\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"vary\", \"vary\", \"vary\", \"view\", \"view\", \"vyvoje\", \"watch\", \"watermark\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"web\", \"web\", \"web\", \"web\", \"web\", \"web\", \"web\", \"weight\", \"winnifre\", \"wish\", \"wish\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workshop\", \"workshop\", \"workshop\", \"world\", \"world\", \"world\", \"write\", \"write\", \"write\", \"write\", \"write\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xsl\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 2, 8, 4, 5, 1, 7, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el34181404518837940088045166998\", ldavis_el34181404518837940088045166998_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el34181404518837940088045166998\", ldavis_el34181404518837940088045166998_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el34181404518837940088045166998\", ldavis_el34181404518837940088045166998_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "5     -0.016189 -0.021801       1        1  50.396423\n",
       "1      0.013174 -0.129239       2        1  17.013510\n",
       "7      0.025221 -0.047690       3        1   7.693998\n",
       "3     -0.161904  0.025068       4        1   7.204810\n",
       "4      0.068049  0.051465       5        1   4.719015\n",
       "0      0.066537  0.046859       6        1   4.509253\n",
       "6     -0.000815  0.067541       7        1   4.432286\n",
       "2      0.005926  0.007796       8        1   4.030705, topic_info=        Term        Freq       Total Category  logprob  loglift\n",
       "145     text  249.000000  249.000000  Default  30.0000  30.0000\n",
       "27    encode  120.000000  120.000000  Default  29.0000  29.0000\n",
       "47     paper   72.000000   72.000000  Default  28.0000  28.0000\n",
       "628      odd   26.000000   26.000000  Default  27.0000  27.0000\n",
       "72      work   64.000000   64.000000  Default  26.0000  26.0000\n",
       "..       ...         ...         ...      ...      ...      ...\n",
       "393   output    1.926012   17.622608   Topic8  -5.5992   0.9975\n",
       "395     part    1.925634   17.757750   Topic8  -5.5994   0.9897\n",
       "223   system    1.937777   29.952539   Topic8  -5.5931   0.4732\n",
       "197   letter    1.929139   20.322968   Topic8  -5.5976   0.8566\n",
       "416  provide    1.940299   49.261120   Topic8  -5.5918  -0.0231\n",
       "\n",
       "[550 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "2250      6  0.724413   abbasid\n",
       "76        3  0.889573  academic\n",
       "228       1  0.445743    access\n",
       "228       2  0.173344    access\n",
       "228       3  0.198108    access\n",
       "...     ...       ...       ...\n",
       "154       4  0.036475       xml\n",
       "154       6  0.036475       xml\n",
       "154       7  0.036475       xml\n",
       "154       8  0.036475       xml\n",
       "2378      7  0.498041       xsl\n",
       "\n",
       "[1150 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 2, 8, 4, 5, 1, 7, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Mallet Model ##\n",
    "\n",
    "### Passage de l'algorithme de Gensim à celui de Mallet ###\n",
    "\n",
    "Pour la suite, nous utiliserons l'algorithme de topic modeling de Mallet plutôt que celui proposé par Gensim. Bien que Gensim offre une meilleure approche de Topic Modeling, car chaque étape est bien séparée et peut être personnalisée (nettoyage de la donnée ou *preprocessing*, construction et paramètrage du modèle de Topic Modeling), l'algorithme de Topic Modeling proposé par Mallet est un peu plus précis que celui de Gensim, en offrant notamment une meilleure qualité de sujets.\n",
    "\n",
    "En 2014 Radim Řehůřek, créateur de Gensim, a créé un Wrapper permettant d'utiliser l'algorithme de Mallet. Nous allons donc télécharger les dossiers de Mallet depuis GitHub et utiliser ce wrapper pour utiliser l'algorithme de Mallet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les Topics mesurés seront légèrement différents. Tout d'abord, il faut télécharger Mallet dans le cache :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./cache2019/Mallet'):\n",
    "    git.Git(\"./cache2019\").clone(\"https://github.com/mimno/Mallet.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Important___ : Il faut maintenant utiliser le terminal pour aller dans ./cache2019/Mallet et taper simplement la commande \" ant \" (rendu possible suite à votre installation de Ant Apache comme indiqué dans le README). Cela permet de compiler le script Java de Mallet. Si le terminal affiche \"Building Successfully\", vous pouvez passer à l'étape suivante, c'est à dire implémenter l'algorithme de LDA Mallet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = \"./cache2019/Mallet/bin/mallet\"\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=8, id2word=id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "Si une erreur se déclenche, c'est que vous n'avez pas compilé manuellement le script Java de Mallet. Allez dans cache2019/Mallet, ouvrez votre terminal et tapez simplement \" ant \". Relancez ensuite la cellule, cela fonctionnera normalement à chaque lancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('encode', 0.049026676279740444),\n",
      "   ('line', 0.04037490987743331),\n",
      "   ('pron', 0.03821196827685652),\n",
      "   ('form', 0.024513338139870222),\n",
      "   ('word', 0.023071377072819033),\n",
      "   ('set', 0.01658255227108868),\n",
      "   ('number', 0.015861571737563085),\n",
      "   ('part', 0.014419610670511895),\n",
      "   ('find', 0.0136986301369863),\n",
      "   ('simple', 0.012256669069935111)]),\n",
      " (1,\n",
      "  [('element', 0.04788732394366197),\n",
      "   ('pron', 0.04056338028169014),\n",
      "   ('text', 0.028169014084507043),\n",
      "   ('level', 0.02028169014084507),\n",
      "   ('source', 0.01915492957746479),\n",
      "   ('provide', 0.017464788732394366),\n",
      "   ('work', 0.015211267605633802),\n",
      "   ('collection', 0.015211267605633802),\n",
      "   ('make', 0.012957746478873239),\n",
      "   ('language', 0.012394366197183098)]),\n",
      " (2,\n",
      "  [('pron', 0.041595441595441596),\n",
      "   ('process', 0.038746438746438745),\n",
      "   ('project', 0.02678062678062678),\n",
      "   ('build', 0.02678062678062678),\n",
      "   ('poem', 0.019943019943019943),\n",
      "   ('time', 0.019943019943019943),\n",
      "   ('rhyme', 0.019373219373219373),\n",
      "   ('tag', 0.018233618233618232),\n",
      "   ('xml', 0.017094017094017096),\n",
      "   ('page', 0.017094017094017096)]),\n",
      " (3,\n",
      "  [('format', 0.03955696202531646),\n",
      "   ('include', 0.0379746835443038),\n",
      "   ('create', 0.03560126582278481),\n",
      "   ('editor', 0.029272151898734177),\n",
      "   ('write', 0.021360759493670885),\n",
      "   ('document', 0.01977848101265823),\n",
      "   ('order', 0.01819620253164557),\n",
      "   ('edition', 0.01740506329113924),\n",
      "   ('web', 0.015822784810126583),\n",
      "   ('component', 0.015822784810126583)]),\n",
      " (4,\n",
      "  [('text', 0.1324599708879185),\n",
      "   ('model', 0.03420669577874818),\n",
      "   ('represent', 0.020378457059679767),\n",
      "   ('annotation', 0.018195050946142648),\n",
      "   ('ontology', 0.018195050946142648),\n",
      "   ('token', 0.018195050946142648),\n",
      "   ('edition', 0.017467248908296942),\n",
      "   ('representation', 0.013828238719068414),\n",
      "   ('technology', 0.013100436681222707),\n",
      "   ('structure', 0.013100436681222707)]),\n",
      " (5,\n",
      "  [('datum', 0.05274888558692422),\n",
      "   ('encode', 0.029717682020802376),\n",
      "   ('file', 0.02526002971768202),\n",
      "   ('specific', 0.02451708766716196),\n",
      "   ('project', 0.023031203566121844),\n",
      "   ('access', 0.020059435364041606),\n",
      "   ('digital', 0.019316493313521546),\n",
      "   ('provide', 0.017830609212481426),\n",
      "   ('database', 0.017830609212481426),\n",
      "   ('system', 0.01634472511144131)]),\n",
      " (6,\n",
      "  [('text', 0.047619047619047616),\n",
      "   ('guideline', 0.03050595238095238),\n",
      "   ('textual', 0.02976190476190476),\n",
      "   ('work', 0.027529761904761904),\n",
      "   ('encode', 0.024553571428571428),\n",
      "   ('develop', 0.020833333333333332),\n",
      "   ('base', 0.017857142857142856),\n",
      "   ('letter', 0.01711309523809524),\n",
      "   ('access', 0.015625),\n",
      "   ('online', 0.014136904761904762)]),\n",
      " (7,\n",
      "  [('paper', 0.0703883495145631),\n",
      "   ('description', 0.03398058252427184),\n",
      "   ('type', 0.029935275080906147),\n",
      "   ('feature', 0.02912621359223301),\n",
      "   ('record', 0.02831715210355987),\n",
      "   ('information', 0.025080906148867314),\n",
      "   ('structure', 0.020226537216828478),\n",
      "   ('pron', 0.0186084142394822),\n",
      "   ('datum', 0.0186084142394822),\n",
      "   ('user', 0.01779935275080906)])]\n"
     ]
    }
   ],
   "source": [
    "# Voici les \"nouveaux\" topics calculés par Mallet\n",
    "pprint(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons comparer le score de cohérence de ces algorithmes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score of LDA Mallet :  0.33404972464874566\n",
      "\n",
      "Coherence Score of LDA Gensim :  0.26502737897608397\n"
     ]
    }
   ],
   "source": [
    "# Je calcule le score de cohérence de Mallet\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score of LDA Mallet : ', coherence_ldamallet)\n",
    "\n",
    "# Je calcule le score de Gensim\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score of LDA Gensim : ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, Mallet est légèrement meilleur que Gensim. Il y a donc un certain intérêt à continuer avec Mallet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critique du choix du nombre de clusters ###\n",
    "\n",
    "Nous allons ici voir si le nombre de clusters choisi est vraiment représentatif et optimal. Pour calculer cela, nous nous baserons sur la \" cohérence \", un coefficient calculé par l'ordinateur. Tout d'abord, nous créons une fonction permettant de calculer la cohérence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Calcule la cohérence c_v pour un nombre variable de topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Dictionnaire de Gensim\n",
    "    corpus : Corpus de Gensim\n",
    "    texts : Liste des corpus\n",
    "    limit : Nombre maximum de corpus\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : Liste des modèles de topic LDA topic\n",
    "    coherence_values : Valeur de la cohérence correspondance au model de LDA et son nombre de topics respectif\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis nous cherchons à voir si cela est vraiment cohérent. Nous appliquons cette fonction au corpus. La fonction lancée ci-dessous va attribuer à chaque \"model_list\", une élément propre à Gensim regroupant la liste des topics attribués à un corpus (élément copié sur celui de Mallet mais avec cet avantage de ne pas stocker dans la RAM les textes, allégeant grandement le processus) la variable \"coherence_values\" qui est une liste constituée de nombres décimaux représentant la cohérence de chaque topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peut prendre du temps\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis nous affichons le résultat sous la forme d'un graphique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Nombre de Topics\")\n",
    "plt.ylabel(\"Score de cohérence\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons qu'il y a un pic à 8 topics, un autre à 20, puis à partir de 32 topics le score de cohérence monte en flèche. Le pic à 8 topics est intéressant, car c'est le nombre de \" topics \" différents proposés lors de la Conférence TEI 2019. L'augmentation finale permet cependant de comprendre que les abstracts restent relativement peu liés les uns aux autres, et que le nombre optimal de topics pour l'ordinateur serait d'un topic par abstract..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous affichons ici ensuite le score de cohérence précis pour une suite de nombre de topics, pour avoir une vision plus précise : par exemple, il est légèrement mieux d'avoir 8 topics que 20 topics, ce qui conforte l'idée que les abstracts sont guidés par 8 sujets différents, ceux attribués par les organisateurs de la conférence TEI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de Topics = 2  a une valeur de cohérence de :  0.2864\n",
      "Nombre de Topics = 8  a une valeur de cohérence de :  0.321\n",
      "Nombre de Topics = 14  a une valeur de cohérence de :  0.3466\n",
      "Nombre de Topics = 20  a une valeur de cohérence de :  0.3764\n",
      "Nombre de Topics = 26  a une valeur de cohérence de :  0.364\n",
      "Nombre de Topics = 32  a une valeur de cohérence de :  0.3869\n",
      "Nombre de Topics = 38  a une valeur de cohérence de :  0.4148\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Nombre de Topics =\", m, \" a une valeur de cohérence de : \", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voir les topics ###\n",
    "\n",
    "La cellule ci-dessous permet d'afficher pour chaque topic (représenté par un nombre entier) les 10 mots-clés représentant le mieux ce topic, et un facteur attribué à chacun de ces mots permettant de voir l'importance de chaque mot-clé au sein du cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.157*\"text\" + 0.043*\"model\" + 0.034*\"edition\" + 0.019*\"represent\" + '\n",
      "  '0.018*\"ontology\" + 0.018*\"annotation\" + 0.015*\"base\" + 0.014*\"scholarly\" + '\n",
      "  '0.014*\"representation\" + 0.013*\"technology\"'),\n",
      " (1,\n",
      "  '0.067*\"paper\" + 0.043*\"line\" + 0.034*\"type\" + 0.032*\"description\" + '\n",
      "  '0.027*\"record\" + 0.026*\"structure\" + 0.024*\"pron\" + 0.020*\"information\" + '\n",
      "  '0.015*\"editor\" + 0.015*\"feature\"'),\n",
      " (2,\n",
      "  '0.035*\"encode\" + 0.027*\"include\" + 0.026*\"write\" + 0.024*\"resource\" + '\n",
      "  '0.021*\"web\" + 0.020*\"text\" + 0.020*\"event\" + 0.017*\"markup\" + '\n",
      "  '0.017*\"history\" + 0.016*\"single\"'),\n",
      " (3,\n",
      "  '0.054*\"encode\" + 0.034*\"format\" + 0.029*\"access\" + 0.022*\"word\" + '\n",
      "  '0.019*\"provide\" + 0.018*\"follow\" + 0.017*\"form\" + 0.016*\"problem\" + '\n",
      "  '0.016*\"information\" + 0.015*\"order\"'),\n",
      " (4,\n",
      "  '0.064*\"datum\" + 0.057*\"project\" + 0.044*\"document\" + 0.034*\"file\" + '\n",
      "  '0.030*\"create\" + 0.028*\"digital\" + 0.028*\"database\" + 0.023*\"system\" + '\n",
      "  '0.019*\"work\" + 0.016*\"approach\"'),\n",
      " (5,\n",
      "  '0.050*\"element\" + 0.042*\"pron\" + 0.034*\"text\" + 0.025*\"level\" + '\n",
      "  '0.021*\"work\" + 0.017*\"odd\" + 0.015*\"collection\" + 0.015*\"provide\" + '\n",
      "  '0.014*\"source\" + 0.012*\"language\"'),\n",
      " (6,\n",
      "  '0.052*\"pron\" + 0.033*\"process\" + 0.026*\"build\" + 0.025*\"time\" + '\n",
      "  '0.020*\"poem\" + 0.019*\"rhyme\" + 0.018*\"tag\" + 0.016*\"encoder\" + 0.016*\"long\" '\n",
      "  '+ 0.015*\"page\"'),\n",
      " (7,\n",
      "  '0.034*\"guideline\" + 0.028*\"textual\" + 0.023*\"develop\" + 0.021*\"research\" + '\n",
      "  '0.021*\"encode\" + 0.019*\"letter\" + 0.018*\"present\" + 0.017*\"exist\" + '\n",
      "  '0.015*\"online\" + 0.015*\"humanity\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = model_list[1] #optimal_model et model_list sont des éléments gensim contenant les topics et les textes. \n",
    "#Model_list est la liste des modèles de nombres de topics et la distribution interne donnée ci-dessus. Comme le modèle le plus efficace est\n",
    "#celui à 8 topics, je le sélectionne\n",
    "model_topics = optimal_model.show_topics(formatted=False) #Model_topics est une liste produite par la méthode show_topics.\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation ###\n",
    "\n",
    "Nous allons produire sous la forme d'un tableau le sujet dominant de chaque texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document n°</th>\n",
       "      <th>Topic dominant n°</th>\n",
       "      <th>Pourcentage de Contribution au topic</th>\n",
       "      <th>Mots-clés</th>\n",
       "      <th>Texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>use machine learn for the Automated Classifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2728</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>TEI XML and Delta Format Interchangeability TE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3281</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>correspsearch v2 – new way of explore correspo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>get along with Relational Databases Background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>introduce objectification : when be an &lt; objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>analyze and Visualizing Uncertain Knowledge : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3669</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>reference an editorial ontology from the TEI :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>case Study TEI Customization : a restrict TEI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>element, pron, text, level, work, odd, collect...</td>\n",
       "      <td>in search of comity : TEI for distant read Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>reconceive TEI model of theatrical performance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2392</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>model FRBR entity and -PRON- Relationships wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>scale up automatic Structuring of Manuscript S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>recreate history through event recreate histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>highlight -PRON- example : encode xml example ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>element, pron, text, level, work, odd, collect...</td>\n",
       "      <td>grow collection of TEI text : some lesson from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>pron, process, build, time, poem, rhyme, tag, ...</td>\n",
       "      <td>how -PRON- triple -PRON- encode speed in the  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>a TEI customization for the description of pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>reference annotation as a core concept of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2789</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>make linkable Data from Account Books : Bookke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5306</td>\n",
       "      <td>pron, process, build, time, poem, rhyme, tag, ...</td>\n",
       "      <td>the Prefabricated website : who need a server ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>refine the Current Teaching Methodology of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>explore TEI structure to find distinctive feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5383</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>advantage and challenge of tokenized TEI Advan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2049</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>Manuscripta - the editor from past to future M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3213</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>native - TEI dialectal dictionary for bavarian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4407</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>archive a TEI project fairly archive a TEI pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4823</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>an encode strategic proposal of \" Ruby \" text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3709</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>TEI encoding of correspondence : a community e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3569</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>an Attempt of Dissemination of TEI in a TEI - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2041</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>encode history in TEI : a corpus - orient appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>text Graph Ontology . a Semantic Web approach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3346</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>Genesis and Variance : from Letter to Literatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>five century of history in a network how shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>a sign of the time : medieval punctuation , -P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>reflect the influence of Technology on model o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>validate @selector : a regular expression adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3335</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>use Microsoft Word for prepare XML TEI - compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2927</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>inscription , Hieroglyphs , Linguistics … and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>create high - quality print from TEI document ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3531</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>what be a line ? encode and counting Lines in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>element, pron, text, level, work, odd, collect...</td>\n",
       "      <td>towards large corpus of Indic text : for now ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>use Github and -PRON- integration to create , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4146</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>introduce an open , dynamic and Efficient Lexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2601</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>Parla - CLARIN : TEI guideline for corpus of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>challenge in encode parliamentary datum : betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>a realistic theory of textuality and -PRON- co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document n°  Topic dominant n°  Pourcentage de Contribution au topic  \\\n",
       "0             0                1.0                                0.2985   \n",
       "1             1                3.0                                0.2728   \n",
       "2             2                7.0                                0.3281   \n",
       "3             3                4.0                                0.4004   \n",
       "4             4                7.0                                0.3140   \n",
       "5             5                7.0                                0.2526   \n",
       "6             6                7.0                                0.3669   \n",
       "7             7                3.0                                0.1790   \n",
       "8             8                5.0                                0.4965   \n",
       "9             9                7.0                                0.3809   \n",
       "10           10                0.0                                0.2392   \n",
       "11           11                7.0                                0.1652   \n",
       "12           12                2.0                                0.3059   \n",
       "13           13                1.0                                0.2383   \n",
       "14           14                5.0                                0.2575   \n",
       "15           15                6.0                                0.5911   \n",
       "16           16                1.0                                0.6777   \n",
       "17           17                7.0                                0.2319   \n",
       "18           18                2.0                                0.2789   \n",
       "19           19                6.0                                0.5306   \n",
       "20           20                7.0                                0.5536   \n",
       "21           21                1.0                                0.3035   \n",
       "22           22                3.0                                0.5383   \n",
       "23           23                4.0                                0.2049   \n",
       "24           24                4.0                                0.3213   \n",
       "25           25                4.0                                0.4407   \n",
       "26           26                2.0                                0.4823   \n",
       "27           27                7.0                                0.3709   \n",
       "28           28                2.0                                0.3569   \n",
       "29           29                2.0                                0.2041   \n",
       "30           30                0.0                                0.6337   \n",
       "31           31                7.0                                0.3346   \n",
       "32           32                2.0                                0.2738   \n",
       "33           33                2.0                                0.2673   \n",
       "34           34                0.0                                0.2823   \n",
       "35           35                2.0                                0.2736   \n",
       "36           36                3.0                                0.3335   \n",
       "37           37                0.0                                0.2927   \n",
       "38           38                4.0                                0.4595   \n",
       "39           39                1.0                                0.3531   \n",
       "40           40                5.0                                0.1609   \n",
       "41           41                4.0                                0.2634   \n",
       "42           42                3.0                                0.4146   \n",
       "43           43                2.0                                0.2601   \n",
       "44           44                3.0                                0.4153   \n",
       "45           45                0.0                                0.2661   \n",
       "\n",
       "                                            Mots-clés  \\\n",
       "0   paper, line, type, description, record, struct...   \n",
       "1   encode, format, access, word, provide, follow,...   \n",
       "2   guideline, textual, develop, research, encode,...   \n",
       "3   datum, project, document, file, create, digita...   \n",
       "4   guideline, textual, develop, research, encode,...   \n",
       "5   guideline, textual, develop, research, encode,...   \n",
       "6   guideline, textual, develop, research, encode,...   \n",
       "7   encode, format, access, word, provide, follow,...   \n",
       "8   element, pron, text, level, work, odd, collect...   \n",
       "9   guideline, textual, develop, research, encode,...   \n",
       "10  text, model, edition, represent, ontology, ann...   \n",
       "11  guideline, textual, develop, research, encode,...   \n",
       "12  encode, include, write, resource, web, text, e...   \n",
       "13  paper, line, type, description, record, struct...   \n",
       "14  element, pron, text, level, work, odd, collect...   \n",
       "15  pron, process, build, time, poem, rhyme, tag, ...   \n",
       "16  paper, line, type, description, record, struct...   \n",
       "17  guideline, textual, develop, research, encode,...   \n",
       "18  encode, include, write, resource, web, text, e...   \n",
       "19  pron, process, build, time, poem, rhyme, tag, ...   \n",
       "20  guideline, textual, develop, research, encode,...   \n",
       "21  paper, line, type, description, record, struct...   \n",
       "22  encode, format, access, word, provide, follow,...   \n",
       "23  datum, project, document, file, create, digita...   \n",
       "24  datum, project, document, file, create, digita...   \n",
       "25  datum, project, document, file, create, digita...   \n",
       "26  encode, include, write, resource, web, text, e...   \n",
       "27  guideline, textual, develop, research, encode,...   \n",
       "28  encode, include, write, resource, web, text, e...   \n",
       "29  encode, include, write, resource, web, text, e...   \n",
       "30  text, model, edition, represent, ontology, ann...   \n",
       "31  guideline, textual, develop, research, encode,...   \n",
       "32  encode, include, write, resource, web, text, e...   \n",
       "33  encode, include, write, resource, web, text, e...   \n",
       "34  text, model, edition, represent, ontology, ann...   \n",
       "35  encode, include, write, resource, web, text, e...   \n",
       "36  encode, format, access, word, provide, follow,...   \n",
       "37  text, model, edition, represent, ontology, ann...   \n",
       "38  datum, project, document, file, create, digita...   \n",
       "39  paper, line, type, description, record, struct...   \n",
       "40  element, pron, text, level, work, odd, collect...   \n",
       "41  datum, project, document, file, create, digita...   \n",
       "42  encode, format, access, word, provide, follow,...   \n",
       "43  encode, include, write, resource, web, text, e...   \n",
       "44  encode, format, access, word, provide, follow,...   \n",
       "45  text, model, edition, represent, ontology, ann...   \n",
       "\n",
       "                                                Texte  \n",
       "0   use machine learn for the Automated Classifica...  \n",
       "1   TEI XML and Delta Format Interchangeability TE...  \n",
       "2   correspsearch v2 – new way of explore correspo...  \n",
       "3   get along with Relational Databases Background...  \n",
       "4   introduce objectification : when be an < objec...  \n",
       "5   analyze and Visualizing Uncertain Knowledge : ...  \n",
       "6   reference an editorial ontology from the TEI :...  \n",
       "7   case Study TEI Customization : a restrict TEI ...  \n",
       "8   in search of comity : TEI for distant read Int...  \n",
       "9   reconceive TEI model of theatrical performance...  \n",
       "10  model FRBR entity and -PRON- Relationships wit...  \n",
       "11  scale up automatic Structuring of Manuscript S...  \n",
       "12  recreate history through event recreate histor...  \n",
       "13  highlight -PRON- example : encode xml example ...  \n",
       "14  grow collection of TEI text : some lesson from...  \n",
       "15  how -PRON- triple -PRON- encode speed in the  ...  \n",
       "16  a TEI customization for the description of pap...  \n",
       "17  reference annotation as a core concept of the ...  \n",
       "18  make linkable Data from Account Books : Bookke...  \n",
       "19  the Prefabricated website : who need a server ...  \n",
       "20  refine the Current Teaching Methodology of the...  \n",
       "21  explore TEI structure to find distinctive feat...  \n",
       "22  advantage and challenge of tokenized TEI Advan...  \n",
       "23  Manuscripta - the editor from past to future M...  \n",
       "24  native - TEI dialectal dictionary for bavarian...  \n",
       "25  archive a TEI project fairly archive a TEI pro...  \n",
       "26  an encode strategic proposal of \" Ruby \" text ...  \n",
       "27  TEI encoding of correspondence : a community e...  \n",
       "28  an Attempt of Dissemination of TEI in a TEI - ...  \n",
       "29  encode history in TEI : a corpus - orient appr...  \n",
       "30  text Graph Ontology . a Semantic Web approach ...  \n",
       "31  Genesis and Variance : from Letter to Literatu...  \n",
       "32  five century of history in a network how shoul...  \n",
       "33  a sign of the time : medieval punctuation , -P...  \n",
       "34  reflect the influence of Technology on model o...  \n",
       "35  validate @selector : a regular expression adve...  \n",
       "36  use Microsoft Word for prepare XML TEI - compl...  \n",
       "37  inscription , Hieroglyphs , Linguistics … and ...  \n",
       "38  create high - quality print from TEI document ...  \n",
       "39  what be a line ? encode and counting Lines in ...  \n",
       "40  towards large corpus of Indic text : for now ,...  \n",
       "41  use Github and -PRON- integration to create , ...  \n",
       "42  introduce an open , dynamic and Efficient Lexi...  \n",
       "43  Parla - CLARIN : TEI guideline for corpus of p...  \n",
       "44  challenge in encode parliamentary datum : betw...  \n",
       "45  a realistic theory of textuality and -PRON- co...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=documents):\n",
    "    # Iniatilise la sortie en un tableau pandas\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Récupère le sujet principal de chaque document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        #Récupère pour chaque document le sujet dominant, le pourcentage de contribution à ce sujet et les mots-clés\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Ajout du titre dans la dernière colonne en prenant les premiers mots de chaque texte\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=documents)\n",
    "\n",
    "# Mise en place du tableau\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document n°', 'Topic dominant n°', 'Pourcentage de Contribution au topic', 'Mots-clés', 'Texte']\n",
    "\n",
    "# Affiche le tableau en présentant seulement les 10 premiers textes. Changez le chiffre 10 si vous le souhaitez pour obtenir l'étude de plus de textes.\n",
    "df_dominant_topic.head(46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons remarquer que le modèle représenté fonctionnerait autour d'un texte central souvent très représentatif pour chaque cluster.\n",
    "Cependant, chaque abstract est lié par une petite base solide à son topic (minimum 15%), ce qui indique que les textes ne sont pas totalement séparés les uns et des autres, et donc qu'une certaine thématique générale (bien évidemment la TEI) les relie.\n",
    "\n",
    "La cohérence thématique entre tous ces abstracts n'est donc pas très profonde, et bien souvent il semblerait que la thématique d'un groupe d'abstract ne représenterait réellement qu'un seul abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chercher les abstracts les plus représentatifs ###\n",
    "\n",
    "Nous pouvons alors chercher à sortir les abstracts les plus représentatifs de chaque topic :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic n°</th>\n",
       "      <th>Pourcentage de contribution à un topic</th>\n",
       "      <th>Mots-Clés</th>\n",
       "      <th>Texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>text Graph Ontology . a Semantic Web approach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>a TEI customization for the description of pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4823</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>an encode strategic proposal of \" Ruby \" text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5383</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>advantage and challenge of tokenized TEI Advan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>create high - quality print from TEI document ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>element, pron, text, level, work, odd, collect...</td>\n",
       "      <td>in search of comity : TEI for distant read Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>pron, process, build, time, poem, rhyme, tag, ...</td>\n",
       "      <td>how -PRON- triple -PRON- encode speed in the  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>refine the Current Teaching Methodology of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic n°  Pourcentage de contribution à un topic  \\\n",
       "0       0.0                                  0.6337   \n",
       "1       1.0                                  0.6777   \n",
       "2       2.0                                  0.4823   \n",
       "3       3.0                                  0.5383   \n",
       "4       4.0                                  0.4595   \n",
       "5       5.0                                  0.4965   \n",
       "6       6.0                                  0.5911   \n",
       "7       7.0                                  0.5536   \n",
       "\n",
       "                                           Mots-Clés  \\\n",
       "0  text, model, edition, represent, ontology, ann...   \n",
       "1  paper, line, type, description, record, struct...   \n",
       "2  encode, include, write, resource, web, text, e...   \n",
       "3  encode, format, access, word, provide, follow,...   \n",
       "4  datum, project, document, file, create, digita...   \n",
       "5  element, pron, text, level, work, odd, collect...   \n",
       "6  pron, process, build, time, poem, rhyme, tag, ...   \n",
       "7  guideline, textual, develop, research, encode,...   \n",
       "\n",
       "                                               Texte  \n",
       "0  text Graph Ontology . a Semantic Web approach ...  \n",
       "1  a TEI customization for the description of pap...  \n",
       "2  an encode strategic proposal of \" Ruby \" text ...  \n",
       "3  advantage and challenge of tokenized TEI Advan...  \n",
       "4  create high - quality print from TEI document ...  \n",
       "5  in search of comity : TEI for distant read Int...  \n",
       "6  how -PRON- triple -PRON- encode speed in the  ...  \n",
       "7  refine the Current Teaching Methodology of the...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic n°', \"Pourcentage de contribution à un topic\", \"Mots-Clés\", \"Texte\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La théorie formulée précédemment semble se vérifier : certains abstracts incarnent à eux seuls leur topic.\n",
    "\n",
    "Cependant, les résultats que nous venons de voir montrent aussi que les topics restent représentatifs et cohérents : globalement chaque abstract fait participe à son Topic à hauteur d'au moins 20%, et aucun abstract ne dépasse les 70% de participation au topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Des topics égaux ? ###\n",
    "\n",
    "Nous allons maintenant regarder le nombre de documents par topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N° du topic</th>\n",
       "      <th>Mots-clés du topic</th>\n",
       "      <th>Nombre de documents relevant de ce topic</th>\n",
       "      <th>Proportion des documents parfaitement représentatifs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>element, pron, text, level, work, odd, collect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>element, pron, text, level, work, odd, collect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>pron, process, build, time, poem, rhyme, tag, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>pron, process, build, time, poem, rhyme, tag, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>guideline, textual, develop, research, encode,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>paper, line, type, description, record, struct...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>element, pron, text, level, work, odd, collect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>datum, project, document, file, create, digita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>encode, include, write, resource, web, text, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>encode, format, access, word, provide, follow,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>text, model, edition, represent, ontology, ann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      N° du topic                                 Mots-clés du topic  \\\n",
       "0.0           1.0  paper, line, type, description, record, struct...   \n",
       "1.0           3.0  encode, format, access, word, provide, follow,...   \n",
       "2.0           7.0  guideline, textual, develop, research, encode,...   \n",
       "3.0           4.0  datum, project, document, file, create, digita...   \n",
       "4.0           7.0  guideline, textual, develop, research, encode,...   \n",
       "5.0           7.0  guideline, textual, develop, research, encode,...   \n",
       "6.0           7.0  guideline, textual, develop, research, encode,...   \n",
       "7.0           3.0  encode, format, access, word, provide, follow,...   \n",
       "8.0           5.0  element, pron, text, level, work, odd, collect...   \n",
       "9.0           7.0  guideline, textual, develop, research, encode,...   \n",
       "10.0          0.0  text, model, edition, represent, ontology, ann...   \n",
       "11.0          7.0  guideline, textual, develop, research, encode,...   \n",
       "12.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "13.0          1.0  paper, line, type, description, record, struct...   \n",
       "14.0          5.0  element, pron, text, level, work, odd, collect...   \n",
       "15.0          6.0  pron, process, build, time, poem, rhyme, tag, ...   \n",
       "16.0          1.0  paper, line, type, description, record, struct...   \n",
       "17.0          7.0  guideline, textual, develop, research, encode,...   \n",
       "18.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "19.0          6.0  pron, process, build, time, poem, rhyme, tag, ...   \n",
       "20.0          7.0  guideline, textual, develop, research, encode,...   \n",
       "21.0          1.0  paper, line, type, description, record, struct...   \n",
       "22.0          3.0  encode, format, access, word, provide, follow,...   \n",
       "23.0          4.0  datum, project, document, file, create, digita...   \n",
       "24.0          4.0  datum, project, document, file, create, digita...   \n",
       "25.0          4.0  datum, project, document, file, create, digita...   \n",
       "26.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "27.0          7.0  guideline, textual, develop, research, encode,...   \n",
       "28.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "29.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "30.0          0.0  text, model, edition, represent, ontology, ann...   \n",
       "31.0          7.0  guideline, textual, develop, research, encode,...   \n",
       "32.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "33.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "34.0          0.0  text, model, edition, represent, ontology, ann...   \n",
       "35.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "36.0          3.0  encode, format, access, word, provide, follow,...   \n",
       "37.0          0.0  text, model, edition, represent, ontology, ann...   \n",
       "38.0          4.0  datum, project, document, file, create, digita...   \n",
       "39.0          1.0  paper, line, type, description, record, struct...   \n",
       "40.0          5.0  element, pron, text, level, work, odd, collect...   \n",
       "41.0          4.0  datum, project, document, file, create, digita...   \n",
       "42.0          3.0  encode, format, access, word, provide, follow,...   \n",
       "43.0          2.0  encode, include, write, resource, web, text, e...   \n",
       "44.0          3.0  encode, format, access, word, provide, follow,...   \n",
       "45.0          0.0  text, model, edition, represent, ontology, ann...   \n",
       "\n",
       "      Nombre de documents relevant de ce topic  \\\n",
       "0.0                                        5.0   \n",
       "1.0                                        5.0   \n",
       "2.0                                        9.0   \n",
       "3.0                                        6.0   \n",
       "4.0                                        6.0   \n",
       "5.0                                        3.0   \n",
       "6.0                                        2.0   \n",
       "7.0                                       10.0   \n",
       "8.0                                        NaN   \n",
       "9.0                                        NaN   \n",
       "10.0                                       NaN   \n",
       "11.0                                       NaN   \n",
       "12.0                                       NaN   \n",
       "13.0                                       NaN   \n",
       "14.0                                       NaN   \n",
       "15.0                                       NaN   \n",
       "16.0                                       NaN   \n",
       "17.0                                       NaN   \n",
       "18.0                                       NaN   \n",
       "19.0                                       NaN   \n",
       "20.0                                       NaN   \n",
       "21.0                                       NaN   \n",
       "22.0                                       NaN   \n",
       "23.0                                       NaN   \n",
       "24.0                                       NaN   \n",
       "25.0                                       NaN   \n",
       "26.0                                       NaN   \n",
       "27.0                                       NaN   \n",
       "28.0                                       NaN   \n",
       "29.0                                       NaN   \n",
       "30.0                                       NaN   \n",
       "31.0                                       NaN   \n",
       "32.0                                       NaN   \n",
       "33.0                                       NaN   \n",
       "34.0                                       NaN   \n",
       "35.0                                       NaN   \n",
       "36.0                                       NaN   \n",
       "37.0                                       NaN   \n",
       "38.0                                       NaN   \n",
       "39.0                                       NaN   \n",
       "40.0                                       NaN   \n",
       "41.0                                       NaN   \n",
       "42.0                                       NaN   \n",
       "43.0                                       NaN   \n",
       "44.0                                       NaN   \n",
       "45.0                                       NaN   \n",
       "\n",
       "      Proportion des documents parfaitement représentatifs  \n",
       "0.0                                              0.1087     \n",
       "1.0                                              0.1087     \n",
       "2.0                                              0.1957     \n",
       "3.0                                              0.1304     \n",
       "4.0                                              0.1304     \n",
       "5.0                                              0.0652     \n",
       "6.0                                              0.0435     \n",
       "7.0                                              0.2174     \n",
       "8.0                                                 NaN     \n",
       "9.0                                                 NaN     \n",
       "10.0                                                NaN     \n",
       "11.0                                                NaN     \n",
       "12.0                                                NaN     \n",
       "13.0                                                NaN     \n",
       "14.0                                                NaN     \n",
       "15.0                                                NaN     \n",
       "16.0                                                NaN     \n",
       "17.0                                                NaN     \n",
       "18.0                                                NaN     \n",
       "19.0                                                NaN     \n",
       "20.0                                                NaN     \n",
       "21.0                                                NaN     \n",
       "22.0                                                NaN     \n",
       "23.0                                                NaN     \n",
       "24.0                                                NaN     \n",
       "25.0                                                NaN     \n",
       "26.0                                                NaN     \n",
       "27.0                                                NaN     \n",
       "28.0                                                NaN     \n",
       "29.0                                                NaN     \n",
       "30.0                                                NaN     \n",
       "31.0                                                NaN     \n",
       "32.0                                                NaN     \n",
       "33.0                                                NaN     \n",
       "34.0                                                NaN     \n",
       "35.0                                                NaN     \n",
       "36.0                                                NaN     \n",
       "37.0                                                NaN     \n",
       "38.0                                                NaN     \n",
       "39.0                                                NaN     \n",
       "40.0                                                NaN     \n",
       "41.0                                                NaN     \n",
       "42.0                                                NaN     \n",
       "43.0                                                NaN     \n",
       "44.0                                                NaN     \n",
       "45.0                                                NaN     "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permet de calculer le nombre de documents par topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Proportion des documents étant parfaitement représentatif du topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# N° du topic et mot-clés\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Lie les colonnes\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Renomme les colonnes\n",
    "df_dominant_topics.columns = ['N° du topic', 'Mots-clés du topic', 'Nombre de documents relevant de ce topic', 'Proportion des documents parfaitement représentatifs']\n",
    "\n",
    "# Représentation\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nous pouvons conclure qu'en regardant la faible proportion des documents représentés dans les topics, les abstracts restent quand même bien différents les uns des autres, une grande diversité prédomine en réalité dans ces abstracts, bien qu'une trame de fonds les relient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

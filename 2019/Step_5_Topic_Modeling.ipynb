{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEI Conference 2019 #\n",
    "\n",
    "## Etape 5 : Topic Modeling ##\n",
    "\n",
    "Jusqu'à maintenant, nous avons fait de la classification non supervisée, où l'ordinateur distribuait librement chaque document en fonction de la répartition de ses mots.\n",
    "\n",
    "Nous allons ici développer un peu cela en faisant du topic modeling : cette fois-ci, chaque mot est assimilé à un sujet (ou plus précisément à une variété de sujets dont la proximité est donnée sous la forme d'une coefficient relatif à chacun des sujets), et l'addition de chacun de ces coefficients pour chaque mot détermine pour chaque abstract un sujet (ou plutôt une liste de thèmes dont la proximité est indiquée sous la forme d'un coefficient). Grâce à cela, on peut déterminer des clusters fondés non plus la répétitivité de certains termes ou de certaines constructions, mais sur les champs lexicaux utilisés.\n",
    "\n",
    "Nous nous appuierons pour cela sur divers librairies qu'il convient d'importer.\n",
    "\n",
    "## Les packages ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# SpaCy pour la lemmatisation\n",
    "import spacy\n",
    "\n",
    "# Librairies pour la représentation en schéma\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Active le chargement pour Gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "#Permet d'utiliser LDA Mallet dans la seconde partie de l'analyse\n",
    "import git\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les stopwords ##\n",
    "\n",
    "Je définis des stopwords, c'est à dire la liste de mots qui ne doivent pas être pris en compte, ces mots étant généralement des mots grammaticaux. Les mots grammaticaux sont généralement très nombreux mais portent un très faible poids sémantique. Il faut donc les retirer pour éviter qu'ils n'occultent les autres mots à cause de leur surreprésentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use']) #permet d'ajouter certains termes que j'ai décrété"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choisir son corpus ##\n",
    "\n",
    "Il faut activer l'une des deux cellules (au choix) pour charger en mémoire le corpus traité de la manière que vous voulez.\n",
    "\n",
    "Le meilleur choix pour un premier test est de choisir le texte lemmatisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './cache2019/cacheSTEM/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-24416f703eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./cache2019/cacheSTEM/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#filelist est une liste regroupant tous les chemins vers les différents abstracts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mabstract\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cache2019/cacheSTEM/'"
     ]
    }
   ],
   "source": [
    "#Pour utiliser les textes stemmés, c'est ici\n",
    "import os\n",
    "documents = []\n",
    "Path = \"./cache2019/cacheSTEM/\"\n",
    "filelist = os.listdir(Path) #filelist est une liste regroupant tous les chemins vers les différents abstracts.\n",
    "\n",
    "for abstract in filelist:\n",
    "    with open(Path + abstract, \"r\", encoding=\"UTF-8\") as y:\n",
    "        texte = y.read()\n",
    "        documents.append(texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour utiliser les textes lemmatisés, c'est ici\n",
    "import os\n",
    "documents = []\n",
    "Path = \"./cache2019/cacheLEM/\"\n",
    "filelist = os.listdir(Path) #filelist est une liste regroupant tous les chemins vers les différents abstracts.\n",
    "\n",
    "for abstract in filelist:\n",
    "    with open(Path + abstract, \"r\", encoding=\"UTF-8\") as y:\n",
    "        texte = y.read()\n",
    "        documents.append(texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling partie 1 : définir des topic ##\n",
    "\n",
    "### Séquençage et nettoyage ###\n",
    "\n",
    "Tout d'abord, je définis une fonction qui séquence chaque abstract en mot et retire la ponctuation. C'est l'étape du préprocessing, c'est à dire formatter le document afin de le rendre lisible par gensim. Gensim a sa propre méthode de séquençage, que nous utiliserons. Nous avons déjà lemmatisé les documents, mais il est utile de le refaire, car cette fois-ci nous utiliserons le lemmatiseur intégré à Gensim, qui permet alors de rendre un document utilisable par Gensim.\n",
    "\n",
    "Chaque document, sous la forme d'une str, devient une liste de str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['use', 'machine', 'learn', 'for', 'the', 'automated', 'classification', 'of', 'stage', 'directions', 'in', 'tei', 'encode', 'drama', 'corpora', 'authors', 'daria', 'maximova', 'national', 'research', 'university', 'higher', 'school', 'of', 'economics', 'moscow', 'ru', 'frank', 'fischer', 'dariah', 'eu', 'and', 'national', 'research', 'university', 'higher', 'school', 'of', 'economics', 'moscow', 'ru', 'abstract', 'the', 'stage', 'tag', 'be', 'core', 'element', 'for', 'the', 'encoding', 'of', 'drama', 'the', 'tei', 'guideline', 'suggest', 'nine', 'value', 'for', 'pron', 'type', 'attribute', 'which', 'be', 'widely', 'use', 'in', 'large', 'corpus', 'such', 'as', 'the', 'french', 'theatre', 'classique', 'the', 'shakespeare', 'folger', 'library', 'or', 'the', 'swedish', 'dramawebben', 'this', 'paper', 'introduce', 'an', 'approach', 'to', 'automatically', 'assign', 'stage', 'direction', 'type', 'to', 'the', 'tei', 'encoded', 'russian', 'drama', 'corpus', 'rusdracor', 'https', 'dracor', 'org', 'the', 'corpu', 'currently', 'feature', 'play', 'range', 'from', 'mid', 'th', 'to', 'mid', 'th', 'century', 'which', 'make', 'for', 'stage', 'direction', 'with', 'token', 'pron', 'select', 'play', 'comprise', 'stage', 'direction', 'to', 'represent', 'the', 'breadth', 'of', 'the', 'corpus', 'for', 'the', 'manual', 'annotation', 'pron', 'establish', 'clear', 'set', 'of', 'rule', 'to', 'identify', 'the', 'stage', 'direction', 'type', 'propose', 'by', 'the', 'tei', 'guideline', 'https', 'www', 'tei', 'org', 'release', 'doc', 'tei', 'doc', 'en', 'html', 'ref', 'stage', 'html', 'follow', 'the', 'annotation', 'of', 'pron', 'subcorpu', 'pron', 'develop', 'tool', 'for', 'the', 'classification', 'of', 'the', 'remain', 'play', 'without', 'human', 'interference', 'for', 'the', 'conversion', 'of', 'stage', 'direction', 'into', 'feature', 'vector', 'pron', 'use', 'morphological', 'and', 'semantic', 'datum', 'pron', 'tool', 'in', 'pron', 'current', 'state', 'be', 'able', 'to', 'classify', 'different', 'type', 'with', 'an', 'score', 'of', 'approx', 'which', 'mean', 'that', 'out', 'of', 'stage', 'direction', 'of', 'any', 'give', 'type', 'be', 'assign', 'correctly', 'pron', 'work', 'will', 'inform', 'dedicated', 'analysis', 'of', 'stage', 'direction', 'which', 'after', 'preliminary', 'study', 'by', 'sperantov', 'and', 'detken', 'will', 'be', 'base', 'on', 'large', 'corpus', 'allow', 'for', 'description', 'of', 'the', 'evolvement', 'of', 'stage', 'direction', 'over', 'year']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(documents):\n",
    "    for document in documents:\n",
    "        yield(gensim.utils.simple_preprocess(str(document), deacc=True))  # deacc=True retire la ponctuation\n",
    "\n",
    "data_words = list(sent_to_words(documents)) #je lemmatise les abstracts et les stock dans une variable\n",
    "\n",
    "print(data_words[:1]) #Voici à quoi ressemble un extrait du corpus lemmatisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire les bigrammes et les trigrammes ###\n",
    "\n",
    "Nous allons maintenant construire les bigrammes et les trigrammes, c'est à dire rassembler les mots par groupe de 2 ou 3 en fonction de leur ressemblance sémantique, permettant de dégager ainsi des débuts de regroupement.\n",
    "\n",
    "Nous créons donc les modèles pour créer les bigrammes et les trigrammes, qui donnent une liste de mots assignés à chaque mot un à un. Nous testons à la fin un exemple de la liste de mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use', 'machine', 'learn', 'for', 'the', 'automated', 'classification', 'of', 'stage', 'directions', 'in', 'tei', 'encode', 'drama', 'corpora', 'authors', 'daria', 'maximova', 'national', 'research', 'university', 'higher', 'school', 'of', 'economics', 'moscow', 'ru', 'frank', 'fischer', 'dariah', 'eu', 'and', 'national', 'research', 'university', 'higher', 'school', 'of', 'economics', 'moscow', 'ru', 'abstract', 'the', 'stage', 'tag', 'be', 'core', 'element', 'for', 'the', 'encoding', 'of', 'drama', 'the', 'tei', 'guideline', 'suggest', 'nine', 'value', 'for', 'pron', 'type', 'attribute', 'which', 'be', 'widely', 'use', 'in', 'large', 'corpus', 'such', 'as', 'the', 'french', 'theatre', 'classique', 'the', 'shakespeare', 'folger', 'library', 'or', 'the', 'swedish', 'dramawebben', 'this', 'paper', 'introduce', 'an', 'approach', 'to', 'automatically', 'assign', 'stage_direction', 'type', 'to', 'the', 'tei', 'encoded', 'russian', 'drama', 'corpus', 'rusdracor', 'https', 'dracor', 'org', 'the', 'corpu', 'currently', 'feature', 'play', 'range', 'from', 'mid', 'th', 'to', 'mid', 'th_century', 'which', 'make', 'for', 'stage_direction', 'with', 'token', 'pron', 'select', 'play', 'comprise', 'stage_direction', 'to', 'represent', 'the', 'breadth', 'of', 'the', 'corpus', 'for', 'the', 'manual', 'annotation', 'pron', 'establish', 'clear', 'set', 'of', 'rule', 'to', 'identify', 'the', 'stage_direction', 'type', 'propose', 'by', 'the', 'tei', 'guideline', 'https_www', 'tei', 'org', 'release', 'doc', 'tei', 'doc', 'en', 'html', 'ref', 'stage', 'html', 'follow', 'the', 'annotation', 'of', 'pron', 'subcorpu', 'pron', 'develop', 'tool', 'for', 'the', 'classification', 'of', 'the', 'remain', 'play', 'without', 'human', 'interference', 'for', 'the', 'conversion', 'of', 'stage_direction', 'into', 'feature', 'vector', 'pron', 'use', 'morphological', 'and', 'semantic', 'datum', 'pron', 'tool', 'in', 'pron', 'current_state', 'be', 'able', 'to', 'classify', 'different', 'type', 'with', 'an', 'score', 'of', 'approx', 'which', 'mean', 'that', 'out', 'of', 'stage_direction', 'of', 'any', 'give', 'type', 'be', 'assign', 'correctly', 'pron', 'work', 'will', 'inform', 'dedicated', 'analysis', 'of', 'stage_direction', 'which', 'after', 'preliminary', 'study', 'by', 'sperantov', 'and', 'detken', 'will', 'be', 'base', 'on', 'large', 'corpus', 'allow', 'for', 'description', 'of', 'the', 'evolvement', 'of', 'stage_direction', 'over', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Construit les modèles bigramme et trigramme\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # plus le paramètre threshold est haut, plus il est difficile de construire des groupes de mots\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# On applique la méthode et les modèles dans une variable\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Un exemple d'une trigrammes avec le premier mot.\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous insérons ensuite les modèles dans des fonctions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis ensuite nous l'appliquons à notre set de textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['machine', 'learn', 'automate', 'classification', 'stage', 'direction', 'encode', 'high', 'school', 'economic', 'high', 'school', 'economic', 'abstract', 'stage', 'tag', 'core', 'element', 'encode', 'drama', 'guideline', 'suggest', 'value', 'pron', 'type', 'attribute', 'widely', 'large', 'paper', 'introduce', 'approach', 'automatically', 'assign', 'stage_direction', 'type', 'encode', 'russian', 'drama', 'currently', 'feature', 'play', 'range', 'mid', 'make', 'stage_direction', 'token', 'select', 'play', 'comprise', 'stage_direction', 'represent', 'manual', 'annotation', 'pron', 'establish', 'clear', 'set', 'rule', 'identify', 'stage_direction', 'type', 'propose', 'guideline', 'stage', 'develop', 'tool', 'classification', 'remain', 'play', 'human', 'interference', 'conversion', 'stage_direction', 'feature', 'vector', 'morphological', 'able', 'classify', 'different', 'type', 'score', 'approx', 'mean', 'stage_direction', 'give', 'type', 'assign', 'correctly', 'pron', 'work', 'inform', 'dedicated', 'analysis', 'stage_direction', 'preliminary', 'study', 'sperantov', 'base', 'large', 'allow', 'description', 'evolvement', 'stage_direction', 'year']]\n"
     ]
    }
   ],
   "source": [
    "# On retire les stop words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# On forme les bigrammes\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# On lemmatise le texte grâce à spacy. J'utilise le corpus d'entraînement le plus petit à notre disposition.\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Je ne lemmatise qu'en ne gardant les noms, les adjectifs, les verbes et les adverbes\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Exemple du résultat sur le premier abstract\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, les mots de chaque texte sont encodés sous la forme de tuple où le premier entier est son identifiant et où le second est son nombre d'occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 2), (27, 1), (28, 3), (29, 1), (30, 1), (31, 2), (32, 1), (33, 2), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 3), (50, 1), (51, 3), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 3), (64, 8), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 5), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Je crée le dictionnaire dans lequel est stocké chaque mot différent en clé et un identifiant (nombre entier) en valeur\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# J'associe le corpus à une variable lemmatisé\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Je crée une liste avec à l'intérieur une liste de deux entiers où le premier représente un mot (la valeur de la clé du dictionnaire id2word) et le second est son nombre d'occurence\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Visualisation un peu barbare sur le premier corpus\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux le comprendre, voici une visualisation adaptée à un être humain :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('able', 1),\n",
       "  ('abstract', 1),\n",
       "  ('allow', 1),\n",
       "  ('analysis', 1),\n",
       "  ('annotation', 1),\n",
       "  ('approach', 1),\n",
       "  ('approx', 1),\n",
       "  ('assign', 2),\n",
       "  ('attribute', 1),\n",
       "  ('automate', 1),\n",
       "  ('automatically', 1),\n",
       "  ('base', 1),\n",
       "  ('classification', 2),\n",
       "  ('classify', 1),\n",
       "  ('clear', 1),\n",
       "  ('comprise', 1),\n",
       "  ('conversion', 1),\n",
       "  ('core', 1),\n",
       "  ('correctly', 1),\n",
       "  ('currently', 1),\n",
       "  ('dedicated', 1),\n",
       "  ('description', 1),\n",
       "  ('develop', 1),\n",
       "  ('different', 1),\n",
       "  ('direction', 1),\n",
       "  ('drama', 2),\n",
       "  ('economic', 2),\n",
       "  ('element', 1),\n",
       "  ('encode', 3),\n",
       "  ('establish', 1),\n",
       "  ('evolvement', 1),\n",
       "  ('feature', 2),\n",
       "  ('give', 1),\n",
       "  ('guideline', 2),\n",
       "  ('high', 2),\n",
       "  ('human', 1),\n",
       "  ('identify', 1),\n",
       "  ('inform', 1),\n",
       "  ('interference', 1),\n",
       "  ('introduce', 1),\n",
       "  ('large', 2),\n",
       "  ('learn', 1),\n",
       "  ('machine', 1),\n",
       "  ('make', 1),\n",
       "  ('manual', 1),\n",
       "  ('mean', 1),\n",
       "  ('mid', 1),\n",
       "  ('morphological', 1),\n",
       "  ('paper', 1),\n",
       "  ('play', 3),\n",
       "  ('preliminary', 1),\n",
       "  ('pron', 3),\n",
       "  ('propose', 1),\n",
       "  ('range', 1),\n",
       "  ('remain', 1),\n",
       "  ('represent', 1),\n",
       "  ('rule', 1),\n",
       "  ('russian', 1),\n",
       "  ('school', 2),\n",
       "  ('score', 1),\n",
       "  ('select', 1),\n",
       "  ('set', 1),\n",
       "  ('sperantov', 1),\n",
       "  ('stage', 3),\n",
       "  ('stage_direction', 8),\n",
       "  ('study', 1),\n",
       "  ('suggest', 1),\n",
       "  ('tag', 1),\n",
       "  ('token', 1),\n",
       "  ('tool', 1),\n",
       "  ('type', 5),\n",
       "  ('value', 1),\n",
       "  ('vector', 1),\n",
       "  ('widely', 1),\n",
       "  ('work', 1),\n",
       "  ('year', 1)]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voici une version un peu plus lisible. C'est purement de la term-frequency, à l'état brut.\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire l'attribution des sujets ###\n",
    "\n",
    "La LDA (latent Dirichlet Allocation) est une méthode permettant de définir que si certains thèmes sont observés dans un corpus, nous pouvons alors dire que chacun des mots du corpus peuvent être attribués à l'un de ces thèmes.\n",
    "\n",
    "Nous allons appliquer l'algorithme LDA de Gensim à notre corpus en souhaitant 8 topics dans lequel les corpus seront rangés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je construis mon algorithme de LDA\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1, #update_every détermine avec quelle régularité il faut remettre le modèle à jour\n",
    "                                           chunksize=100, #chunksize définit le nombre de documents à utiliser dans chaque passage\n",
    "                                           passes=10, #passes est le nombre total de passage\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons alors trouver les mots clés les plus pertinents de chaque cluster que la machine a trouvé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.016*\"text\" + 0.015*\"format\" + 0.014*\"datum\" + 0.009*\"file\" + '\n",
      "  '0.008*\"principle\" + 0.008*\"fair\" + 0.007*\"pron\" + 0.007*\"letter\" + '\n",
      "  '0.006*\"project\" + 0.006*\"also\"'),\n",
      " (1,\n",
      "  '0.023*\"pron\" + 0.014*\"line\" + 0.013*\"process\" + 0.013*\"build\" + '\n",
      "  '0.012*\"rhyme\" + 0.010*\"project\" + 0.010*\"poem\" + 0.009*\"encode\" + '\n",
      "  '0.007*\"time\" + 0.007*\"page\"'),\n",
      " (2,\n",
      "  '0.020*\"text\" + 0.015*\"encode\" + 0.010*\"token\" + 0.009*\"performance\" + '\n",
      "  '0.008*\"network\" + 0.008*\"problem\" + 0.007*\"type\" + 0.007*\"pointer\" + '\n",
      "  '0.006*\"ontology\" + 0.006*\"element\"'),\n",
      " (3,\n",
      "  '0.018*\"guideline\" + 0.011*\"pron\" + 0.010*\"access\" + 0.010*\"stage_direction\" '\n",
      "  '+ 0.009*\"teach\" + 0.008*\"text\" + 0.008*\"pedagogy\" + 0.007*\"type\" + '\n",
      "  '0.007*\"allow\" + 0.007*\"humanity\"'),\n",
      " (4,\n",
      "  '0.015*\"high\" + 0.015*\"quality\" + 0.011*\"print\" + 0.009*\"document\" + '\n",
      "  '0.009*\"edition\" + 0.009*\"latex\" + 0.007*\"model\" + 0.007*\"create\" + '\n",
      "  '0.006*\"complex\" + 0.006*\"format\"'),\n",
      " (5,\n",
      "  '0.024*\"paper\" + 0.019*\"datum\" + 0.013*\"project\" + 0.012*\"pron\" + '\n",
      "  '0.009*\"database\" + 0.008*\"file\" + 0.008*\"watermark\" + 0.008*\"access\" + '\n",
      "  '0.008*\"description\" + 0.007*\"encode\"'),\n",
      " (6,\n",
      "  '0.037*\"text\" + 0.017*\"pron\" + 0.010*\"encode\" + 0.009*\"element\" + '\n",
      "  '0.007*\"work\" + 0.007*\"also\" + 0.006*\"model\" + 0.006*\"different\" + '\n",
      "  '0.006*\"level\" + 0.005*\"represent\"'),\n",
      " (7,\n",
      "  '0.016*\"textual\" + 0.015*\"element\" + 0.013*\"encode\" + 0.012*\"text\" + '\n",
      "  '0.012*\"paper\" + 0.011*\"guideline\" + 0.010*\"pron\" + 0.010*\"example\" + '\n",
      "  '0.010*\"letter\" + 0.009*\"object\"')]\n"
     ]
    }
   ],
   "source": [
    "# J'affiche les mot-clés des 8 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critique du calcul : le score de cohérence ###\n",
    "\n",
    "La perplexité et le score de cohérence permettent de définir si les groupes générés par topic sont cohérents, c'est à dire s'il y a trop ou pas assez de groupes, et si les groupes sont vraiment représentés par ce topic, si ce topic est vraiment au coeur des textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.266326529284318\n",
      "\n",
      "Coherence Score:  0.2822983625251866\n"
     ]
    }
   ],
   "source": [
    "# Je calcule la Perplexité\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # permet de savoir si le modèle est bon. Plus c'est bas, mieux c'est.\n",
    "\n",
    "# Je calcule le score de cohérence.\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation ###\n",
    "\n",
    "Grâce à cette carte interactive, nous pouvons visualiser la répartition des thèmes et des mots-clés dans chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el52031397388011789285310301274\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el52031397388011789285310301274_data = {\"mdsDat\": {\"x\": [0.009015099158547696, 0.13284744612881363, 0.10402988149573823, -0.0074149853773455825, -0.07510537877083695, -0.04354045346180072, -0.05259485991264698, -0.06723674926046938], \"y\": [-0.020445130839890687, -0.021374344012910808, 0.029330576723249673, -0.040542860012778084, -0.11946667782878477, 0.03839738759721762, 0.09477799434048358, 0.03932305403341344], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [45.10502624511719, 19.371543884277344, 14.730029106140137, 6.431472301483154, 5.670429229736328, 3.9511992931365967, 3.502458333969116, 1.237844705581665]}, \"tinfo\": {\"Term\": [\"text\", \"paper\", \"encode\", \"element\", \"datum\", \"guideline\", \"format\", \"textual\", \"document\", \"pron\", \"model\", \"edition\", \"access\", \"rhyme\", \"high\", \"create\", \"project\", \"token\", \"type\", \"example\", \"odd\", \"available\", \"file\", \"build\", \"letter\", \"line\", \"description\", \"process\", \"complex\", \"database\", \"graph\", \"eltec\", \"parliamentary\", \"linguistic\", \"population\", \"sign\", \"genetic\", \"female\", \"comity\", \"japanese\", \"punctuation\", \"typically\", \"bibliographic\", \"weight\", \"distant_reade\", \"language\", \"ontological\", \"distinctive_feature\", \"influence\", \"accord\", \"regular_expression\", \"debate\", \"old\", \"country\", \"european\", \"edge\", \"title\", \"austrian\", \"applause\", \"corpu\", \"text\", \"literary\", \"short\", \"novel\", \"revision\", \"property\", \"view\", \"theory\", \"variation\", \"represent\", \"sequence\", \"level\", \"model\", \"editor\", \"element\", \"indicate\", \"work\", \"pron\", \"different\", \"technology\", \"encode\", \"also\", \"source\", \"annotation\", \"particular\", \"component\", \"word\", \"base\", \"edition\", \"textual\", \"example\", \"make\", \"information\", \"way\", \"available\", \"provide\", \"type\", \"document\", \"structure\", \"project\", \"collection\", \"datum\", \"rhyme\", \"night\", \"would\", \"site\", \"host\", \"labelling\", \"label\", \"refrain\", \"lineation\", \"uncertainty\", \"shortcut\", \"prose\", \"entire\", \"background\", \"conclusion\", \"fast\", \"instant\", \"breeze\", \"feminine\", \"sound\", \"auto\", \"total\", \"static\", \"ending\", \"diagnostic\", \"check\", \"product\", \"build\", \"complicate\", \"recreate\", \"poem\", \"event\", \"line\", \"render\", \"tag\", \"page\", \"rendition\", \"process\", \"encoder\", \"report\", \"complete\", \"time\", \"pron\", \"project\", \"xml\", \"file\", \"encode\", \"provide\", \"link\", \"collection\", \"long\", \"also\", \"include\", \"create\", \"make\", \"feature\", \"document\", \"work\", \"text\", \"datum\", \"watermark\", \"mold\", \"module\", \"rdb\", \"bookkeepe\", \"relational_database\", \"registration\", \"motive\", \"table\", \"custom\", \"integration\", \"linkable\", \"financial\", \"maker\", \"normally\", \"im\", \"storage\", \"meanwhile\", \"origin\", \"subversion\", \"fromthepage\", \"struggle\", \"mapping\", \"plan\", \"statistic\", \"mill\", \"enter\", \"investment\", \"official\", \"entail\", \"deploy\", \"paper\", \"customization\", \"wish\", \"terminology\", \"historical\", \"datum\", \"standardized\", \"account\", \"flexible\", \"database\", \"purpose\", \"minimal\", \"store\", \"description\", \"record\", \"access\", \"project\", \"file\", \"create\", \"odd\", \"index\", \"allow\", \"structure\", \"system\", \"pron\", \"document\", \"information\", \"field\", \"instance\", \"encode\", \"many\", \"make\", \"line\", \"type\", \"tool\", \"provide\", \"different\", \"process\", \"work\", \"include\", \"fair\", \"cmif\", \"inscription\", \"orcid\", \"usable\", \"findable\", \"iip\", \"correspsearch\", \"actor\", \"rely\", \"attestation\", \"basically\", \"academic\", \"poorly\", \"satlow\", \"fairly\", \"footnote\", \"scientific\", \"examine\", \"guide\", \"sale\", \"browser\", \"aggregate\", \"cslink\", \"creator\", \"aggregation\", \"quantity\", \"openness\", \"prominent\", \"illuminate\", \"archival\", \"popular\", \"force\", \"correspondence\", \"principle\", \"extensive\", \"format\", \"ability\", \"letter\", \"service\", \"offer\", \"platform\", \"datum\", \"develop\", \"file\", \"resource\", \"text\", \"search\", \"database\", \"research\", \"http\", \"object\", \"possible\", \"metadata\", \"digital\", \"edition\", \"also\", \"information\", \"project\", \"pron\", \"process\", \"encode\", \"paper\", \"specific\", \"allow\", \"document\", \"web\", \"uri\", \"theatrical_performance\", \"tokenize\", \"promptbook\", \"searchable\", \"teidata\", \"pointer\", \"unary\", \"underline\", \"tokenized\", \"interaction\", \"underlined\", \"informal\", \"enumerate\", \"performance\", \"quarterly\", \"theatrical\", \"press\", \"dramatic\", \"music\", \"explicitly\", \"rend\", \"network\", \"factoid\", \"regularize\", \"jewish\", \"void\", \"belong\", \"editable\", \"funde\", \"typology\", \"map\", \"break\", \"encoding_initiative\", \"overcome\", \"connection\", \"situation\", \"correspondence\", \"token\", \"analysis\", \"problem\", \"online\", \"editorial\", \"encode\", \"solution\", \"deal\", \"text\", \"workshop\", \"ontology\", \"attribute\", \"type\", \"word\", \"way\", \"discussion\", \"textual\", \"element\", \"information\", \"document\", \"form\", \"model\", \"project\", \"order\", \"advantage\", \"variance\", \"egxml\", \"dynamic\", \"objectification\", \"elaborate\", \"dhip\", \"torsten\", \"highlighting\", \"namespace\", \"genesis\", \"actively\", \"mscontent\", \"listobject\", \"objectname\", \"msidentifier\", \"wholesale\", \"clarify\", \"criticism\", \"impressively\", \"comprehensible\", \"roeder\", \"musicology\", \"retrace\", \"revise\", \"reshape\", \"orient\", \"refocus\", \"siege\", \"favor\", \"reorganize\", \"pursue\", \"object\", \"alignment\", \"letter\", \"introduce\", \"textual\", \"change\", \"guideline\", \"manual\", \"critical\", \"possibly\", \"element\", \"look\", \"user\", \"example\", \"paper\", \"humanity\", \"understand\", \"encode\", \"many\", \"description\", \"document\", \"text\", \"include\", \"pron\", \"method\", \"also\", \"available\", \"describe\", \"still\", \"markup\", \"model\", \"novel\", \"make\", \"base\", \"stage_direction\", \"pedagogy\", \"teaching\", \"bower\", \"log\", \"lite\", \"teach\", \"school\", \"cayless\", \"partnership\", \"engage\", \"refine\", \"rigorous\", \"dialect\", \"formatter\", \"lexicographer\", \"methodology\", \"dialectal\", \"continuation\", \"analogue\", \"philipp\", \"native\", \"cite\", \"notably\", \"mundarten\", \"ed\", \"dually\", \"morphological\", \"approx\", \"vector\", \"classification\", \"friendly\", \"perspective\", \"lately\", \"additionally\", \"emphasis\", \"training\", \"guideline\", \"creation\", \"server\", \"learn\", \"conference\", \"standardize\", \"suggestion\", \"humanity\", \"material\", \"access\", \"infrastructure\", \"stage\", \"online\", \"allow\", \"play\", \"pron\", \"type\", \"tool\", \"present\", \"editor\", \"article\", \"text\", \"different\", \"work\", \"project\", \"encode\", \"structure\", \"digital\", \"available\", \"base\", \"latex\", \"xsl\", \"drawback\", \"pain\", \"reledmac\", \"fortunately\", \"rescue\", \"partial\", \"age\", \"impressive\", \"portal\", \"hassle\", \"luckily\", \"lawyer\", \"behaviour\", \"consequential\", \"tex\", \"standardised\", \"quality\", \"freely\", \"utilise\", \"syntax\", \"engine\", \"commercial\", \"society\", \"package\", \"yield\", \"redundancy\", \"apache\", \"typeset\", \"high\", \"print\", \"template\", \"processing\", \"critical\", \"complex\", \"extension\", \"edition\", \"document\", \"create\", \"format\", \"model\", \"even\", \"rather\", \"odd\", \"however\", \"available\", \"job\", \"text\", \"pron\", \"implementation\", \"also\", \"process\", \"make\"], \"Freq\": [267.0, 72.0, 121.0, 78.0, 81.0, 31.0, 40.0, 40.0, 57.0, 195.0, 52.0, 39.0, 40.0, 30.0, 13.0, 38.0, 86.0, 21.0, 45.0, 45.0, 28.0, 36.0, 44.0, 41.0, 17.0, 57.0, 36.0, 62.0, 14.0, 36.0, 16.17850112915039, 14.294428825378418, 12.429996490478516, 20.91753578186035, 9.559366226196289, 8.640303611755371, 8.621476173400879, 8.614253997802734, 8.614058494567871, 7.698672294616699, 7.687845230102539, 7.673222064971924, 15.272323608398438, 6.731361389160156, 6.7329020500183105, 25.439617156982422, 5.802559852600098, 5.799854755401611, 5.792452812194824, 5.793435096740723, 5.794579982757568, 5.790658950805664, 5.788743019104004, 5.788966655731201, 5.7881550788879395, 5.786690711975098, 12.395183563232422, 4.8572564125061035, 4.854011058807373, 4.853045463562012, 213.4154052734375, 15.237235069274902, 10.486252784729004, 15.239055633544922, 13.332080841064453, 9.584424018859863, 9.573511123657227, 9.57355785369873, 9.56495475769043, 28.49838638305664, 12.401083946228027, 32.31473159790039, 37.439212799072266, 24.704208374023438, 50.34728240966797, 14.619749069213867, 41.24311447143555, 97.78065490722656, 32.37056350708008, 13.65252685546875, 60.029083251953125, 40.2160530090332, 27.71804428100586, 16.49867820739746, 15.281414031982422, 14.302717208862305, 19.498472213745117, 20.683311462402344, 21.62267303466797, 21.570159912109375, 22.9951171875, 24.874759674072266, 21.870826721191406, 20.991514205932617, 19.867839813232422, 22.10108184814453, 21.102861404418945, 22.857681274414062, 20.165700912475586, 24.804738998413086, 19.045108795166016, 22.056644439697266, 29.91407012939453, 13.28847885131836, 6.283560752868652, 15.076081275939941, 4.513394832611084, 4.496796607971191, 11.538763999938965, 4.484829902648926, 3.6500003337860107, 8.942447662353516, 3.6304821968078613, 6.294073581695557, 7.145930767059326, 2.76485013961792, 2.7486956119537354, 2.745978832244873, 2.74605655670166, 2.7471866607666016, 2.7444820404052734, 2.7429418563842773, 2.738755226135254, 2.7366111278533936, 6.272521495819092, 6.262600421905518, 6.26079797744751, 6.274167537689209, 5.3972344398498535, 31.792585372924805, 1.8804295063018799, 1.8792458772659302, 23.795392990112305, 13.372295379638672, 34.571834564208984, 8.018373489379883, 17.651906967163086, 18.609819412231445, 11.5587158203125, 31.809053421020508, 15.059179306030273, 8.01715087890625, 7.155986309051514, 18.62459945678711, 56.641571044921875, 25.642148971557617, 11.568382263183594, 14.237344741821289, 23.02605628967285, 14.128114700317383, 9.83917236328125, 11.564178466796875, 9.795246124267578, 14.217031478881836, 11.586190223693848, 10.689352989196777, 11.495465278625488, 9.80898380279541, 10.719185829162598, 9.855002403259277, 10.37251091003418, 9.812345504760742, 15.498462677001953, 6.950690269470215, 6.096253871917725, 4.3808794021606445, 3.5305817127227783, 3.5302743911743164, 3.5292415618896484, 3.5288453102111816, 3.5274558067321777, 3.526895761489868, 3.526167869567871, 2.674274444580078, 2.673267126083374, 2.6727843284606934, 1.8190122842788696, 1.8187915086746216, 1.818600058555603, 1.8184678554534912, 1.8184937238693237, 1.8179917335510254, 1.8180992603302002, 1.8187601566314697, 1.8177752494812012, 1.817973256111145, 1.8176376819610596, 1.8177605867385864, 1.8176681995391846, 1.8176980018615723, 1.817206621170044, 1.8171344995498657, 4.384636402130127, 46.30927276611328, 8.660634994506836, 3.5290768146514893, 4.383862018585205, 9.527981758117676, 35.20662307739258, 4.384204864501953, 5.238373279571533, 3.5236105918884277, 16.3821964263916, 7.793308734893799, 4.381040096282959, 6.098180294036865, 14.63978385925293, 12.943424224853516, 15.40247917175293, 25.02997398376465, 15.529074668884277, 12.971172332763672, 10.332457542419434, 7.7656474113464355, 9.509944915771484, 11.195952415466309, 9.52779769897461, 23.259761810302734, 12.129073143005371, 10.377846717834473, 5.232969284057617, 6.098357677459717, 13.727097511291504, 7.7965989112854, 9.542059898376465, 9.537290573120117, 8.653914451599121, 6.965029716491699, 8.620606422424316, 8.60988712310791, 8.723402976989746, 8.680438041687012, 7.82171106338501, 6.520114421844482, 4.404248237609863, 3.6637799739837646, 2.944051742553711, 2.2349660396575928, 2.2343502044677734, 2.230347156524658, 1.5286599397659302, 1.524746060371399, 1.5241433382034302, 1.5244907140731812, 1.523537039756775, 1.5237457752227783, 1.5224618911743164, 1.5183594226837158, 1.5163213014602661, 2.9619088172912598, 2.9554669857025146, 2.2387707233428955, 2.2276055812835693, 0.812319278717041, 0.8101401329040527, 0.8095153570175171, 0.8093757629394531, 0.8091309070587158, 0.809108555316925, 0.8087723255157471, 0.8081313967704773, 0.8081148266792297, 0.8079357743263245, 2.9486703872680664, 1.5251730680465698, 1.5190422534942627, 4.404655456542969, 6.532837390899658, 1.5224249362945557, 12.307639122009277, 1.5188528299331665, 5.845813751220703, 2.2468748092651367, 4.399780750274658, 2.96402907371521, 11.579476356506348, 5.124577045440674, 7.263656139373779, 4.4001994132995605, 13.095837593078613, 2.9586222171783447, 5.136460304260254, 4.4099626541137695, 2.9517860412597656, 2.9549200534820557, 4.402198314666748, 3.692089080810547, 4.381078243255615, 4.420026779174805, 5.139138698577881, 4.4212870597839355, 5.147084712982178, 5.90609884262085, 3.6914925575256348, 3.711085319519043, 2.9921672344207764, 2.9798853397369385, 2.977860450744629, 2.977773427963257, 2.9743330478668213, 3.5599398612976074, 4.1039228439331055, 2.8666832447052, 2.7833688259124756, 2.1737558841705322, 2.1706717014312744, 4.948145866394043, 1.478196620941162, 1.47779381275177, 1.4775454998016357, 1.4768388271331787, 1.4771078824996948, 1.4755057096481323, 1.4746595621109009, 6.68979549407959, 1.4487611055374146, 1.4252375364303589, 1.422861099243164, 3.4317290782928467, 2.7357640266418457, 2.17641544342041, 2.1714365482330322, 5.648709297180176, 0.7825861573219299, 0.782501220703125, 0.7823441624641418, 0.7825362682342529, 0.7824457883834839, 0.7824368476867676, 0.7822381258010864, 2.868502140045166, 1.4701229333877563, 3.5647599697113037, 1.400267481803894, 2.1731951236724854, 2.1581473350524902, 1.4723150730133057, 4.236708641052246, 7.051979064941406, 3.56784725189209, 5.531303882598877, 4.197308540344238, 2.8642032146453857, 11.328804969787598, 3.5566823482513428, 2.826132297515869, 14.42936897277832, 2.827829122543335, 4.302407264709473, 4.2631707191467285, 4.977970123291016, 3.9858756065368652, 4.294466018676758, 2.94630765914917, 3.9675066471099854, 4.296241760253906, 3.6068599224090576, 3.6069259643554688, 3.3129823207855225, 3.288722038269043, 2.957282781600952, 2.8871335983276367, 2.8754472732543945, 2.5096631050109863, 2.5038819313049316, 3.72739577293396, 1.2959259748458862, 1.2933694124221802, 1.2932190895080566, 1.2922892570495605, 1.2911512851715088, 1.2900598049163818, 2.5114004611968994, 0.6863721013069153, 0.6862919330596924, 0.6861462593078613, 0.6858905553817749, 0.6858922839164734, 0.6858800649642944, 0.6856954097747803, 0.6851922869682312, 0.6851100921630859, 0.6848981380462646, 0.6848583817481995, 0.6848025918006897, 0.6848028302192688, 0.6848162412643433, 0.684727132320404, 0.6847400069236755, 0.68462073802948, 0.6846579313278198, 0.6846883296966553, 0.6846878528594971, 1.2955026626586914, 4.352071285247803, 1.2924833297729492, 4.948844909667969, 3.1286866664886475, 8.008828163146973, 4.347767353057861, 5.567597389221191, 1.2921249866485596, 1.902366280555725, 1.292991042137146, 7.437830924987793, 2.5096893310546875, 3.122589588165283, 4.956004619598389, 6.19782018661499, 2.517879009246826, 1.2933300733566284, 6.828668117523193, 3.136298418045044, 3.1457667350769043, 3.758824586868286, 6.286340236663818, 3.134373664855957, 5.043262958526611, 2.517030954360962, 3.148790121078491, 2.5311014652252197, 2.5295445919036865, 1.9120607376098633, 1.9128124713897705, 1.9399720430374146, 1.915915608406067, 1.9352079629898071, 1.9217026233673096, 4.695082664489746, 3.523247718811035, 2.3713319301605225, 1.8056010007858276, 1.7962002754211426, 1.7919821739196777, 4.098084926605225, 1.2275147438049316, 1.2225008010864258, 1.2220792770385742, 1.221372365951538, 1.7995007038116455, 1.799863576889038, 0.6510071158409119, 0.6507965922355652, 0.6507352590560913, 2.3706400394439697, 0.6507477760314941, 0.6506839394569397, 0.6506808996200562, 0.6506306529045105, 0.6506262421607971, 0.6505237221717834, 0.6506054997444153, 0.6505346298217773, 0.6503825783729553, 0.6502881646156311, 0.6501787900924683, 0.6501027941703796, 0.6499513387680054, 1.2275522947311401, 1.2274370193481445, 1.224444031715393, 1.221549391746521, 1.2205641269683838, 1.2235405445098877, 1.2218211889266968, 8.15400218963623, 2.391225814819336, 2.9495041370391846, 2.3821892738342285, 1.8000376224517822, 1.2259851694107056, 1.2261987924575806, 2.956815004348755, 2.9544074535369873, 4.710411071777344, 1.7988919019699097, 2.388878345489502, 2.3851284980773926, 2.963402271270752, 1.8084380626678467, 4.833375930786133, 2.9774394035339355, 2.404618978500366, 2.3865296840667725, 2.4129130840301514, 1.826422095298767, 3.629807233810425, 2.4004790782928467, 2.432676315307617, 2.4575886726379395, 2.431920051574707, 1.8263028860092163, 1.8260200023651123, 1.8248430490493774, 1.8181779384613037, 1.3598122596740723, 0.6998106241226196, 0.37077242136001587, 0.3707016110420227, 0.3706813156604767, 0.37066325545310974, 0.37065380811691284, 0.37064194679260254, 0.3706004321575165, 0.3705935478210449, 0.370565801858902, 0.37056270241737366, 0.37051013112068176, 0.3704792857170105, 0.37043821811676025, 0.3704076409339905, 0.37039124965667725, 0.3702864646911621, 2.346724033355713, 0.7003161311149597, 0.7172753214836121, 0.3707598149776459, 0.3711370527744293, 0.3704398572444916, 0.3702462911605835, 0.3810999393463135, 0.3708871006965637, 0.37090158462524414, 0.3707321584224701, 0.3706166446208954, 2.3471126556396484, 1.6929212808609009, 0.704458475112915, 1.034867763519287, 0.701211154460907, 1.038670301437378, 0.7013252973556519, 1.365607500076294, 1.3760584592819214, 1.0394461154937744, 1.035643219947815, 1.043393850326538, 0.7040714621543884, 0.702449381351471, 0.7033432722091675, 0.7054778337478638, 0.7087735533714294, 0.38211092352867126, 0.4208819568157196, 0.399472177028656, 0.37952736020088196, 0.3860032856464386, 0.3851858377456665, 0.38168126344680786], \"Total\": [267.0, 72.0, 121.0, 78.0, 81.0, 31.0, 40.0, 40.0, 57.0, 195.0, 52.0, 39.0, 40.0, 30.0, 13.0, 38.0, 86.0, 21.0, 45.0, 45.0, 28.0, 36.0, 44.0, 41.0, 17.0, 57.0, 36.0, 62.0, 14.0, 36.0, 16.8270206451416, 14.934036254882812, 13.044132232666016, 22.273439407348633, 10.18816089630127, 9.248610496520996, 9.24071979522705, 9.238844871520996, 9.239096641540527, 8.299497604370117, 8.302096366882324, 8.291840553283691, 16.617918014526367, 7.34324836730957, 7.344982624053955, 27.824739456176758, 6.4006757736206055, 6.399775505065918, 6.396211624145508, 6.397441864013672, 6.399275302886963, 6.3955769538879395, 6.395284652709961, 6.396437644958496, 6.3963189125061035, 6.395244121551514, 13.894769668579102, 5.451642990112305, 5.450685024261475, 5.450253009796143, 267.7340087890625, 17.61934471130371, 12.016980171203613, 17.718381881713867, 15.696298599243164, 11.078800201416016, 11.073066711425781, 11.077253341674805, 11.076481819152832, 36.882022857666016, 14.80431842803955, 43.81273651123047, 52.506752014160156, 33.11148452758789, 78.56932830810547, 18.29060935974121, 67.18228912353516, 195.5042724609375, 50.36713409423828, 17.334997177124023, 121.15922546386719, 72.53131103515625, 46.45598602294922, 22.737548828125, 20.60662269592285, 18.83940315246582, 30.131345748901367, 35.10633087158203, 39.442649841308594, 40.22966384887695, 45.563926696777344, 53.96516799926758, 43.0521354675293, 39.843666076660156, 36.00407409667969, 49.72264099121094, 45.08721160888672, 57.533363342285156, 40.165016174316406, 86.21294403076172, 39.38566207885742, 81.09535217285156, 30.847618103027344, 14.005779266357422, 6.915370464324951, 16.645578384399414, 5.139405727386475, 5.136756420135498, 13.183932304382324, 5.135622024536133, 4.255520343780518, 10.445462226867676, 4.253010272979736, 7.5296430587768555, 8.6583890914917, 3.3700320720672607, 3.365185260772705, 3.364692449569702, 3.364967107772827, 3.3665642738342285, 3.3658039569854736, 3.3660459518432617, 3.364816665649414, 3.3654863834381104, 7.774474143981934, 7.770418167114258, 7.772498607635498, 7.860279083251953, 6.886308670043945, 41.91322708129883, 2.4802873134613037, 2.482024669647217, 31.606172561645508, 17.82065773010254, 57.60881423950195, 11.442956924438477, 29.675939559936523, 32.374019622802734, 18.452045440673828, 62.978248596191406, 26.08095359802246, 12.232073783874512, 10.753662109375, 39.913116455078125, 195.5042724609375, 86.21294403076172, 26.293058395385742, 44.50248336791992, 121.15922546386719, 49.72264099121094, 24.05089569091797, 39.38566207885742, 25.85647201538086, 72.53131103515625, 42.355018615722656, 38.17719268798828, 53.96516799926758, 31.913471221923828, 57.533363342285156, 67.18228912353516, 267.7340087890625, 81.09535217285156, 16.18349266052246, 7.585042476654053, 6.726473331451416, 5.002965927124023, 4.144355297088623, 4.1447882652282715, 4.145056247711182, 4.144881248474121, 4.144339084625244, 4.144847393035889, 4.145322799682617, 3.284564256668091, 3.2845640182495117, 3.284851551055908, 2.424691677093506, 2.4246597290039062, 2.4244253635406494, 2.424262523651123, 2.4250364303588867, 2.424424886703491, 2.424614191055298, 2.425596237182617, 2.4245595932006836, 2.424834966659546, 2.4245100021362305, 2.424825668334961, 2.42488694190979, 2.4250805377960205, 2.4248344898223877, 2.42478346824646, 5.8946852684021, 72.79914093017578, 13.896924018859863, 5.092086315155029, 6.6749749183654785, 17.094751358032227, 81.09535217285156, 6.9006147384643555, 8.710488319396973, 5.457566261291504, 36.97299575805664, 14.80002498626709, 7.234082221984863, 11.002991676330566, 36.53346633911133, 32.076568603515625, 40.53988265991211, 86.21294403076172, 44.50248336791992, 38.17719268798828, 28.26382064819336, 19.377105712890625, 28.255571365356445, 40.165016174316406, 30.903432846069336, 195.5042724609375, 57.533363342285156, 43.0521354675293, 10.1126070022583, 15.464247703552246, 121.15922546386719, 29.1202335357666, 53.96516799926758, 57.60881423950195, 45.08721160888672, 22.991607666015625, 49.72264099121094, 50.36713409423828, 62.978248596191406, 67.18228912353516, 42.355018615722656, 7.216439247131348, 5.041862487792969, 4.322319984436035, 3.6002519130706787, 2.8754663467407227, 2.875394821166992, 2.8760690689086914, 2.150568962097168, 2.148456335067749, 2.150313377380371, 2.151179075241089, 2.1500983238220215, 2.1508688926696777, 2.15107798576355, 2.1521832942962646, 2.152897357940674, 4.54013729095459, 4.5440897941589355, 3.487480878829956, 3.825806140899658, 1.427324891090393, 1.4276899099349976, 1.4278113842010498, 1.427885890007019, 1.4278792142868042, 1.4278960227966309, 1.4279075860977173, 1.4269431829452515, 1.4270570278167725, 1.4269013404846191, 5.433436393737793, 3.010202646255493, 3.0117080211639404, 11.074714660644531, 18.2270565032959, 3.0990259647369385, 40.97789001464844, 3.1000418663024902, 17.470874786376953, 5.206112384796143, 14.373701095581055, 8.865812301635742, 81.09535217285156, 23.366796493530273, 44.50248336791992, 21.4163875579834, 267.7340087890625, 9.673227310180664, 36.97299575805664, 25.8133487701416, 10.266400337219238, 10.66457748413086, 29.47266960144043, 19.255685806274414, 37.968597412109375, 39.442649841308594, 72.53131103515625, 43.0521354675293, 86.21294403076172, 195.5042724609375, 62.978248596191406, 121.15922546386719, 72.79914093017578, 29.668659210205078, 28.255571365356445, 57.533363342285156, 18.930816650390625, 4.196097373962402, 4.9217424392700195, 3.498897075653076, 3.516221284866333, 2.8001298904418945, 2.799380302429199, 6.479828357696533, 2.1018168926239014, 2.101729154586792, 2.1014351844787598, 2.1009371280670166, 2.101876735687256, 2.1015334129333496, 2.101551055908203, 9.555377006530762, 2.104973316192627, 2.1127848625183105, 2.116487503051758, 5.109803676605225, 4.140121936798096, 3.6873998641967773, 3.7484664916992188, 9.794454574584961, 1.4031065702438354, 1.40330970287323, 1.4030473232269287, 1.403456211090088, 1.4034196138381958, 1.4034631252288818, 1.4031097888946533, 5.304469585418701, 2.8233776092529297, 7.745520114898682, 2.7055344581604004, 4.607104778289795, 4.5785346031188965, 2.9628353118896484, 11.074714660644531, 21.54744529724121, 10.243019104003906, 19.554645538330078, 15.048871040344238, 7.832048416137695, 121.15922546386719, 12.925992012023926, 8.193024635314941, 267.7340087890625, 8.749114990234375, 22.63345718383789, 22.70264434814453, 45.08721160888672, 30.131345748901367, 39.843666076660156, 11.823968887329102, 40.22966384887695, 78.56932830810547, 43.0521354675293, 57.533363342285156, 30.824893951416016, 52.506752014160156, 86.21294403076172, 23.928131103515625, 13.082030296325684, 3.154273509979248, 3.1568362712860107, 5.240938663482666, 1.9296857118606567, 1.9295897483825684, 1.9298079013824463, 1.9299265146255493, 1.930676817893982, 1.9312751293182373, 4.101321220397949, 1.3173034191131592, 1.3173508644104004, 1.317421793937683, 1.3175383806228638, 1.3175482749938965, 1.317565679550171, 1.3176591396331787, 1.3172688484191895, 1.317314863204956, 1.317309021949768, 1.3173730373382568, 1.317347526550293, 1.3173617124557495, 1.3175033330917358, 1.3173877000808716, 1.3174165487289429, 1.3172179460525513, 1.3173155784606934, 1.3174128532409668, 1.3174588680267334, 2.6524033546447754, 10.66457748413086, 2.8173654079437256, 17.470874786376953, 10.784095764160156, 40.22966384887695, 18.565021514892578, 31.433563232421875, 3.460139274597168, 6.590237140655518, 3.6758241653442383, 78.56932830810547, 12.29726791381836, 17.929899215698242, 45.563926696777344, 72.79914093017578, 14.28641414642334, 4.564080238342285, 121.15922546386719, 29.1202335357666, 36.53346633911133, 57.533363342285156, 267.7340087890625, 42.355018615722656, 195.5042724609375, 23.366165161132812, 72.53131103515625, 36.00407409667969, 36.34516143798828, 14.501748085021973, 15.311053276062012, 52.506752014160156, 17.718381881713867, 53.96516799926758, 35.10633087158203, 5.353494167327881, 4.203490257263184, 3.038144588470459, 2.447624444961548, 2.455080032348633, 2.457066059112549, 5.73422908782959, 1.8675086498260498, 1.8712772130966187, 1.8715183734893799, 1.8718422651290894, 3.1510496139526367, 3.340388059616089, 1.285752773284912, 1.2857441902160645, 1.2857586145401, 4.684109687805176, 1.2858575582504272, 1.285813808441162, 1.2858227491378784, 1.285735845565796, 1.285810947418213, 1.2857009172439575, 1.2858625650405884, 1.2858457565307617, 1.285883903503418, 1.2858350276947021, 1.2861835956573486, 1.286254644393921, 1.2862522602081299, 2.5907485485076904, 2.7537829875946045, 2.757819414138794, 2.7598674297332764, 2.7600021362304688, 2.818540573120117, 2.8194172382354736, 31.433563232421875, 6.696441173553467, 10.782637596130371, 8.573471069335938, 5.911683082580566, 3.45141863822937, 3.4613053798675537, 14.28641414642334, 14.278271675109863, 40.53988265991211, 7.793148994445801, 14.96262264251709, 15.048871040344238, 28.255571365356445, 7.958545207977295, 195.5042724609375, 45.08721160888672, 22.991607666015625, 25.888765335083008, 33.11148452758789, 10.13570499420166, 267.7340087890625, 50.36713409423828, 67.18228912353516, 86.21294403076172, 121.15922546386719, 40.165016174316406, 37.968597412109375, 36.00407409667969, 35.10633087158203, 2.030693531036377, 1.3688936233520508, 1.0368067026138306, 1.0368707180023193, 1.036875605583191, 1.0369261503219604, 1.03694486618042, 1.0369374752044678, 1.0369950532913208, 1.0370099544525146, 1.0369746685028076, 1.037079095840454, 1.0371382236480713, 1.0372053384780884, 1.0372060537338257, 1.0372264385223389, 1.0372440814971924, 1.0374374389648438, 6.942739486694336, 2.092329740524292, 2.283311367034912, 1.649570345878601, 1.8961793184280396, 1.8968207836151123, 1.8971531391143799, 1.9646728038787842, 1.9227919578552246, 1.9235000610351562, 1.9239983558654785, 1.9241811037063599, 13.36313533782959, 9.873546600341797, 4.145504951477051, 11.992372512817383, 6.590237140655518, 14.29539966583252, 7.4664626121521, 39.442649841308594, 57.533363342285156, 38.17719268798828, 40.97789001464844, 52.506752014160156, 14.948646545410156, 15.93336296081543, 28.26382064819336, 33.48957061767578, 36.00407409667969, 2.822726249694824, 267.7340087890625, 195.5042724609375, 3.641298294067383, 72.53131103515625, 62.978248596191406, 53.96516799926758], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.886499881744385, -6.010300159454346, -6.150100231170654, -5.6296000480651855, -6.412700176239014, -6.513800144195557, -6.515900135040283, -6.5167999267578125, -6.5167999267578125, -6.629199981689453, -6.6305999755859375, -6.632500171661377, -5.944200038909912, -6.763400077819824, -6.763199806213379, -5.433899879455566, -6.911900043487549, -6.912399768829346, -6.913599967956543, -6.91349983215332, -6.913300037384033, -6.914000034332275, -6.914299964904785, -6.9141998291015625, -6.914400100708008, -6.914599895477295, -6.152900218963623, -7.089700222015381, -7.090400218963623, -7.09060001373291, -3.306999921798706, -5.946499824523926, -6.320099830627441, -5.946300029754639, -6.079999923706055, -6.410099983215332, -6.411200046539307, -6.411200046539307, -6.412099838256836, -5.320400238037109, -6.152400016784668, -5.194699764251709, -5.047500133514404, -5.463200092315674, -4.751299858093262, -5.987800121307373, -4.950699806213379, -4.087500095367432, -5.192999839782715, -6.056300163269043, -4.575399875640869, -4.975900173187256, -5.348100185394287, -5.8668999671936035, -5.943600177764893, -6.009799957275391, -5.699900150299072, -5.640900135040283, -5.596499919891357, -5.598899841308594, -5.534900188446045, -5.456299781799316, -5.585000038146973, -5.626100063323975, -5.681099891662598, -5.5746002197265625, -5.620800018310547, -5.540900230407715, -5.666200160980225, -5.459199905395508, -5.723400115966797, -5.576600074768066, -4.426700115203857, -5.238100051879883, -5.987100124359131, -5.1118998527526855, -6.317999839782715, -6.321599960327148, -5.379300117492676, -6.3242998123168945, -6.530300140380859, -5.634200096130371, -6.535600185394287, -5.985400199890137, -5.858500003814697, -6.808000087738037, -6.813899993896484, -6.814899921417236, -6.814799785614014, -6.8144001960754395, -6.815400123596191, -6.815999984741211, -6.817500114440918, -6.818299770355225, -5.988800048828125, -5.9903998374938965, -5.990699768066406, -5.98859977722168, -6.139100074768066, -4.365799903869629, -7.19350004196167, -7.1940999031066895, -4.6554999351501465, -5.231800079345703, -4.2820000648498535, -5.743299961090088, -4.95419979095459, -4.901299953460693, -5.377600193023682, -4.365300178527832, -5.11299991607666, -5.7434000968933105, -5.857100009918213, -4.9004998207092285, -3.788300037384033, -4.5808000564575195, -5.376699924468994, -5.169099807739258, -4.688399791717529, -5.176799774169922, -5.538599967956543, -5.377099990844727, -5.543099880218506, -5.170599937438965, -5.375199794769287, -5.4558000564575195, -5.3831000328063965, -5.5416998863220215, -5.453000068664551, -5.5370001792907715, -5.485899925231934, -5.541399955749512, -4.810400009155273, -5.612299919128418, -5.7434000968933105, -6.073800086975098, -6.289599895477295, -6.289700031280518, -6.289999961853027, -6.29010009765625, -6.290500164031982, -6.2906999588012695, -6.290900230407715, -6.567399978637695, -6.567800045013428, -6.567999839782715, -6.9527997970581055, -6.952899932861328, -6.953000068664551, -6.953100204467773, -6.953100204467773, -6.953400135040283, -6.9532999992370605, -6.952899932861328, -6.953499794006348, -6.953400135040283, -6.95359992980957, -6.953499794006348, -6.953499794006348, -6.953499794006348, -6.953800201416016, -6.953800201416016, -6.072999954223633, -3.7158000469207764, -5.392300128936768, -6.29010009765625, -6.073200225830078, -5.296899795532227, -3.9899001121520996, -6.0731000900268555, -5.895100116729736, -6.291600227355957, -4.754899978637695, -5.497799873352051, -6.073800086975098, -5.743100166320801, -4.867400169372559, -4.990499973297119, -4.8165998458862305, -4.330999851226807, -4.8084001541137695, -4.988399982452393, -5.215799808502197, -5.501399993896484, -5.298799991607666, -5.135499954223633, -5.296899795532227, -4.404399871826172, -5.055500030517578, -5.211400032043457, -5.896100044250488, -5.743100166320801, -4.931700229644775, -5.497399806976318, -5.295400142669678, -5.295899868011475, -5.393099784851074, -5.610199928283691, -5.396900177001953, -5.398200035095215, -5.3850998878479, -5.389999866485596, -5.494200229644775, -4.847499847412109, -5.239799976348877, -5.423900127410889, -5.642600059509277, -5.9182000160217285, -5.918499946594238, -5.920300006866455, -6.297999858856201, -6.300600051879883, -6.301000118255615, -6.3007001876831055, -6.301400184631348, -6.301199913024902, -6.30210018157959, -6.304800033569336, -6.306099891662598, -5.636600017547607, -5.638800144195557, -5.916500091552734, -5.921500205993652, -6.930300235748291, -6.933000087738037, -6.933700084686279, -6.933899879455566, -6.934199810028076, -6.934199810028076, -6.934599876403809, -6.935400009155273, -6.935500144958496, -6.935699939727783, -5.64109992980957, -6.300300121307373, -6.304299831390381, -5.239699840545654, -4.845600128173828, -6.30210018157959, -4.212200164794922, -6.304500102996826, -4.956699848175049, -5.912899971008301, -5.240900039672852, -5.635900020599365, -4.273200035095215, -5.088399887084961, -4.739500045776367, -5.240799903869629, -4.150100231170654, -5.637700080871582, -5.085999965667725, -5.238500118255615, -5.639999866485596, -5.638899803161621, -5.240300178527832, -5.416200160980225, -5.245100021362305, -5.236299991607666, -5.0854997634887695, -5.236000061035156, -5.084000110626221, -4.946400165557861, -5.416399955749512, -5.411099910736084, -5.626399993896484, -5.630499839782715, -5.631199836730957, -5.631199836730957, -5.632400035858154, -5.326700210571289, -5.184500217437744, -5.543300151824951, -5.572800159454346, -5.820000171661377, -5.821400165557861, -4.997499942779541, -6.205599784851074, -6.205900192260742, -6.206099987030029, -6.206600189208984, -6.206399917602539, -6.207499980926514, -6.208000183105469, -4.695899963378906, -6.225800037384033, -6.242099761962891, -6.243800163269043, -5.363399982452393, -5.590099811553955, -5.81879997253418, -5.821100234985352, -4.864999771118164, -6.841599941253662, -6.841700077056885, -6.841899871826172, -6.841700077056885, -6.841800212860107, -6.841800212860107, -6.842100143432617, -5.542699813842773, -6.211100101470947, -5.325399875640869, -6.259799957275391, -5.820300102233887, -5.827199935913086, -6.20959997177124, -5.152699947357178, -4.643199920654297, -5.32450008392334, -4.886000156402588, -5.1620001792907715, -5.5441999435424805, -4.169099807739258, -5.327600002288818, -5.557600021362305, -3.9272000789642334, -5.557000160217285, -5.13730001449585, -5.146500110626221, -4.991399765014648, -5.213699817657471, -5.139100074768066, -5.515900135040283, -5.218299865722656, -5.138700008392334, -5.313600063323975, -5.313600063323975, -5.398600101470947, -5.406000137329102, -5.512199878692627, -5.536200046539307, -5.540299892425537, -5.315100193023682, -5.317399978637695, -4.91949987411499, -5.97599983215332, -5.978000164031982, -5.978099822998047, -5.978799819946289, -5.979700088500977, -5.980500221252441, -5.3144001960754395, -6.611599922180176, -6.611700057983398, -6.6118998527526855, -6.612299919128418, -6.612299919128418, -6.612299919128418, -6.612500190734863, -6.61329984664917, -6.613399982452393, -6.613699913024902, -6.613800048828125, -6.613900184631348, -6.613800048828125, -6.613800048828125, -6.613999843597412, -6.613900184631348, -6.614099979400635, -6.614099979400635, -6.613999843597412, -6.613999843597412, -5.97629976272583, -4.764599800109863, -5.978700160980225, -4.636099815368652, -5.094600200653076, -4.154699802398682, -4.765600204467773, -4.5183000564575195, -5.978899955749512, -5.592100143432617, -5.978300094604492, -4.228600025177002, -5.315100193023682, -5.09660005569458, -4.6346001625061035, -4.410999774932861, -5.311800003051758, -5.978000164031982, -4.3140997886657715, -5.092199802398682, -5.089200019836426, -4.911099910736084, -4.3968000411987305, -5.092800140380859, -4.617199897766113, -5.312099933624268, -5.088200092315674, -5.306600093841553, -5.307199954986572, -5.586999893188477, -5.586699962615967, -5.5725998878479, -5.585000038146973, -5.574999809265137, -5.581999778747559, -4.56820011138916, -4.855299949645996, -5.251200199127197, -5.523799896240234, -5.5289998054504395, -5.531300067901611, -4.70419979095459, -5.9096999168396, -5.91379976272583, -5.914100170135498, -5.914700031280518, -5.527200222015381, -5.5269999504089355, -6.543900012969971, -6.5441999435424805, -6.544300079345703, -5.251500129699707, -6.544300079345703, -6.544400215148926, -6.544400215148926, -6.54449987411499, -6.54449987411499, -6.544600009918213, -6.54449987411499, -6.544600009918213, -6.544899940490723, -6.545000076293945, -6.545199871063232, -6.545300006866455, -6.545499801635742, -5.909599781036377, -5.9096999168396, -5.912199974060059, -5.914599895477295, -5.91540002822876, -5.912899971008301, -5.914299964904785, -4.016200065612793, -5.2428998947143555, -5.0329999923706055, -5.246699810028076, -5.526899814605713, -5.910900115966797, -5.910799980163574, -5.030600070953369, -5.031400203704834, -4.564899921417236, -5.527500152587891, -5.243800163269043, -5.2453999519348145, -5.028299808502197, -5.522200107574463, -4.539100170135498, -5.023600101470947, -5.237299919128418, -5.244800090789795, -5.233799934387207, -5.51230001449585, -4.825500011444092, -5.238999843597412, -5.2256999015808105, -5.2154998779296875, -5.22599983215332, -5.512400150299072, -5.512499809265137, -5.513199806213379, -5.5167999267578125, -4.767199993133545, -5.43149995803833, -6.066699981689453, -6.06689977645874, -6.066999912261963, -6.066999912261963, -6.0671000480651855, -6.0671000480651855, -6.067200183868408, -6.067200183868408, -6.067299842834473, -6.067299842834473, -6.067500114440918, -6.067500114440918, -6.067599773406982, -6.067699909210205, -6.067800045013428, -6.0680999755859375, -4.22160005569458, -5.430799961090088, -5.406899929046631, -6.066800117492676, -6.065800189971924, -6.067599773406982, -6.06820011138916, -6.039299964904785, -6.066400051116943, -6.066400051116943, -6.06689977645874, -6.067200183868408, -4.221399784088135, -4.548099994659424, -5.424900054931641, -5.040299892425537, -5.429500102996826, -5.036600112915039, -5.4293999671936035, -4.763000011444092, -4.75540018081665, -5.035900115966797, -5.039599895477295, -5.032100200653076, -5.42549991607666, -5.427800178527832, -5.426499843597412, -5.423500061035156, -5.418799877166748, -6.036600112915039, -5.940000057220459, -5.992199897766113, -6.043399810791016, -6.026500225067139, -6.028600215911865, -6.037700176239014], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7569000124931335, 0.7523999810218811, 0.7480000257492065, 0.7333999872207642, 0.7325000166893005, 0.7281000018119812, 0.7268000245094299, 0.7261999845504761, 0.7261000275611877, 0.7210000157356262, 0.7192999720573425, 0.7185999751091003, 0.7117000222206116, 0.7092000246047974, 0.7092000246047974, 0.70660001039505, 0.6980999708175659, 0.697700023651123, 0.6970000267028809, 0.6970000267028809, 0.6969000101089478, 0.6967999935150146, 0.6965000033378601, 0.696399986743927, 0.6963000297546387, 0.6962000131607056, 0.6819999814033508, 0.6807000041007996, 0.6801999807357788, 0.6801000237464905, 0.5694000124931335, 0.6509000062942505, 0.6599000096321106, 0.6453999876976013, 0.6328999996185303, 0.6513000130653381, 0.6506999731063843, 0.6503000259399414, 0.6495000123977661, 0.5382999777793884, 0.6190000176429749, 0.4918000102043152, 0.4580000042915344, 0.5033000111579895, 0.35109999775886536, 0.5722000002861023, 0.3082999885082245, 0.10329999774694443, 0.35409998893737793, 0.5573999881744385, 0.09390000253915787, 0.20640000700950623, 0.2797999978065491, 0.47540000081062317, 0.49720001220703125, 0.5206999778747559, 0.36090001463890076, 0.2671000063419342, 0.19509999454021454, 0.1729000061750412, 0.11230000108480453, 0.021700000390410423, 0.11890000104904175, 0.15530000627040863, 0.20160000026226044, -0.014700000174343586, 0.03700000047683716, -0.12690000236034393, 0.10719999670982361, -0.4496000111103058, 0.06960000097751617, -0.5058000087738037, 1.6105999946594238, 1.5887999534606934, 1.5456000566482544, 1.5422999858856201, 1.5115000009536743, 1.5082999467849731, 1.5081000328063965, 1.5059000253677368, 1.4879000186920166, 1.4859999418258667, 1.4831000566482544, 1.4621000289916992, 1.4493999481201172, 1.4434000253677368, 1.4390000104904175, 1.4381999969482422, 1.438099980354309, 1.437999963760376, 1.4372999668121338, 1.4366999864578247, 1.4355000257492065, 1.434499979019165, 1.4266999959945679, 1.4256000518798828, 1.4250999689102173, 1.4160000085830688, 1.3976999521255493, 1.3650000095367432, 1.3645000457763672, 1.3631999492645264, 1.3574999570846558, 1.354200005531311, 1.1306999921798706, 1.2856999635696411, 1.121899962425232, 1.0877000093460083, 1.1735999584197998, 0.958299994468689, 1.0921000242233276, 1.2188999652862549, 1.2340999841690063, 0.8791000247001648, 0.4025000035762787, 0.42879998683929443, 0.8202999830245972, 0.5016999840736389, -0.019099999219179153, 0.3831000030040741, 0.7476000189781189, 0.41589999198913574, 0.6707000136375427, 0.011800000444054604, 0.3450999855995178, 0.3684000074863434, 0.0949999988079071, 0.46160000562667847, -0.039000000804662704, -0.27810001373291016, -1.6095000505447388, -0.4706000089645386, 1.871999979019165, 1.8279000520706177, 1.8169000148773193, 1.7825000286102295, 1.7549999952316284, 1.7547999620437622, 1.7544000148773193, 1.7544000148773193, 1.75409996509552, 1.7538000345230103, 1.753499984741211, 1.7096999883651733, 1.7093000411987305, 1.7091000080108643, 1.6279000043869019, 1.6277999877929688, 1.6277999877929688, 1.6276999711990356, 1.6274000406265259, 1.6274000406265259, 1.6274000406265259, 1.6274000406265259, 1.6272000074386597, 1.6272000074386597, 1.6272000074386597, 1.6270999908447266, 1.6270999908447266, 1.6269999742507935, 1.6267999410629272, 1.6267999410629272, 1.6193000078201294, 1.4629000425338745, 1.4423999786376953, 1.5485999584197998, 1.4947999715805054, 1.3307000398635864, 1.080899953842163, 1.4616999626159668, 1.4068000316619873, 1.4778000116348267, 1.1013000011444092, 1.273900032043457, 1.4138000011444092, 1.3250999450683594, 1.0008000135421753, 1.007699966430664, 0.9474999904632568, 0.6784999966621399, 0.862500011920929, 0.8357999920845032, 0.9089999794960022, 1.0009000301361084, 0.8263000249862671, 0.6377999782562256, 0.7386000156402588, -0.21359999477863312, 0.35850000381469727, 0.4925000071525574, 1.256500005722046, 0.9847999811172485, -0.26249998807907104, 0.5975000262260437, 0.1826999932527542, 0.11680000275373459, 0.2646999955177307, 0.7210999727249146, 0.16300000250339508, 0.14890000224113464, -0.061500001698732376, -0.13109999895095825, 0.22609999775886536, 2.6424999237060547, 2.608799934387207, 2.578700065612793, 2.5427000522613525, 2.492000102996826, 2.4916999340057373, 2.4897000789642334, 2.402600049972534, 2.4010000228881836, 2.3998000621795654, 2.399600028991699, 2.3994998931884766, 2.3993000984191895, 2.3982999324798584, 2.3951001167297363, 2.393399953842163, 2.316800117492676, 2.313800096511841, 2.3006999492645264, 2.2030999660491943, 2.180299997329712, 2.1774001121520996, 2.176500082015991, 2.176300048828125, 2.1760001182556152, 2.1758999824523926, 2.17549991607666, 2.1754000186920166, 2.175299882888794, 2.1751999855041504, 2.132699966430664, 2.0641000270843506, 2.059499979019165, 1.8220000267028809, 1.717900037765503, 2.0332000255584717, 1.541200041770935, 2.0304999351501465, 1.6491999626159668, 1.9036999940872192, 1.5600999593734741, 1.648300051689148, 0.7975999712944031, 1.226699948310852, 0.9312999844551086, 1.1614999771118164, -0.2736999988555908, 1.5592999458312988, 0.7700999975204468, 0.9768999814987183, 1.497499942779541, 1.4605000019073486, 0.8425999879837036, 1.0923999547958374, 0.5845000147819519, 0.5552999973297119, 0.09679999947547913, 0.46799999475479126, -0.07440000027418137, -0.7555999755859375, -0.09279999881982803, -0.7418000102043152, -0.44769999384880066, 0.4458000063896179, 0.49390000104904175, -0.21719999611377716, 0.8931999802589417, 2.7054998874664307, 2.688199996948242, 2.670599937438965, 2.636199951171875, 2.6166999340057373, 2.615499973297119, 2.6001999378204346, 2.517899990081787, 2.517699956893921, 2.517699956893921, 2.517400026321411, 2.517199993133545, 2.516200065612793, 2.515700101852417, 2.513400077819824, 2.496299982070923, 2.4762001037597656, 2.4728000164031982, 2.4718000888824463, 2.4556000232696533, 2.3427000045776367, 2.323899984359741, 2.319499969482422, 2.286099910736084, 2.285799980163574, 2.285799980163574, 2.285799980163574, 2.2857000827789307, 2.285599946975708, 2.285599946975708, 2.2551000118255615, 2.2172999382019043, 2.093899965286255, 2.2112998962402344, 2.118499994277954, 2.117799997329712, 2.170599937438965, 1.909000039100647, 1.753000020980835, 1.8152999877929688, 1.607100009918213, 1.593000054359436, 1.8639999628067017, 0.5001000165939331, 1.5794999599456787, 1.8055000305175781, -0.05079999938607216, 1.7404999732971191, 1.2096999883651733, 1.1973999738693237, 0.6662999987602234, 0.847100019454956, 0.642300009727478, 1.480299949645996, 0.5533999800682068, -0.03629999980330467, 0.3903000056743622, 0.10040000081062317, 0.6394000053405762, 0.09950000047683716, -0.5026000142097473, 0.7551000118255615, 1.3549000024795532, 3.002500057220459, 2.9993999004364014, 2.890399932861328, 2.8329999446868896, 2.8310999870300293, 2.830899953842163, 2.8301000595092773, 2.8287999629974365, 2.827699899673462, 2.7407000064849854, 2.579200029373169, 2.5790998935699463, 2.5787999629974365, 2.5782999992370605, 2.5782999992370605, 2.5782999992370605, 2.578000068664551, 2.577500104904175, 2.577399969100952, 2.5771000385284424, 2.5769999027252197, 2.576900005340576, 2.576900005340576, 2.5768001079559326, 2.5768001079559326, 2.5768001079559326, 2.57669997215271, 2.57669997215271, 2.57669997215271, 2.57669997215271, 2.5146000385284424, 2.33489990234375, 2.451900005340576, 1.9697999954223633, 1.9937000274658203, 1.6171000003814697, 1.7795000076293945, 1.5002000331878662, 2.2460999488830566, 1.988700032234192, 2.186300039291382, 0.8737000226974487, 1.6418999433517456, 1.483299970626831, 1.0125999450683594, 0.7675999999046326, 1.495300054550171, 1.9701999425888062, 0.35519999265670776, 1.0027999877929688, 0.7789999842643738, 0.5029000043869019, -0.5205000042915344, 0.6274999976158142, -0.42640000581741333, 1.0029000043869019, 0.094200000166893, 0.576200008392334, 0.566100001335144, 1.2051000595092773, 1.1512000560760498, -0.06710000336170197, 1.006700038909912, -0.09700000286102295, 0.32600000500679016, 3.2204999923706055, 3.1751999855041504, 3.1038999557495117, 3.047499895095825, 3.0392000675201416, 3.036099910736084, 3.0157999992370605, 2.9321000576019287, 2.9260001182556152, 2.92549991607666, 2.924799919128418, 2.7915000915527344, 2.733299970626831, 2.671099901199341, 2.670799970626831, 2.6707000732421875, 2.6707000732421875, 2.670599937438965, 2.670599937438965, 2.670599937438965, 2.670599937438965, 2.6705000400543213, 2.6703999042510986, 2.6703999042510986, 2.670300006866455, 2.670099973678589, 2.6700000762939453, 2.6695001125335693, 2.669300079345703, 2.669100046157837, 2.60479998588562, 2.5436999797821045, 2.539799928665161, 2.536600112915039, 2.535799980163574, 2.517199993133545, 2.515500068664551, 2.0023000240325928, 2.321899890899658, 2.0553998947143555, 2.0710999965667725, 2.162600040435791, 2.316699981689453, 2.313999891281128, 1.7764999866485596, 1.7762999534606934, 1.1992000341415405, 1.885599970817566, 1.5169999599456787, 1.5096999406814575, 1.0967999696731567, 1.8698999881744385, -0.3483000099658966, 0.6341999769210815, 1.093999981880188, 0.9677000045776367, 0.732699990272522, 1.6380000114440918, -0.9491000175476074, 0.30799999833106995, 0.0333000011742115, -0.20589999854564667, -0.5566999912261963, 0.26100000739097595, 0.31709998846054077, 0.36959999799728394, 0.3912000060081482, 3.990799903869629, 3.720900058746338, 3.3635001182556152, 3.3631999492645264, 3.3631999492645264, 3.363100051879883, 3.36299991607666, 3.36299991607666, 3.362799882888794, 3.362799882888794, 3.362799882888794, 3.3626999855041504, 3.362499952316284, 3.362299919128418, 3.3622000217437744, 3.3620998859405518, 3.361999988555908, 3.361599922180176, 3.3071000576019287, 3.297300100326538, 3.2339000701904297, 2.8991000652313232, 2.7607998847961426, 2.7585999965667725, 2.7578999996185303, 2.751800060272217, 2.7462000846862793, 2.745800018310547, 2.7451000213623047, 2.7446999549865723, 2.6524999141693115, 2.6284000873565674, 2.6194000244140625, 1.9417999982833862, 2.1512999534606934, 1.7697999477386475, 2.026599884033203, 1.0285999774932861, 0.6586999893188477, 0.7882000207901001, 0.7138000130653381, 0.4733000099658966, 1.336300015449524, 1.2702000141143799, 0.6983000040054321, 0.5317000150680542, 0.46389999985694885, 2.3921000957489014, -2.0636000633239746, -1.8013999462127686, 2.1305999755859375, -0.8440999984741211, -0.7049999833106995, -0.5597000122070312]}, \"token.table\": {\"Topic\": [1, 4, 4, 1, 2, 3, 4, 5, 7, 1, 1, 3, 6, 4, 2, 7, 1, 2, 3, 4, 5, 4, 4, 2, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 7, 1, 4, 5, 7, 1, 2, 3, 4, 5, 7, 2, 1, 7, 1, 2, 4, 1, 2, 4, 5, 7, 4, 1, 2, 3, 4, 5, 7, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 2, 1, 2, 3, 4, 5, 6, 7, 4, 5, 1, 4, 3, 7, 2, 5, 2, 4, 1, 2, 3, 4, 6, 7, 1, 2, 3, 6, 1, 2, 7, 6, 4, 7, 4, 1, 2, 3, 4, 1, 3, 1, 2, 4, 1, 2, 3, 6, 8, 2, 1, 2, 3, 5, 7, 6, 2, 1, 6, 7, 2, 5, 7, 1, 1, 2, 4, 5, 4, 1, 1, 2, 3, 4, 6, 7, 8, 1, 2, 7, 4, 2, 4, 6, 8, 6, 4, 3, 1, 3, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 5, 1, 2, 3, 1, 2, 3, 4, 6, 7, 1, 2, 3, 5, 6, 7, 1, 2, 3, 4, 5, 7, 6, 2, 3, 7, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 3, 5, 1, 1, 1, 2, 3, 4, 5, 6, 8, 2, 5, 7, 3, 6, 7, 1, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 6, 7, 1, 2, 4, 5, 6, 6, 1, 2, 3, 5, 6, 7, 1, 1, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 5, 7, 2, 3, 7, 3, 3, 3, 2, 3, 5, 1, 1, 2, 3, 4, 6, 8, 1, 2, 5, 4, 6, 1, 2, 3, 4, 5, 6, 7, 2, 5, 1, 2, 3, 5, 8, 1, 4, 5, 4, 4, 2, 6, 1, 2, 3, 4, 5, 7, 1, 2, 1, 3, 5, 1, 2, 3, 4, 6, 7, 3, 4, 3, 5, 6, 1, 4, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 7, 8, 7, 4, 8, 2, 7, 3, 5, 1, 6, 1, 1, 1, 4, 1, 2, 5, 6, 7, 1, 2, 5, 7, 8, 6, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 6, 7, 4, 4, 3, 1, 4, 6, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 5, 1, 2, 3, 4, 5, 6, 1, 3, 7, 4, 1, 2, 3, 5, 2, 3, 5, 1, 2, 3, 6, 7, 3, 1, 5, 1, 3, 1, 2, 2, 1, 3, 5, 2, 7, 8, 1, 2, 3, 7, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 2, 1, 5, 1, 2, 3, 4, 5, 3, 6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 6, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 3, 1, 6, 7, 1, 2, 3, 4, 6, 4, 5, 3, 1, 2, 4, 6, 1, 2, 3, 6, 7, 3, 1, 2, 3, 4, 5, 1, 2, 3, 6, 1, 5, 7, 3, 1, 3, 1, 2, 3, 4, 5, 6, 8, 3, 3, 7, 3, 6, 6, 7, 5, 6, 6, 6, 7, 1, 2, 4, 5, 2, 3, 7, 1, 6, 1, 2, 4, 6, 6, 6, 1, 3, 5, 8, 1, 2, 3, 4, 5, 7, 3, 1, 1, 3, 4, 5, 6, 7, 1, 1, 3, 5, 4, 4, 1, 2, 3, 4, 5, 6, 7, 6, 3, 1, 3, 5, 1, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 4, 6, 7, 7, 1, 2, 5, 2, 7, 7, 3, 2, 3, 4, 1, 2, 7, 1, 2, 3, 2, 5, 4, 3, 4, 1, 1, 2, 3, 4, 6, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 5, 1, 2, 4, 1, 3, 4, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 8, 2, 3, 1, 2, 3, 4, 5, 7, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 2, 6, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 3, 4, 4, 6, 2, 3, 4, 8, 4, 5, 1, 2, 5, 8, 3, 1, 2, 3, 7, 2, 2, 5, 7, 6, 2, 3, 1, 5, 3, 4, 1, 5, 1, 2, 3, 1, 2, 3, 6, 6, 1, 2, 5, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 6, 7, 6, 1, 2, 4, 6, 6, 6, 1, 3, 2, 2, 7, 6, 4, 4, 7, 1, 4, 1, 2, 4, 5, 5, 1, 2, 1, 2, 7, 2, 3, 4, 7, 1, 2, 2, 6, 1, 2, 3, 3, 5, 3, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 7, 3, 4, 7, 1, 3, 2, 3, 3, 1, 2, 3, 4, 5, 6, 7, 3, 1, 2, 3, 6, 1, 2, 3, 4, 5, 7, 3, 3, 2, 5, 7, 6, 1, 2, 3, 4, 3, 1, 2, 4, 7, 1, 7, 7, 1, 2, 3, 4, 5, 1, 2, 8, 1, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 5, 5, 1, 2, 1, 2, 3, 4, 1, 3, 1, 5, 7, 5, 5, 1, 2, 3, 7, 6, 2, 1, 7, 1, 2, 3, 5, 7, 2, 1, 1, 3, 5, 5, 2, 3, 5, 5, 1, 3, 6, 5, 4, 1, 2, 3, 4, 6, 7, 1, 8, 6, 1, 2, 7, 1, 2, 5, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 6, 1, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 3, 5, 7, 2, 1, 2, 3, 4, 5, 6, 8, 2], \"Freq\": [0.32257628440856934, 0.6451525688171387, 0.9298567771911621, 0.39467307925224304, 0.02466706745326519, 0.3700059950351715, 0.07400120049715042, 0.02466706745326519, 0.1233353316783905, 0.9378748536109924, 0.3444123864173889, 0.5740206241607666, 0.7591265439987183, 0.9309009313583374, 0.3623185455799103, 0.3623185455799103, 0.22932219505310059, 0.3822036683559418, 0.0764407366514206, 0.1528814733028412, 0.22932219505310059, 0.7003726363182068, 0.7003310918807983, 0.35494154691696167, 0.35494154691696167, 0.24773874878883362, 0.1415649950504303, 0.35391250252723694, 0.10617375373840332, 0.07078249752521515, 0.10617375373840332, 0.5514859557151794, 0.19302009046077728, 0.08272289484739304, 0.06893574446439743, 0.02757429890334606, 0.04136144742369652, 0.01378714945167303, 0.7777121663093567, 0.4881373345851898, 0.09762746840715408, 0.39050987362861633, 0.09762746840715408, 0.7036818265914917, 0.04398011416196823, 0.04398011416196823, 0.08796022832393646, 0.04398011416196823, 0.04398011416196823, 0.5197509527206421, 0.9173159003257751, 0.7774510383605957, 0.18404558300971985, 0.18404558300971985, 0.5521367788314819, 0.09866111725568771, 0.49330559372901917, 0.09866111725568771, 0.09866111725568771, 0.19732223451137543, 0.9297226667404175, 0.3964295983314514, 0.3083341121673584, 0.04404773190617561, 0.04404773190617561, 0.17619092762470245, 0.04404773190617561, 0.9171547293663025, 0.8915790319442749, 0.5554926991462708, 0.11109853535890579, 0.0833239033818245, 0.0833239033818245, 0.027774633839726448, 0.0833239033818245, 0.055549267679452896, 0.027774633839726448, 0.8901992440223694, 0.5981826782226562, 0.14242444932460785, 0.08545467257499695, 0.0284848902374506, 0.0569697804749012, 0.0569697804749012, 0.0569697804749012, 0.9301900267601013, 0.7125452756881714, 0.902640163898468, 0.06017601117491722, 0.9651682376861572, 0.8171188235282898, 0.5164275765419006, 0.5164275765419006, 0.891116201877594, 0.7004321813583374, 0.09543526917695999, 0.7634821534156799, 0.09543526917695999, 0.047717634588479996, 0.023858817294239998, 0.534394383430481, 0.3231884241104126, 0.2693236768245697, 0.215458944439888, 0.215458944439888, 0.127221941947937, 0.7633316516876221, 0.7777858376502991, 0.7589216232299805, 0.38598883152008057, 0.38598883152008057, 0.7933576107025146, 0.4824090600013733, 0.30467939376831055, 0.15233969688415527, 0.05077990144491196, 0.9741212129592896, 0.5271979570388794, 0.18598315119743347, 0.650941014289856, 0.09299157559871674, 0.6295731663703918, 0.0699525773525238, 0.20985771715641022, 0.0699525773525238, 0.0699525773525238, 0.8063582181930542, 0.7431233525276184, 0.1061604768037796, 0.0530802384018898, 0.0530802384018898, 0.0530802384018898, 0.7591233253479004, 0.8914813995361328, 0.5074697136878967, 0.16915656626224518, 0.33831313252449036, 0.43682098388671875, 0.43682098388671875, 0.7777175903320312, 0.9173886179924011, 0.09029577672481537, 0.09029577672481537, 0.3611831068992615, 0.3611831068992615, 0.9299864768981934, 0.9380221366882324, 0.28813013434410095, 0.28813013434410095, 0.34051743149757385, 0.02619364857673645, 0.02619364857673645, 0.02619364857673645, 0.02619364857673645, 0.2986660897731781, 0.2986660897731781, 0.2986660897731781, 0.7003393769264221, 0.4552188217639923, 0.15173961222171783, 0.30347922444343567, 0.15173961222171783, 0.7591464519500732, 0.7003360986709595, 0.9650536179542542, 0.21587510406970978, 0.6476253271102905, 0.14391674101352692, 0.18932737410068512, 0.18932737410068512, 0.4327482581138611, 0.1352338343858719, 0.027046766132116318, 0.2712855935096741, 0.12331163138151169, 0.4315907061100006, 0.1479739546775818, 0.024662325158715248, 0.012331162579357624, 0.4882201850414276, 0.1220550462603569, 0.3661651313304901, 0.9381483793258667, 0.1696443408727646, 0.6785773634910583, 0.44022366404533386, 0.24762581288814545, 0.19259785115718842, 0.027513979002833366, 0.08254193514585495, 0.027513979002833366, 0.38321027159690857, 0.0821164920926094, 0.41058245301246643, 0.02737216278910637, 0.0821164920926094, 0.02737216278910637, 0.3851619064807892, 0.12838730216026306, 0.08559153228998184, 0.2139788419008255, 0.12838730216026306, 0.08559153228998184, 0.5181862711906433, 0.7719525098800659, 0.12865875661373138, 0.7777544856071472, 0.777691125869751, 0.6353349089622498, 0.09927108138799667, 0.1786879450082779, 0.019854215905070305, 0.019854215905070305, 0.019854215905070305, 0.03970843181014061, 0.47407597303390503, 0.13168777525424957, 0.18436287343502045, 0.10535021871328354, 0.026337554678320885, 0.05267510935664177, 0.5920177698135376, 0.16914793848991394, 0.2537219226360321, 0.9530315399169922, 0.937532901763916, 0.39976805448532104, 0.19119341671466827, 0.20857463777065277, 0.05214365944266319, 0.06952487677335739, 0.06952487677335739, 0.017381219193339348, 0.19570223987102509, 0.5871067047119141, 0.7777047157287598, 0.19080550968647003, 0.7632220387458801, 0.777675211429596, 0.9381971955299377, 0.7125231623649597, 0.5577718615531921, 0.1014130637049675, 0.12676632404327393, 0.1014130637049675, 0.05070653185248375, 0.025353265926241875, 0.025353265926241875, 0.7550250291824341, 0.060402002185583115, 0.060402002185583115, 0.030201001092791557, 0.030201001092791557, 0.060402002185583115, 0.12768052518367767, 0.3830415606498718, 0.12768052518367767, 0.3830415606498718, 0.9503185153007507, 0.5182448625564575, 0.636380672454834, 0.11454851925373077, 0.07636567950248718, 0.050910450518131256, 0.08909329026937485, 0.012727612629532814, 0.9374558925628662, 0.3547935485839844, 0.3547935485839844, 0.49521610140800476, 0.18983283638954163, 0.11555042862892151, 0.03301440551877022, 0.09078961610794067, 0.057775214314460754, 0.01650720275938511, 0.23005293309688568, 0.5751323699951172, 0.11502646654844284, 0.038342155516147614, 0.038342155516147614, 0.038342155516147614, 0.3696127235889435, 0.3696127235889435, 0.772159218788147, 0.12869320809841156, 0.534233033657074, 0.5273762941360474, 0.8248159289360046, 0.8247807025909424, 0.8084644675254822, 0.11549492180347443, 0.4758390188217163, 0.9380395412445068, 0.46826982498168945, 0.20068706572055817, 0.13379137217998505, 0.06689568608999252, 0.13379137217998505, 0.06689568608999252, 0.05611465126276016, 0.7294904589653015, 0.16834396123886108, 0.5734798312187195, 0.28673991560935974, 0.5047852993011475, 0.19752468168735504, 0.08778874576091766, 0.021947186440229416, 0.04389437288045883, 0.10973593592643738, 0.021947186440229416, 0.27119380235671997, 0.5423876047134399, 0.267864465713501, 0.267864465713501, 0.267864465713501, 0.1339322328567505, 0.1339322328567505, 0.3226820230484009, 0.6453640460968018, 0.7127042412757874, 0.9700074791908264, 0.9289806485176086, 0.8916119337081909, 0.7590634822845459, 0.376016765832901, 0.31334730982780457, 0.1880083829164505, 0.06266946345567703, 0.031334731727838516, 0.031334731727838516, 0.9741477370262146, 0.8913174867630005, 0.2966594099998474, 0.49443235993385315, 0.09888646751642227, 0.13482393324375153, 0.31458917260169983, 0.359530508518219, 0.15729458630084991, 0.022470656782388687, 0.022470656782388687, 0.9133632183074951, 0.695556640625, 0.7329274415969849, 0.18323186039924622, 0.18323186039924622, 0.22025765478610992, 0.660772979259491, 0.3320375084877014, 0.6640750169754028, 0.4866196811199188, 0.2919718027114868, 0.12976524233818054, 0.097323939204216, 0.439261257648468, 0.073210209608078, 0.0976136177778244, 0.292840838432312, 0.0244034044444561, 0.0244034044444561, 0.0244034044444561, 0.7777596712112427, 0.47793614864349365, 0.47793614864349365, 0.36313682794570923, 0.36313682794570923, 0.8248735070228577, 0.7127026319503784, 0.24382387101650238, 0.731471598148346, 0.9739500880241394, 0.9508516192436218, 0.2613828182220459, 0.5227656364440918, 0.38175755739212036, 0.1272525191307068, 0.0636262595653534, 0.19087877869606018, 0.2545050382614136, 0.5986618995666504, 0.0748327374458313, 0.0748327374458313, 0.0748327374458313, 0.1496654748916626, 0.517953097820282, 0.17549246549606323, 0.17549246549606323, 0.5849748849868774, 0.058497488498687744, 0.058497488498687744, 0.9728751182556152, 0.38818055391311646, 0.1791602522134781, 0.20902030169963837, 0.05972008407115936, 0.05972008407115936, 0.05972008407115936, 0.02986004203557968, 0.02986004203557968, 0.29221537709236145, 0.09740512073040009, 0.09740512073040009, 0.29221537709236145, 0.09740512073040009, 0.09740512073040009, 0.3499828577041626, 0.13999314606189728, 0.13999314606189728, 0.20998971164226532, 0.20998971164226532, 0.6953935623168945, 0.7008193135261536, 0.8248580098152161, 0.5492546558380127, 0.27462732791900635, 0.7591199278831482, 0.42497915029525757, 0.2833194434642792, 0.18887962400913239, 0.023609953001141548, 0.0708298608660698, 0.023609953001141548, 0.10321459174156189, 0.30964377522468567, 0.41285836696624756, 0.051607295870780945, 0.10321459174156189, 0.8200929760932922, 0.10934572666883469, 0.05467286333441734, 0.05467286333441734, 0.9380552768707275, 0.47584301233291626, 0.5110083222389221, 0.046455301344394684, 0.23227651417255402, 0.09291060268878937, 0.09291060268878937, 0.023227650672197342, 0.2566356658935547, 0.5132713317871094, 0.2566356658935547, 0.9254289269447327, 0.064665287733078, 0.452657014131546, 0.387991726398468, 0.064665287733078, 0.8915391564369202, 0.9649429321289062, 0.4759780764579773, 0.37091657519340515, 0.18545828759670258, 0.09272914379835129, 0.27818745374679565, 0.09272914379835129, 0.8247148990631104, 0.9639137387275696, 0.7127343416213989, 0.3542674481868744, 0.3542674481868744, 0.07584990561008453, 0.9101988673210144, 0.7787014842033386, 0.898481011390686, 0.03593923896551132, 0.03593923896551132, 0.36233624815940857, 0.36233624815940857, 0.49244260787963867, 0.46655547618865967, 0.11663886904716492, 0.11663886904716492, 0.23327773809432983, 0.22895246744155884, 0.05723811686038971, 0.34342870116233826, 0.05723811686038971, 0.28619059920310974, 0.7303812503814697, 0.09129765629768372, 0.11412206292152405, 0.04564882814884186, 0.02282441407442093, 0.7777509689331055, 0.17358455061912537, 0.6075459122657776, 0.17358455061912537, 0.017358453944325447, 0.034716907888650894, 0.017358453944325447, 0.9399555325508118, 0.9428269863128662, 0.04489652439951897, 0.24947096407413483, 0.41578492522239685, 0.16631397604942322, 0.12473548203706741, 0.041578494012355804, 0.9133631587028503, 0.7590583562850952, 0.813978910446167, 0.8513370156288147, 0.05675579980015755, 0.05675579980015755, 0.8146374225616455, 0.4641004502773285, 0.38675037026405334, 0.07735007256269455, 0.038675036281347275, 0.038675036281347275, 0.5692321062088013, 0.16263775527477264, 0.08131887763738632, 0.24395662546157837, 0.46326178312301636, 0.20383518934249878, 0.18530471622943878, 0.0370609425008297, 0.0370609425008297, 0.0370609425008297, 0.01853047125041485, 0.9132832884788513, 0.28900569677352905, 0.28900569677352905, 0.28900569677352905, 0.48076537251472473, 0.10302115231752396, 0.274723082780838, 0.03434038534760475, 0.10302115231752396, 0.35418570041656494, 0.35418570041656494, 0.8248921036720276, 0.7184352278709412, 0.06531229615211487, 0.13062459230422974, 0.13062459230422974, 0.42021891474723816, 0.14007297158241272, 0.21010945737361908, 0.07003648579120636, 0.21010945737361908, 0.8249931335449219, 0.3115962743759155, 0.20773084461688995, 0.20773084461688995, 0.20773084461688995, 0.05193271115422249, 0.59915691614151, 0.04279692471027374, 0.25678154826164246, 0.12839077413082123, 0.21348774433135986, 0.21348774433135986, 0.4269754886627197, 0.8248015642166138, 0.27646908164024353, 0.5529381632804871, 0.7046712636947632, 0.03809034079313278, 0.09522584825754166, 0.03809034079313278, 0.057135507464408875, 0.03809034079313278, 0.01904517039656639, 0.8919978737831116, 0.9228689074516296, 0.777493953704834, 0.9650457501411438, 0.7590991854667664, 0.7589854598045349, 0.777698278427124, 0.7246163487434387, 0.24153877794742584, 0.759101152420044, 0.5177926421165466, 0.7777193188667297, 0.20419718325138092, 0.10209859162569046, 0.10209859162569046, 0.612591564655304, 0.9281882643699646, 0.8248471617698669, 0.7776880860328674, 0.8465784192085266, 0.11287712305784225, 0.18753673136234283, 0.09376836568117142, 0.28130510449409485, 0.37507346272468567, 0.5182191133499146, 0.7589911818504333, 0.5307137966156006, 0.3538092076778412, 0.07076184451580048, 0.03538092225790024, 0.27828601002693176, 0.06957150250673294, 0.20871451497077942, 0.27828601002693176, 0.06957150250673294, 0.06957150250673294, 0.824798583984375, 0.9381912350654602, 0.33225083351135254, 0.13290032744407654, 0.06645016372203827, 0.2658006548881531, 0.06645016372203827, 0.13290032744407654, 0.9374009966850281, 0.6627357006072998, 0.13254714012145996, 0.17672951519489288, 0.700798749923706, 0.8332750201225281, 0.501501739025116, 0.04179181531071663, 0.16716726124286652, 0.125375434756279, 0.125375434756279, 0.04179181531071663, 0.04179181531071663, 0.759061336517334, 0.824729859828949, 0.2170560508966446, 0.2170560508966446, 0.4341121017932892, 0.5089905858039856, 0.3088896572589874, 0.5868903398513794, 0.030888965353369713, 0.061777930706739426, 0.030888965353369713, 0.19230996072292328, 0.013736425898969173, 0.6318755745887756, 0.041209276765584946, 0.013736425898969173, 0.08241855353116989, 0.013736425898969173, 0.9199538826942444, 0.7279213070869446, 0.14558427035808563, 0.09705617278814316, 0.04852808639407158, 0.5343254804611206, 0.9515901803970337, 0.10465312004089355, 0.2093062400817871, 0.7325718402862549, 0.36260533332824707, 0.36260533332824707, 0.7777647376060486, 0.8247984051704407, 0.45117127895355225, 0.22558563947677612, 0.3383784592151642, 0.3769533038139343, 0.3769533038139343, 0.25130221247673035, 0.03163938969373703, 0.7593453526496887, 0.18983633816242218, 0.15432506799697876, 0.7716253995895386, 0.9297663569450378, 0.33220353722572327, 0.6644070744514465, 0.9815314412117004, 0.576805591583252, 0.1357189565896988, 0.10178922116756439, 0.1357189565896988, 0.0339297391474247, 0.27204784750938416, 0.27204784750938416, 0.27204784750938416, 0.4248947203159332, 0.03862679377198219, 0.23176077008247375, 0.07725358754396439, 0.07725358754396439, 0.03862679377198219, 0.07725358754396439, 0.4724809229373932, 0.3291809558868408, 0.2743174731731415, 0.38404446840286255, 0.5064036250114441, 0.10128072649240494, 0.10128072649240494, 0.10128072649240494, 0.20256145298480988, 0.35797119140625, 0.1534162312746048, 0.1534162312746048, 0.0511387437582016, 0.3068324625492096, 0.0511387437582016, 0.23817747831344604, 0.5081119537353516, 0.14290648698806763, 0.06351399421691895, 0.03175699710845947, 0.015878498554229736, 0.416931688785553, 0.16677267849445343, 0.16677267849445343, 0.16677267849445343, 0.08338633924722672, 0.08338633924722672, 0.7260783910751343, 0.14521567523479462, 0.2899796664714813, 0.3015788495540619, 0.2899796664714813, 0.057995930314064026, 0.034797560423612595, 0.02319837175309658, 0.7007428407669067, 0.8531886339187622, 0.5012677907943726, 0.2915537357330322, 0.11764448881149292, 0.030689867213368416, 0.010229955427348614, 0.02557488903403282, 0.02557488903403282, 0.9026248455047607, 0.09026248008012772, 0.7968505024909973, 0.13280841708183289, 0.44245436787605286, 0.28156188130378723, 0.18100406229496002, 0.040223125368356705, 0.020111562684178352, 0.020111562684178352, 0.020111562684178352, 0.9636120200157166, 0.337837278842926, 0.06756745278835297, 0.5405396223068237, 0.06756745278835297, 0.3770165741443634, 0.3770165741443634, 0.14403536915779114, 0.14403536915779114, 0.2880707383155823, 0.2880707383155823, 0.7003254294395447, 0.4750654101371765, 0.7531366944313049, 0.12552277743816376, 0.06276138871908188, 0.06276138871908188, 0.7995257377624512, 0.4988064765930176, 0.0623508095741272, 0.4052802622318268, 0.0311754047870636, 0.8057937622070312, 0.5198855996131897, 0.31735455989837646, 0.6347091197967529, 0.7591758370399475, 0.7788735032081604, 0.9650049805641174, 0.937606155872345, 0.7126010656356812, 0.9650673866271973, 0.9300969839096069, 0.2667757570743561, 0.5335515141487122, 0.1747799962759018, 0.6991199851036072, 0.0873899981379509, 0.27097266912460327, 0.6503344178199768, 0.054194532334804535, 0.054194532334804535, 0.7590369582176208, 0.24525685608386993, 0.6540182828903198, 0.08175228536128998, 0.7591774463653564, 0.027113480493426323, 0.10845392197370529, 0.027113480493426323, 0.027113480493426323, 0.027113480493426323, 0.4648757576942444, 0.1549585908651352, 0.1162189394235611, 0.1549585908651352, 0.0387396477162838, 0.0774792954325676, 0.7590779662132263, 0.5136253833770752, 0.23346607387065887, 0.18677286803722382, 0.046693217009305954, 0.7590929865837097, 0.7590113878250122, 0.8282207250595093, 0.12741857767105103, 0.9725224375724792, 0.29936641454696655, 0.5987328290939331, 0.7590864300727844, 0.7006113529205322, 0.9292888641357422, 0.5354727506637573, 0.22006607055664062, 0.6601982116699219, 0.4135124683380127, 0.10337811708450317, 0.3101343512535095, 0.10337811708450317, 0.7142525911331177, 0.8105742931365967, 0.1350957155227661, 0.09274169057607651, 0.5564501285552979, 0.2782250642776489, 0.19208191335201263, 0.19208191335201263, 0.38416382670402527, 0.19208191335201263, 0.8321558237075806, 0.08321557939052582, 0.9405103325843811, 0.7591195702552795, 0.9731191396713257, 0.9011402130126953, 0.06007601320743561, 0.3375145494937897, 0.3375145494937897, 0.5271055698394775, 0.1547269970178604, 0.23209050297737122, 0.3094539940357208, 0.0773634985089302, 0.3094539940357208, 0.8912534117698669, 0.6027210354804993, 0.15068025887012482, 0.15068025887012482, 0.04305150359869003, 0.021525751799345016, 0.021525751799345016, 0.021525751799345016, 0.5055840015411377, 0.10111680626869202, 0.13482239842414856, 0.10111680626869202, 0.06741119921207428, 0.03370559960603714, 0.03370559960603714, 0.5346656441688538, 0.13366641104221344, 0.20049960911273956, 0.13366641104221344, 0.9339694380760193, 0.28973594307899475, 0.28973594307899475, 0.28973594307899475, 0.2898292541503906, 0.5796585083007812, 0.7717563509941101, 0.12862606346607208, 0.824908971786499, 0.4137432277202606, 0.2068716138601303, 0.06895720213651657, 0.13791440427303314, 0.06895720213651657, 0.13791440427303314, 0.06895720213651657, 0.8249377608299255, 0.1817687451839447, 0.1817687451839447, 0.5453062653541565, 0.09088437259197235, 0.49794578552246094, 0.12448644638061523, 0.27387017011642456, 0.049794577062129974, 0.024897288531064987, 0.049794577062129974, 0.8245395421981812, 0.8249379396438599, 0.28890833258628845, 0.28890833258628845, 0.28890833258628845, 0.6062184572219849, 0.517741858959198, 0.1294354647397995, 0.32358863949775696, 0.032358866184949875, 0.9651719927787781, 0.303276002407074, 0.606552004814148, 0.0673946663737297, 0.03369733318686485, 0.17439135909080505, 0.6975654363632202, 0.658296525478363, 0.807614803314209, 0.05768676847219467, 0.11537353694438934, 0.05768676847219467, 0.7144438624382019, 0.4824502766132355, 0.24122513830661774, 0.24122513830661774, 0.14981329441070557, 0.5992531776428223, 0.14981329441070557, 0.7955657243728638, 0.037350501865148544, 0.022410301491618156, 0.0485556535422802, 0.05229070410132408, 0.022410301491618156, 0.014940201304852962, 0.5468601584434509, 0.04971455782651901, 0.07457184046506882, 0.04971455782651901, 0.09942911565303802, 0.19885823130607605, 0.024857278913259506, 0.4733089506626129, 0.8127202987670898, 0.9027508497238159, 0.09027508646249771, 0.32570746541023254, 0.4760339856147766, 0.12527209520339966, 0.05010884255170822, 0.8636343479156494, 0.07196952402591705, 0.6033197641372681, 0.3248645067214966, 0.04640921577811241, 0.8574130535125732, 0.47586527466773987, 0.4784354567527771, 0.13048239052295685, 0.3044589161872864, 0.08698826283216476, 0.5181544423103333, 0.8914015889167786, 0.3546832203865051, 0.3546832203865051, 0.46576398611068726, 0.15525466203689575, 0.19961313903331757, 0.11089619249105453, 0.06653771549463272, 0.5197016000747681, 0.9648038744926453, 0.18852026760578156, 0.18852026760578156, 0.5655608177185059, 0.47577884793281555, 0.861618161201477, 0.0957353487610817, 0.47579869627952576, 0.47576528787612915, 0.4382043778896332, 0.2191021889448166, 0.2191021889448166, 0.9532667398452759, 0.6955393552780151, 0.16731828451156616, 0.22309105098247528, 0.2788638174533844, 0.11154552549123764, 0.16731828451156616, 0.05577276274561882, 0.4379604160785675, 0.4379604160785675, 0.9510906338691711, 0.902813732624054, 0.09028137475252151, 0.7774524688720703, 0.9030922055244446, 0.09030921757221222, 0.7125266790390015, 0.9268704056739807, 0.5270599126815796, 0.1254904568195343, 0.1254904568195343, 0.05019618570804596, 0.10039237141609192, 0.02509809285402298, 0.02509809285402298, 0.5282392501831055, 0.2112956941127777, 0.10564784705638885, 0.15847176313400269, 0.05282392352819443, 0.9532566070556641, 0.7589754462242126, 0.19638316333293915, 0.7855326533317566, 0.6305725574493408, 0.16594015061855316, 0.06637606024742126, 0.13275212049484253, 0.61027991771698, 0.148848757147789, 0.13396388292312622, 0.04465462639927864, 0.014884875155985355, 0.014884875155985355, 0.02976975031197071, 0.4571891129016876, 0.1142972782254219, 0.3428918123245239, 0.1142972782254219, 0.8676324486732483, 0.2281971126794815, 0.456394225358963, 0.15213140845298767, 0.07606570422649384, 0.03803285211324692, 0.03803285211324692, 0.7305169701576233, 0.5200770497322083], \"Term\": [\"ability\", \"ability\", \"academic\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"accord\", \"account\", \"account\", \"actively\", \"actor\", \"additionally\", \"additionally\", \"advantage\", \"advantage\", \"advantage\", \"advantage\", \"advantage\", \"aggregate\", \"aggregation\", \"alignment\", \"alignment\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"analogue\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"annotation\", \"annotation\", \"annotation\", \"annotation\", \"annotation\", \"annotation\", \"apache\", \"applause\", \"approx\", \"archival\", \"archival\", \"archival\", \"article\", \"article\", \"article\", \"article\", \"article\", \"attestation\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"austrian\", \"auto\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"background\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"basically\", \"belong\", \"bibliographic\", \"bibliographic\", \"bookkeepe\", \"bower\", \"break\", \"break\", \"breeze\", \"browser\", \"build\", \"build\", \"build\", \"build\", \"build\", \"cayless\", \"change\", \"change\", \"change\", \"change\", \"check\", \"check\", \"cite\", \"clarify\", \"classification\", \"classification\", \"cmif\", \"collection\", \"collection\", \"collection\", \"collection\", \"comity\", \"commercial\", \"complete\", \"complete\", \"complete\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complicate\", \"component\", \"component\", \"component\", \"component\", \"component\", \"comprehensible\", \"conclusion\", \"conference\", \"conference\", \"conference\", \"connection\", \"connection\", \"continuation\", \"corpu\", \"correspondence\", \"correspondence\", \"correspondence\", \"correspondence\", \"correspsearch\", \"country\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"creation\", \"creation\", \"creation\", \"creator\", \"critical\", \"critical\", \"critical\", \"critical\", \"criticism\", \"cslink\", \"custom\", \"customization\", \"customization\", \"customization\", \"database\", \"database\", \"database\", \"database\", \"database\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"deal\", \"deal\", \"deal\", \"debate\", \"deploy\", \"deploy\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"description\", \"description\", \"description\", \"description\", \"description\", \"description\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"dhip\", \"diagnostic\", \"diagnostic\", \"dialect\", \"dialectal\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"discussion\", \"discussion\", \"discussion\", \"distant_reade\", \"distinctive_feature\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document\", \"dramatic\", \"dramatic\", \"dually\", \"dynamic\", \"dynamic\", \"ed\", \"edge\", \"editable\", \"edition\", \"edition\", \"edition\", \"edition\", \"edition\", \"edition\", \"edition\", \"editor\", \"editor\", \"editor\", \"editor\", \"editor\", \"editor\", \"editorial\", \"editorial\", \"editorial\", \"editorial\", \"egxml\", \"elaborate\", \"element\", \"element\", \"element\", \"element\", \"element\", \"element\", \"eltec\", \"emphasis\", \"emphasis\", \"encode\", \"encode\", \"encode\", \"encode\", \"encode\", \"encode\", \"encode\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoding_initiative\", \"encoding_initiative\", \"ending\", \"ending\", \"engage\", \"engine\", \"entail\", \"enter\", \"entire\", \"entire\", \"enumerate\", \"european\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"event\", \"event\", \"event\", \"examine\", \"examine\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"explicitly\", \"explicitly\", \"extension\", \"extension\", \"extension\", \"extension\", \"extension\", \"extensive\", \"extensive\", \"factoid\", \"fair\", \"fairly\", \"fast\", \"favor\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"female\", \"feminine\", \"field\", \"field\", \"field\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"financial\", \"findable\", \"flexible\", \"flexible\", \"flexible\", \"footnote\", \"footnote\", \"force\", \"force\", \"form\", \"form\", \"form\", \"form\", \"format\", \"format\", \"format\", \"format\", \"format\", \"format\", \"format\", \"formatter\", \"freely\", \"freely\", \"friendly\", \"friendly\", \"fromthepage\", \"funde\", \"genesis\", \"genesis\", \"genetic\", \"graph\", \"guide\", \"guide\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"high\", \"high\", \"high\", \"high\", \"high\", \"highlighting\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"host\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"http\", \"http\", \"http\", \"http\", \"http\", \"http\", \"humanity\", \"humanity\", \"humanity\", \"humanity\", \"humanity\", \"iip\", \"illuminate\", \"im\", \"implementation\", \"implementation\", \"impressively\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"index\", \"index\", \"index\", \"index\", \"index\", \"indicate\", \"indicate\", \"indicate\", \"indicate\", \"influence\", \"informal\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"infrastructure\", \"infrastructure\", \"infrastructure\", \"inscription\", \"instance\", \"instance\", \"instance\", \"instance\", \"instant\", \"integration\", \"interaction\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"investment\", \"japanese\", \"jewish\", \"job\", \"job\", \"label\", \"label\", \"labelling\", \"language\", \"language\", \"language\", \"lately\", \"lately\", \"latex\", \"learn\", \"learn\", \"learn\", \"learn\", \"letter\", \"letter\", \"letter\", \"letter\", \"letter\", \"level\", \"level\", \"level\", \"level\", \"level\", \"lexicographer\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"lineation\", \"linguistic\", \"linguistic\", \"link\", \"link\", \"link\", \"link\", \"link\", \"linkable\", \"listobject\", \"lite\", \"literary\", \"literary\", \"literary\", \"log\", \"long\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"maker\", \"manual\", \"manual\", \"manual\", \"many\", \"many\", \"many\", \"many\", \"many\", \"map\", \"map\", \"mapping\", \"markup\", \"markup\", \"markup\", \"markup\", \"material\", \"material\", \"material\", \"material\", \"material\", \"meanwhile\", \"metadata\", \"metadata\", \"metadata\", \"metadata\", \"metadata\", \"method\", \"method\", \"method\", \"method\", \"methodology\", \"methodology\", \"methodology\", \"mill\", \"minimal\", \"minimal\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"module\", \"mold\", \"morphological\", \"motive\", \"mscontent\", \"msidentifier\", \"mundarten\", \"music\", \"music\", \"musicology\", \"namespace\", \"native\", \"network\", \"network\", \"network\", \"network\", \"night\", \"normally\", \"notably\", \"novel\", \"novel\", \"object\", \"object\", \"object\", \"object\", \"objectification\", \"objectname\", \"odd\", \"odd\", \"odd\", \"odd\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"official\", \"old\", \"online\", \"online\", \"online\", \"online\", \"online\", \"online\", \"ontological\", \"ontology\", \"ontology\", \"ontology\", \"openness\", \"orcid\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"orient\", \"origin\", \"overcome\", \"overcome\", \"overcome\", \"package\", \"page\", \"page\", \"page\", \"page\", \"page\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"parliamentary\", \"particular\", \"particular\", \"particular\", \"particular\", \"partnership\", \"pedagogy\", \"performance\", \"performance\", \"performance\", \"perspective\", \"perspective\", \"philipp\", \"plan\", \"platform\", \"platform\", \"platform\", \"play\", \"play\", \"play\", \"poem\", \"poem\", \"poem\", \"pointer\", \"pointer\", \"poorly\", \"popular\", \"popular\", \"population\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possibly\", \"possibly\", \"possibly\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"press\", \"principle\", \"principle\", \"principle\", \"print\", \"print\", \"print\", \"print\", \"print\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"product\", \"product\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"prominent\", \"promptbook\", \"pron\", \"pron\", \"pron\", \"pron\", \"pron\", \"pron\", \"pron\", \"property\", \"property\", \"prose\", \"prose\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"punctuation\", \"purpose\", \"purpose\", \"purpose\", \"purpose\", \"pursue\", \"pursue\", \"quality\", \"quality\", \"quality\", \"quality\", \"quantity\", \"quarterly\", \"rather\", \"rather\", \"rather\", \"rather\", \"rdb\", \"record\", \"record\", \"record\", \"record\", \"recreate\", \"redundancy\", \"refine\", \"refine\", \"refocus\", \"refrain\", \"registration\", \"regular_expression\", \"regularize\", \"relational_database\", \"rely\", \"rend\", \"rend\", \"render\", \"render\", \"render\", \"rendition\", \"rendition\", \"rendition\", \"rendition\", \"reorganize\", \"report\", \"report\", \"report\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"reshape\", \"resource\", \"resource\", \"resource\", \"resource\", \"retrace\", \"revise\", \"revision\", \"revision\", \"rhyme\", \"rigorous\", \"rigorous\", \"roeder\", \"sale\", \"satlow\", \"school\", \"scientific\", \"scientific\", \"search\", \"search\", \"search\", \"search\", \"searchable\", \"sequence\", \"sequence\", \"server\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"short\", \"short\", \"shortcut\", \"siege\", \"sign\", \"site\", \"site\", \"situation\", \"situation\", \"society\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"sound\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage_direction\", \"standardize\", \"standardize\", \"standardize\", \"standardized\", \"standardized\", \"static\", \"static\", \"statistic\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"storage\", \"store\", \"store\", \"store\", \"store\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"struggle\", \"subversion\", \"suggestion\", \"suggestion\", \"suggestion\", \"syntax\", \"system\", \"system\", \"system\", \"system\", \"table\", \"tag\", \"tag\", \"tag\", \"tag\", \"teach\", \"teach\", \"teaching\", \"technology\", \"technology\", \"technology\", \"technology\", \"teidata\", \"template\", \"template\", \"template\", \"terminology\", \"terminology\", \"terminology\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"textual\", \"textual\", \"textual\", \"textual\", \"textual\", \"textual\", \"textual\", \"theatrical\", \"theatrical_performance\", \"theory\", \"theory\", \"time\", \"time\", \"time\", \"time\", \"title\", \"title\", \"token\", \"token\", \"token\", \"tokenize\", \"tokenized\", \"tool\", \"tool\", \"tool\", \"tool\", \"torsten\", \"total\", \"training\", \"training\", \"type\", \"type\", \"type\", \"type\", \"type\", \"typeset\", \"typically\", \"typology\", \"typology\", \"typology\", \"unary\", \"uncertainty\", \"uncertainty\", \"underline\", \"underlined\", \"understand\", \"understand\", \"understand\", \"uri\", \"usable\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"utilise\", \"utilise\", \"variance\", \"variation\", \"variation\", \"vector\", \"view\", \"view\", \"void\", \"watermark\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"web\", \"web\", \"web\", \"web\", \"web\", \"weight\", \"wholesale\", \"wish\", \"wish\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workshop\", \"workshop\", \"workshop\", \"workshop\", \"would\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xsl\", \"yield\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 2, 6, 1, 3, 8, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el52031397388011789285310301274\", ldavis_el52031397388011789285310301274_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el52031397388011789285310301274\", ldavis_el52031397388011789285310301274_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el52031397388011789285310301274\", ldavis_el52031397388011789285310301274_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "6      0.009015 -0.020445       1        1  45.105026\n",
       "1      0.132847 -0.021374       2        1  19.371544\n",
       "5      0.104030  0.029331       3        1  14.730029\n",
       "0     -0.007415 -0.040543       4        1   6.431472\n",
       "2     -0.075105 -0.119467       5        1   5.670429\n",
       "7     -0.043540  0.038397       6        1   3.951199\n",
       "3     -0.052595  0.094778       7        1   3.502458\n",
       "4     -0.067237  0.039323       8        1   1.237845, topic_info=                Term        Freq       Total Category  logprob  loglift\n",
       "146             text  267.000000  267.000000  Default  30.0000  30.0000\n",
       "48             paper   72.000000   72.000000  Default  29.0000  29.0000\n",
       "28            encode  121.000000  121.000000  Default  28.0000  28.0000\n",
       "27           element   78.000000   78.000000  Default  27.0000  27.0000\n",
       "94             datum   81.000000   81.000000  Default  26.0000  26.0000\n",
       "...              ...         ...         ...      ...      ...      ...\n",
       "51              pron    0.399472  195.504272   Topic8  -5.9922  -1.8014\n",
       "1981  implementation    0.379527    3.641298   Topic8  -6.0434   2.1306\n",
       "161             also    0.386003   72.531311   Topic8  -6.0265  -0.8441\n",
       "131          process    0.385186   62.978249   Topic8  -6.0286  -0.7050\n",
       "43              make    0.381681   53.965168   Topic8  -6.0377  -0.5597\n",
       "\n",
       "[549 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "76        1  0.322576   ability\n",
       "76        4  0.645153   ability\n",
       "77        4  0.929857  academic\n",
       "229       1  0.394673    access\n",
       "229       2  0.024667    access\n",
       "...     ...       ...       ...\n",
       "155       4  0.076066       xml\n",
       "155       5  0.038033       xml\n",
       "155       6  0.038033       xml\n",
       "2383      8  0.730517       xsl\n",
       "1557      2  0.520077     yield\n",
       "\n",
       "[1035 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[7, 2, 6, 1, 3, 8, 4, 5])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Mallet Model ##\n",
    "\n",
    "### Passage de l'algorithme de Gensim à celui de Mallet ###\n",
    "\n",
    "Pour la suite, nous utiliserons l'algorithme de topic modeling de Mallet plutôt que celui proposé par Gensim. Bien que Gensim offre une meilleure approche de Topic Modeling, car chaque étape est bien séparée et peut être personnalisée (nettoyage de la donnée ou *preprocessing*, construction et paramètrage du modèle de Topic Modeling), l'algorithme de Topic Modeling proposé par Mallet est un peu plus précis que celui de Gensim, en offrant notamment une meilleure qualité de sujets.\n",
    "\n",
    "En 2014 Radim Řehůřek, créateur de Gensim, a créé un Wrapper permettant d'utiliser l'algorithme de Mallet. Nous allons donc télécharger les dossiers de Mallet depuis GitHub et utiliser ce wrapper pour utiliser l'algorithme de Mallet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les Topics mesurés seront légèrement différents. Tout d'abord, il faut télécharger Mallet dans le cache :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./cache2019/Mallet'):\n",
    "    git.Git(\"./cache2019\").clone(\"https://github.com/mimno/Mallet.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Important___ : Il faut maintenant utiliser le terminal pour aller dans ./cache2019/Mallet et taper simplement la commande \" ant \" (rendu possible suite à votre installation de Ant Apache comme indiqué dans le README). Cela permet de compiler le script Java de Mallet. Si le terminal affiche \"Building Successfully\", vous pouvez passer à l'étape suivante, c'est à dire implémenter l'algorithme de LDA Mallet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = \"./cache2019/Mallet/bin/mallet\"\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=8, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('paper', 0.06651198762567673),\n",
      "   ('type', 0.04021655065738593),\n",
      "   ('pron', 0.03557617942768755),\n",
      "   ('description', 0.0317092034029389),\n",
      "   ('structure', 0.027842227378190254),\n",
      "   ('record', 0.027068832173240527),\n",
      "   ('information', 0.02320185614849188),\n",
      "   ('project', 0.020108275328692964),\n",
      "   ('user', 0.017014694508894045),\n",
      "   ('feature', 0.016241299303944315)]),\n",
      " (1,\n",
      "  [('encode', 0.03660049627791563),\n",
      "   ('line', 0.03225806451612903),\n",
      "   ('pron', 0.021712158808933003),\n",
      "   ('poem', 0.021712158808933003),\n",
      "   ('rhyme', 0.02109181141439206),\n",
      "   ('tag', 0.020471464019851116),\n",
      "   ('time', 0.018610421836228287),\n",
      "   ('project', 0.017990074441687345),\n",
      "   ('form', 0.01488833746898263),\n",
      "   ('long', 0.01488833746898263)]),\n",
      " (2,\n",
      "  [('textual', 0.04184457728437233),\n",
      "   ('digital', 0.037574722459436376),\n",
      "   ('work', 0.036720751494449186),\n",
      "   ('document', 0.02305721605465414),\n",
      "   ('event', 0.017079419299743808),\n",
      "   ('history', 0.014517506404782237),\n",
      "   ('bibliographic', 0.014517506404782237),\n",
      "   ('markup', 0.014517506404782237),\n",
      "   ('author', 0.014517506404782237),\n",
      "   ('specific', 0.012809564474807857)]),\n",
      " (3,\n",
      "  [('access', 0.038616251005631534),\n",
      "   ('guideline', 0.03378921962992759),\n",
      "   ('editor', 0.029766693483507644),\n",
      "   ('develop', 0.02172164119066774),\n",
      "   ('letter', 0.01850362027353178),\n",
      "   ('reference', 0.017699115044247787),\n",
      "   ('web', 0.016894609814963796),\n",
      "   ('apply', 0.016090104585679808),\n",
      "   ('online', 0.015285599356395816),\n",
      "   ('edition', 0.014481094127111826)]),\n",
      " (4,\n",
      "  [('encode', 0.07002561912894961),\n",
      "   ('format', 0.04184457728437233),\n",
      "   ('include', 0.030742954739538857),\n",
      "   ('write', 0.02305721605465414),\n",
      "   ('case', 0.017079419299743808),\n",
      "   ('focus', 0.016225448334756618),\n",
      "   ('open', 0.015371477369769428),\n",
      "   ('research', 0.014517506404782237),\n",
      "   ('solution', 0.012809564474807857),\n",
      "   ('publish', 0.012809564474807857)]),\n",
      " (5,\n",
      "  [('text', 0.15527065527065528),\n",
      "   ('model', 0.03561253561253561),\n",
      "   ('represent', 0.02207977207977208),\n",
      "   ('edition', 0.020655270655270654),\n",
      "   ('ontology', 0.017806267806267807),\n",
      "   ('base', 0.017806267806267807),\n",
      "   ('annotation', 0.01638176638176638),\n",
      "   ('datum', 0.014957264957264958),\n",
      "   ('scholarly', 0.014245014245014245),\n",
      "   ('specific', 0.013532763532763533)]),\n",
      " (6,\n",
      "  [('element', 0.048465266558966075),\n",
      "   ('pron', 0.048465266558966075),\n",
      "   ('text', 0.03607969843834141),\n",
      "   ('level', 0.024771136241249325),\n",
      "   ('provide', 0.01830910070005385),\n",
      "   ('source', 0.017770597738287562),\n",
      "   ('odd', 0.01669359181475498),\n",
      "   ('number', 0.014539579967689823),\n",
      "   ('word', 0.011847065158858373),\n",
      "   ('language', 0.011847065158858373)]),\n",
      " (7,\n",
      "  [('process', 0.0414985590778098),\n",
      "   ('datum', 0.029971181556195964),\n",
      "   ('file', 0.02881844380403458),\n",
      "   ('pron', 0.02881844380403458),\n",
      "   ('build', 0.027089337175792507),\n",
      "   ('create', 0.025936599423631124),\n",
      "   ('project', 0.025360230547550433),\n",
      "   ('require', 0.019020172910662825),\n",
      "   ('xml', 0.01729106628242075),\n",
      "   ('document', 0.014985590778097982)])]\n"
     ]
    }
   ],
   "source": [
    "# Voici les \"nouveaux\" topics calculés par Mallet\n",
    "pprint(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons comparer le score de cohérence de ces algorithmes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score of LDA Mallet :  0.37226168312101227\n",
      "\n",
      "Coherence Score of LDA Gensim :  0.2822983625251866\n"
     ]
    }
   ],
   "source": [
    "# Je calcule le score de cohérence de Mallet\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score of LDA Mallet : ', coherence_ldamallet)\n",
    "\n",
    "# Je calcule le score de Gensim\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score of LDA Gensim : ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, Mallet est légèrement meilleur que Gensim. Il y a donc un certain intérêt à continuer avec Mallet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critique du choix du nombre de clusters ###\n",
    "\n",
    "Nous allons ici voir si le nombre de clusters choisi est vraiment représentatif et optimal. Pour calculer cela, nous nous baserons sur la \" cohérence \", un coefficient calculé par l'ordinateur. Tout d'abord, nous créons une fonction permettant de calculer la cohérence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Calcule la cohérence c_v pour un nombre variable de topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Dictionnaire de Gensim\n",
    "    corpus : Corpus de Gensim\n",
    "    texts : Liste des corpus\n",
    "    limit : Nombre maximum de corpus\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : Liste des modèles de topic LDA topic\n",
    "    coherence_values : Valeur de la cohérence correspondance au model de LDA et son nombre de topics respectif\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis nous cherchons à voir si cela est vraiment cohérent. Nous appliquons cette fonction au corpus. La fonction lancée ci-dessous va attribuer à chaque \"model_list\", une élément propre à Gensim regroupant la liste des topics attribués à un corpus (élément copié sur celui de Mallet mais avec cet avantage de ne pas stocker dans la RAM les textes, allégeant grandement le processus) la variable \"coherence_values\" qui est une liste constituée de nombres décimaux représentant la cohérence de chaque topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peut prendre du temps\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis nous affichons le résultat sous la forme d'un graphique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Nombre de Topics\")\n",
    "plt.ylabel(\"Score de cohérence\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons qu'il y a un pic à 8 topics, un autre à 20, puis à partir de 32 topics le score de cohérence monte en flèche. Le pic à 8 topics est intéressant, car c'est le nombre de \" topics \" différents proposés lors de la Conférence TEI 2019. L'augmentation finale permet cependant de comprendre que les abstracts restent relativement peu liés les uns aux autres, et que le nombre optimal de topics pour l'ordinateur serait d'un topic par abstract..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous affichons ici ensuite le score de cohérence précis pour une suite de nombre de topics, pour avoir une vision plus précise : par exemple, il est légèrement mieux d'avoir 8 topics que 20 topics, ce qui conforte l'idée que les abstracts sont guidés par 8 sujets différents, ceux attribués par les organisateurs de la conférence TEI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de Topics = 2  a une valeur de cohérence de :  0.297\n",
      "Nombre de Topics = 8  a une valeur de cohérence de :  0.3593\n",
      "Nombre de Topics = 14  a une valeur de cohérence de :  0.3445\n",
      "Nombre de Topics = 20  a une valeur de cohérence de :  0.343\n",
      "Nombre de Topics = 26  a une valeur de cohérence de :  0.365\n",
      "Nombre de Topics = 32  a une valeur de cohérence de :  0.3711\n",
      "Nombre de Topics = 38  a une valeur de cohérence de :  0.3999\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Nombre de Topics =\", m, \" a une valeur de cohérence de : \", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voir les topics ###\n",
    "\n",
    "La cellule ci-dessous permet d'afficher pour chaque topic (représenté par un nombre entier) les 10 mots-clés représentant le mieux ce topic, et un facteur attribué à chacun de ces mots permettant de voir l'importance de chaque mot-clé au sein du cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.044*\"line\" + 0.035*\"type\" + 0.028*\"element\" + 0.024*\"feature\" + '\n",
      "  '0.021*\"number\" + 0.020*\"word\" + 0.019*\"order\" + 0.018*\"write\" + '\n",
      "  '0.018*\"attribute\" + 0.016*\"follow\"'),\n",
      " (1,\n",
      "  '0.067*\"encode\" + 0.039*\"textual\" + 0.024*\"research\" + 0.023*\"develop\" + '\n",
      "  '0.019*\"letter\" + 0.017*\"digital\" + 0.015*\"guideline\" + 0.015*\"online\" + '\n",
      "  '0.014*\"humanity\" + 0.014*\"present\"'),\n",
      " (2,\n",
      "  '0.074*\"paper\" + 0.034*\"description\" + 0.031*\"information\" + 0.031*\"editor\" '\n",
      "  '+ 0.030*\"record\" + 0.020*\"document\" + 0.019*\"pron\" + 0.018*\"project\" + '\n",
      "  '0.016*\"historical\" + 0.015*\"user\"'),\n",
      " (3,\n",
      "  '0.045*\"pron\" + 0.038*\"encode\" + 0.031*\"work\" + 0.028*\"time\" + 0.023*\"poem\" '\n",
      "  '+ 0.022*\"rhyme\" + 0.021*\"tag\" + 0.019*\"encoder\" + 0.018*\"long\" + '\n",
      "  '0.017*\"form\"'),\n",
      " (4,\n",
      "  '0.046*\"text\" + 0.033*\"pron\" + 0.029*\"element\" + 0.024*\"level\" + '\n",
      "  '0.020*\"source\" + 0.019*\"odd\" + 0.017*\"language\" + 0.016*\"work\" + '\n",
      "  '0.015*\"provide\" + 0.012*\"event\"'),\n",
      " (5,\n",
      "  '0.143*\"text\" + 0.039*\"model\" + 0.031*\"edition\" + 0.019*\"structure\" + '\n",
      "  '0.018*\"represent\" + 0.016*\"base\" + 0.016*\"ontology\" + 0.015*\"annotation\" + '\n",
      "  '0.013*\"scholarly\" + 0.012*\"representation\"'),\n",
      " (6,\n",
      "  '0.058*\"datum\" + 0.039*\"project\" + 0.036*\"file\" + 0.034*\"format\" + '\n",
      "  '0.028*\"access\" + 0.019*\"database\" + 0.019*\"document\" + 0.018*\"system\" + '\n",
      "  '0.015*\"index\" + 0.014*\"principle\"'),\n",
      " (7,\n",
      "  '0.054*\"pron\" + 0.036*\"process\" + 0.035*\"build\" + 0.029*\"create\" + '\n",
      "  '0.017*\"guideline\" + 0.016*\"project\" + 0.016*\"include\" + 0.016*\"page\" + '\n",
      "  '0.015*\"entity\" + 0.015*\"rendition\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = model_list[1] #optimal_model et model_list sont des éléments gensim contenant les topics et les textes. \n",
    "#Model_list est la liste des modèles de nombres de topics et la distribution interne donnée ci-dessus. Comme le modèle le plus efficace est\n",
    "#celui à 8 topics, je le sélectionne\n",
    "model_topics = optimal_model.show_topics(formatted=False) #Model_topics est une liste produite par la méthode show_topics.\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation ###\n",
    "\n",
    "Nous allons produire sous la forme d'un tableau le sujet dominant de chaque texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document n°</th>\n",
       "      <th>Topic dominant n°</th>\n",
       "      <th>Pourcentage de Contribution au topic</th>\n",
       "      <th>Mots-clés</th>\n",
       "      <th>Texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>use machine learn for the Automated Classifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>TEI XML and Delta Format Interchangeability TE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>correspsearch v2 – new way of explore correspo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4224</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>get along with Relational Databases Background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>introduce objectification : when be an &lt; objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>analyze and Visualizing Uncertain Knowledge : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>reference an editorial ontology from the TEI :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>case Study TEI Customization : a restrict TEI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>in search of comity : TEI for distant read Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>reconceive TEI model of theatrical performance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>model FRBR entity and -PRON- Relationships wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>scale up automatic Structuring of Manuscript S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>recreate history through event recreate histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>highlight -PRON- example : encode xml example ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>grow collection of TEI text : some lesson from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6228</td>\n",
       "      <td>pron, encode, work, time, poem, rhyme, tag, en...</td>\n",
       "      <td>how -PRON- triple -PRON- encode speed in the  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6396</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>a TEI customization for the description of pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>reference annotation as a core concept of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3679</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>make linkable Data from Account Books : Bookke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>the Prefabricated website : who need a server ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4520</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>refine the Current Teaching Methodology of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>explore TEI structure to find distinctive feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5653</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>advantage and challenge of tokenized TEI Advan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>Manuscripta - the editor from past to future M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>native - TEI dialectal dictionary for bavarian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>archive a TEI project fairly archive a TEI pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>an encode strategic proposal of \" Ruby \" text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>TEI encoding of correspondence : a community e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2049</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>an Attempt of Dissemination of TEI in a TEI - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2342</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>encode history in TEI : a corpus - orient appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>text Graph Ontology . a Semantic Web approach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4319</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>Genesis and Variance : from Letter to Literatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>five century of history in a network how shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2089</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>a sign of the time : medieval punctuation , -P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2561</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>reflect the influence of Technology on model o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>validate @selector : a regular expression adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>use Microsoft Word for prepare XML TEI - compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>inscription , Hieroglyphs , Linguistics … and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2887</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>create high - quality print from TEI document ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4747</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>what be a line ? encode and counting Lines in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>towards large corpus of Indic text : for now ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2864</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>use Github and -PRON- integration to create , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5529</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>introduce an open , dynamic and Efficient Lexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2835</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>Parla - CLARIN : TEI guideline for corpus of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>challenge in encode parliamentary datum : betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>a realistic theory of textuality and -PRON- co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document n°  Topic dominant n°  Pourcentage de Contribution au topic  \\\n",
       "0             0                0.0                                0.2502   \n",
       "1             1                6.0                                0.2149   \n",
       "2             2                1.0                                0.3005   \n",
       "3             3                6.0                                0.4224   \n",
       "4             4                0.0                                0.2026   \n",
       "5             5                6.0                                0.2267   \n",
       "6             6                0.0                                0.3071   \n",
       "7             7                6.0                                0.1724   \n",
       "8             8                4.0                                0.4916   \n",
       "9             9                5.0                                0.4066   \n",
       "10           10                2.0                                0.2740   \n",
       "11           11                1.0                                0.1473   \n",
       "12           12                4.0                                0.2877   \n",
       "13           13                0.0                                0.2065   \n",
       "14           14                4.0                                0.2458   \n",
       "15           15                3.0                                0.6228   \n",
       "16           16                2.0                                0.6396   \n",
       "17           17                1.0                                0.2492   \n",
       "18           18                2.0                                0.3679   \n",
       "19           19                7.0                                0.5100   \n",
       "20           20                7.0                                0.4520   \n",
       "21           21                0.0                                0.2883   \n",
       "22           22                0.0                                0.5653   \n",
       "23           23                2.0                                0.2807   \n",
       "24           24                2.0                                0.2186   \n",
       "25           25                6.0                                0.5222   \n",
       "26           26                0.0                                0.4081   \n",
       "27           27                1.0                                0.4044   \n",
       "28           28                7.0                                0.2049   \n",
       "29           29                1.0                                0.2342   \n",
       "30           30                5.0                                0.6338   \n",
       "31           31                1.0                                0.4319   \n",
       "32           32                1.0                                0.2114   \n",
       "33           33                5.0                                0.2089   \n",
       "34           34                5.0                                0.2561   \n",
       "35           35                0.0                                0.3035   \n",
       "36           36                5.0                                0.2110   \n",
       "37           37                5.0                                0.3423   \n",
       "38           38                5.0                                0.2887   \n",
       "39           39                0.0                                0.4747   \n",
       "40           40                4.0                                0.1854   \n",
       "41           41                7.0                                0.2864   \n",
       "42           42                6.0                                0.5529   \n",
       "43           43                1.0                                0.2835   \n",
       "44           44                1.0                                0.4046   \n",
       "45           45                1.0                                0.3581   \n",
       "\n",
       "                                            Mots-clés  \\\n",
       "0   line, type, element, feature, number, word, or...   \n",
       "1   datum, project, file, format, access, database...   \n",
       "2   encode, textual, research, develop, letter, di...   \n",
       "3   datum, project, file, format, access, database...   \n",
       "4   line, type, element, feature, number, word, or...   \n",
       "5   datum, project, file, format, access, database...   \n",
       "6   line, type, element, feature, number, word, or...   \n",
       "7   datum, project, file, format, access, database...   \n",
       "8   text, pron, element, level, source, odd, langu...   \n",
       "9   text, model, edition, structure, represent, ba...   \n",
       "10  paper, description, information, editor, recor...   \n",
       "11  encode, textual, research, develop, letter, di...   \n",
       "12  text, pron, element, level, source, odd, langu...   \n",
       "13  line, type, element, feature, number, word, or...   \n",
       "14  text, pron, element, level, source, odd, langu...   \n",
       "15  pron, encode, work, time, poem, rhyme, tag, en...   \n",
       "16  paper, description, information, editor, recor...   \n",
       "17  encode, textual, research, develop, letter, di...   \n",
       "18  paper, description, information, editor, recor...   \n",
       "19  pron, process, build, create, guideline, proje...   \n",
       "20  pron, process, build, create, guideline, proje...   \n",
       "21  line, type, element, feature, number, word, or...   \n",
       "22  line, type, element, feature, number, word, or...   \n",
       "23  paper, description, information, editor, recor...   \n",
       "24  paper, description, information, editor, recor...   \n",
       "25  datum, project, file, format, access, database...   \n",
       "26  line, type, element, feature, number, word, or...   \n",
       "27  encode, textual, research, develop, letter, di...   \n",
       "28  pron, process, build, create, guideline, proje...   \n",
       "29  encode, textual, research, develop, letter, di...   \n",
       "30  text, model, edition, structure, represent, ba...   \n",
       "31  encode, textual, research, develop, letter, di...   \n",
       "32  encode, textual, research, develop, letter, di...   \n",
       "33  text, model, edition, structure, represent, ba...   \n",
       "34  text, model, edition, structure, represent, ba...   \n",
       "35  line, type, element, feature, number, word, or...   \n",
       "36  text, model, edition, structure, represent, ba...   \n",
       "37  text, model, edition, structure, represent, ba...   \n",
       "38  text, model, edition, structure, represent, ba...   \n",
       "39  line, type, element, feature, number, word, or...   \n",
       "40  text, pron, element, level, source, odd, langu...   \n",
       "41  pron, process, build, create, guideline, proje...   \n",
       "42  datum, project, file, format, access, database...   \n",
       "43  encode, textual, research, develop, letter, di...   \n",
       "44  encode, textual, research, develop, letter, di...   \n",
       "45  encode, textual, research, develop, letter, di...   \n",
       "\n",
       "                                                Texte  \n",
       "0   use machine learn for the Automated Classifica...  \n",
       "1   TEI XML and Delta Format Interchangeability TE...  \n",
       "2   correspsearch v2 – new way of explore correspo...  \n",
       "3   get along with Relational Databases Background...  \n",
       "4   introduce objectification : when be an < objec...  \n",
       "5   analyze and Visualizing Uncertain Knowledge : ...  \n",
       "6   reference an editorial ontology from the TEI :...  \n",
       "7   case Study TEI Customization : a restrict TEI ...  \n",
       "8   in search of comity : TEI for distant read Int...  \n",
       "9   reconceive TEI model of theatrical performance...  \n",
       "10  model FRBR entity and -PRON- Relationships wit...  \n",
       "11  scale up automatic Structuring of Manuscript S...  \n",
       "12  recreate history through event recreate histor...  \n",
       "13  highlight -PRON- example : encode xml example ...  \n",
       "14  grow collection of TEI text : some lesson from...  \n",
       "15  how -PRON- triple -PRON- encode speed in the  ...  \n",
       "16  a TEI customization for the description of pap...  \n",
       "17  reference annotation as a core concept of the ...  \n",
       "18  make linkable Data from Account Books : Bookke...  \n",
       "19  the Prefabricated website : who need a server ...  \n",
       "20  refine the Current Teaching Methodology of the...  \n",
       "21  explore TEI structure to find distinctive feat...  \n",
       "22  advantage and challenge of tokenized TEI Advan...  \n",
       "23  Manuscripta - the editor from past to future M...  \n",
       "24  native - TEI dialectal dictionary for bavarian...  \n",
       "25  archive a TEI project fairly archive a TEI pro...  \n",
       "26  an encode strategic proposal of \" Ruby \" text ...  \n",
       "27  TEI encoding of correspondence : a community e...  \n",
       "28  an Attempt of Dissemination of TEI in a TEI - ...  \n",
       "29  encode history in TEI : a corpus - orient appr...  \n",
       "30  text Graph Ontology . a Semantic Web approach ...  \n",
       "31  Genesis and Variance : from Letter to Literatu...  \n",
       "32  five century of history in a network how shoul...  \n",
       "33  a sign of the time : medieval punctuation , -P...  \n",
       "34  reflect the influence of Technology on model o...  \n",
       "35  validate @selector : a regular expression adve...  \n",
       "36  use Microsoft Word for prepare XML TEI - compl...  \n",
       "37  inscription , Hieroglyphs , Linguistics … and ...  \n",
       "38  create high - quality print from TEI document ...  \n",
       "39  what be a line ? encode and counting Lines in ...  \n",
       "40  towards large corpus of Indic text : for now ,...  \n",
       "41  use Github and -PRON- integration to create , ...  \n",
       "42  introduce an open , dynamic and Efficient Lexi...  \n",
       "43  Parla - CLARIN : TEI guideline for corpus of p...  \n",
       "44  challenge in encode parliamentary datum : betw...  \n",
       "45  a realistic theory of textuality and -PRON- co...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=documents):\n",
    "    # Iniatilise la sortie en un tableau pandas\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Récupère le sujet principal de chaque document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        #Récupère pour chaque document le sujet dominant, le pourcentage de contribution à ce sujet et les mots-clés\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Ajout du titre dans la dernière colonne en prenant les premiers mots de chaque texte\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=documents)\n",
    "\n",
    "# Mise en place du tableau\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document n°', 'Topic dominant n°', 'Pourcentage de Contribution au topic', 'Mots-clés', 'Texte']\n",
    "\n",
    "# Affiche le tableau en présentant seulement les 10 premiers textes. Changez le chiffre 10 si vous le souhaitez pour obtenir l'étude de plus de textes.\n",
    "df_dominant_topic.head(46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons remarquer que le modèle représenté fonctionnerait autour d'un texte central souvent très représentatif (le texte 42 pour le topic 6 représentatif à 55%, le texte 30 pour le topic 5 représentatif à 63%, le texte 16 pour le topic 2 représentatif à 63%,...) et de textes gravitant autour et représentatif à hauteur de 20% à 30% en moyenne (le texte 36 est représentatif à 21% du topic 5, le texte 38 est représentatif à 28% du topic 5, le texte 37 est représentatif à 34% du topic 5 par exemple).\n",
    "\n",
    "La cohérence thématique entre tous ces abstracts n'est donc pas très profonde, et bien souvent il semblerait que la thématique d'un groupe d'abstract ne représenterait réellement qu'un seul abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chercher les abstracts les plus représentatifs ###\n",
    "\n",
    "Nous pouvons alors chercher à sortir les abstracts les plus représentatifs de chaque topic :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic n°</th>\n",
       "      <th>Pourcentage de contribution à un topic</th>\n",
       "      <th>Mots-Clés</th>\n",
       "      <th>Texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5653</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>advantage and challenge of tokenized TEI Advan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4319</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>Genesis and Variance : from Letter to Literatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6396</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>a TEI customization for the description of pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6228</td>\n",
       "      <td>pron, encode, work, time, poem, rhyme, tag, en...</td>\n",
       "      <td>how -PRON- triple -PRON- encode speed in the  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>in search of comity : TEI for distant read Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>text Graph Ontology . a Semantic Web approach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5529</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>introduce an open , dynamic and Efficient Lexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>the Prefabricated website : who need a server ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic n°  Pourcentage de contribution à un topic  \\\n",
       "0       0.0                                  0.5653   \n",
       "1       1.0                                  0.4319   \n",
       "2       2.0                                  0.6396   \n",
       "3       3.0                                  0.6228   \n",
       "4       4.0                                  0.4916   \n",
       "5       5.0                                  0.6338   \n",
       "6       6.0                                  0.5529   \n",
       "7       7.0                                  0.5100   \n",
       "\n",
       "                                           Mots-Clés  \\\n",
       "0  line, type, element, feature, number, word, or...   \n",
       "1  encode, textual, research, develop, letter, di...   \n",
       "2  paper, description, information, editor, recor...   \n",
       "3  pron, encode, work, time, poem, rhyme, tag, en...   \n",
       "4  text, pron, element, level, source, odd, langu...   \n",
       "5  text, model, edition, structure, represent, ba...   \n",
       "6  datum, project, file, format, access, database...   \n",
       "7  pron, process, build, create, guideline, proje...   \n",
       "\n",
       "                                               Texte  \n",
       "0  advantage and challenge of tokenized TEI Advan...  \n",
       "1  Genesis and Variance : from Letter to Literatu...  \n",
       "2  a TEI customization for the description of pap...  \n",
       "3  how -PRON- triple -PRON- encode speed in the  ...  \n",
       "4  in search of comity : TEI for distant read Int...  \n",
       "5  text Graph Ontology . a Semantic Web approach ...  \n",
       "6  introduce an open , dynamic and Efficient Lexi...  \n",
       "7  the Prefabricated website : who need a server ...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic n°', \"Pourcentage de contribution à un topic\", \"Mots-Clés\", \"Texte\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La théorie formulée précédemment semble se vérifier : certains abstracts incarnent à eux seuls leur topic.\n",
    "\n",
    "Cependant, les résultats que nous venons de voir montrent aussi que les topics restent représentatifs et cohérents : globalement chaque abstract fait participe à son Topic à hauteur d'au moins 20%, et aucun abstract ne dépasse les 70% de participation au topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Des topics égaux ? ###\n",
    "\n",
    "Nous allons maintenant regarder le nombre de documents par topic.\n",
    "\n",
    "Nous pouvons conclure qu'en regardant la faible proportion des documents représentés dans les topics, les abstracts restent quand même bien différents les uns des autres, une grande diversité prédomine en réalité dans ces abstracts, bien qu'une trame de fonds les relient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N° du topic</th>\n",
       "      <th>Mots-clés du topic</th>\n",
       "      <th>Nombre de documents relevant de ce topic</th>\n",
       "      <th>Proportion des documents parfaitement représentatifs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>pron, encode, work, time, poem, rhyme, tag, en...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>paper, description, information, editor, recor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>text, model, edition, structure, represent, ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>line, type, element, feature, number, word, or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>text, pron, element, level, source, odd, langu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>pron, process, build, create, guideline, proje...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>datum, project, file, format, access, database...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>encode, textual, research, develop, letter, di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      N° du topic                                 Mots-clés du topic  \\\n",
       "0.0           0.0  line, type, element, feature, number, word, or...   \n",
       "1.0           6.0  datum, project, file, format, access, database...   \n",
       "2.0           1.0  encode, textual, research, develop, letter, di...   \n",
       "3.0           6.0  datum, project, file, format, access, database...   \n",
       "4.0           0.0  line, type, element, feature, number, word, or...   \n",
       "5.0           6.0  datum, project, file, format, access, database...   \n",
       "6.0           0.0  line, type, element, feature, number, word, or...   \n",
       "7.0           6.0  datum, project, file, format, access, database...   \n",
       "8.0           4.0  text, pron, element, level, source, odd, langu...   \n",
       "9.0           5.0  text, model, edition, structure, represent, ba...   \n",
       "10.0          2.0  paper, description, information, editor, recor...   \n",
       "11.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "12.0          4.0  text, pron, element, level, source, odd, langu...   \n",
       "13.0          0.0  line, type, element, feature, number, word, or...   \n",
       "14.0          4.0  text, pron, element, level, source, odd, langu...   \n",
       "15.0          3.0  pron, encode, work, time, poem, rhyme, tag, en...   \n",
       "16.0          2.0  paper, description, information, editor, recor...   \n",
       "17.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "18.0          2.0  paper, description, information, editor, recor...   \n",
       "19.0          7.0  pron, process, build, create, guideline, proje...   \n",
       "20.0          7.0  pron, process, build, create, guideline, proje...   \n",
       "21.0          0.0  line, type, element, feature, number, word, or...   \n",
       "22.0          0.0  line, type, element, feature, number, word, or...   \n",
       "23.0          2.0  paper, description, information, editor, recor...   \n",
       "24.0          2.0  paper, description, information, editor, recor...   \n",
       "25.0          6.0  datum, project, file, format, access, database...   \n",
       "26.0          0.0  line, type, element, feature, number, word, or...   \n",
       "27.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "28.0          7.0  pron, process, build, create, guideline, proje...   \n",
       "29.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "30.0          5.0  text, model, edition, structure, represent, ba...   \n",
       "31.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "32.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "33.0          5.0  text, model, edition, structure, represent, ba...   \n",
       "34.0          5.0  text, model, edition, structure, represent, ba...   \n",
       "35.0          0.0  line, type, element, feature, number, word, or...   \n",
       "36.0          5.0  text, model, edition, structure, represent, ba...   \n",
       "37.0          5.0  text, model, edition, structure, represent, ba...   \n",
       "38.0          5.0  text, model, edition, structure, represent, ba...   \n",
       "39.0          0.0  line, type, element, feature, number, word, or...   \n",
       "40.0          4.0  text, pron, element, level, source, odd, langu...   \n",
       "41.0          7.0  pron, process, build, create, guideline, proje...   \n",
       "42.0          6.0  datum, project, file, format, access, database...   \n",
       "43.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "44.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "45.0          1.0  encode, textual, research, develop, letter, di...   \n",
       "\n",
       "      Nombre de documents relevant de ce topic  \\\n",
       "0.0                                        9.0   \n",
       "1.0                                       10.0   \n",
       "2.0                                        5.0   \n",
       "3.0                                        1.0   \n",
       "4.0                                        4.0   \n",
       "5.0                                        7.0   \n",
       "6.0                                        6.0   \n",
       "7.0                                        4.0   \n",
       "8.0                                        NaN   \n",
       "9.0                                        NaN   \n",
       "10.0                                       NaN   \n",
       "11.0                                       NaN   \n",
       "12.0                                       NaN   \n",
       "13.0                                       NaN   \n",
       "14.0                                       NaN   \n",
       "15.0                                       NaN   \n",
       "16.0                                       NaN   \n",
       "17.0                                       NaN   \n",
       "18.0                                       NaN   \n",
       "19.0                                       NaN   \n",
       "20.0                                       NaN   \n",
       "21.0                                       NaN   \n",
       "22.0                                       NaN   \n",
       "23.0                                       NaN   \n",
       "24.0                                       NaN   \n",
       "25.0                                       NaN   \n",
       "26.0                                       NaN   \n",
       "27.0                                       NaN   \n",
       "28.0                                       NaN   \n",
       "29.0                                       NaN   \n",
       "30.0                                       NaN   \n",
       "31.0                                       NaN   \n",
       "32.0                                       NaN   \n",
       "33.0                                       NaN   \n",
       "34.0                                       NaN   \n",
       "35.0                                       NaN   \n",
       "36.0                                       NaN   \n",
       "37.0                                       NaN   \n",
       "38.0                                       NaN   \n",
       "39.0                                       NaN   \n",
       "40.0                                       NaN   \n",
       "41.0                                       NaN   \n",
       "42.0                                       NaN   \n",
       "43.0                                       NaN   \n",
       "44.0                                       NaN   \n",
       "45.0                                       NaN   \n",
       "\n",
       "      Proportion des documents parfaitement représentatifs  \n",
       "0.0                                              0.1957     \n",
       "1.0                                              0.2174     \n",
       "2.0                                              0.1087     \n",
       "3.0                                              0.0217     \n",
       "4.0                                              0.0870     \n",
       "5.0                                              0.1522     \n",
       "6.0                                              0.1304     \n",
       "7.0                                              0.0870     \n",
       "8.0                                                 NaN     \n",
       "9.0                                                 NaN     \n",
       "10.0                                                NaN     \n",
       "11.0                                                NaN     \n",
       "12.0                                                NaN     \n",
       "13.0                                                NaN     \n",
       "14.0                                                NaN     \n",
       "15.0                                                NaN     \n",
       "16.0                                                NaN     \n",
       "17.0                                                NaN     \n",
       "18.0                                                NaN     \n",
       "19.0                                                NaN     \n",
       "20.0                                                NaN     \n",
       "21.0                                                NaN     \n",
       "22.0                                                NaN     \n",
       "23.0                                                NaN     \n",
       "24.0                                                NaN     \n",
       "25.0                                                NaN     \n",
       "26.0                                                NaN     \n",
       "27.0                                                NaN     \n",
       "28.0                                                NaN     \n",
       "29.0                                                NaN     \n",
       "30.0                                                NaN     \n",
       "31.0                                                NaN     \n",
       "32.0                                                NaN     \n",
       "33.0                                                NaN     \n",
       "34.0                                                NaN     \n",
       "35.0                                                NaN     \n",
       "36.0                                                NaN     \n",
       "37.0                                                NaN     \n",
       "38.0                                                NaN     \n",
       "39.0                                                NaN     \n",
       "40.0                                                NaN     \n",
       "41.0                                                NaN     \n",
       "42.0                                                NaN     \n",
       "43.0                                                NaN     \n",
       "44.0                                                NaN     \n",
       "45.0                                                NaN     "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permet de calculer le nombre de documents par topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Proportion des documents étant parfaitement représentatif du topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# N° du topic et mot-clés\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Lie les colonnes\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Renomme les colonnes\n",
    "df_dominant_topics.columns = ['N° du topic', 'Mots-clés du topic', 'Nombre de documents relevant de ce topic', 'Proportion des documents parfaitement représentatifs']\n",
    "\n",
    "# Représentation\n",
    "df_dominant_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

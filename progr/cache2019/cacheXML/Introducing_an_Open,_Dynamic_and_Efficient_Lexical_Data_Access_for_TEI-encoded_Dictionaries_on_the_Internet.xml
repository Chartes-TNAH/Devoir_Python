<body>
<p>Most of the TEI-encoded dictionaries in public data repositories are not directly
            accessible for computational processing. Their use by different applications depends on
            how each application processes each single dictionary. In the last decades direct
            computational access to data on the Internet has been provided through application
            programming interfaces (APIs). APIs provide a centralized access to data and if designed
            and implemented properly, an efficient access to it. But API development and maintenance
            requires technical expertise, which can be an obstacle for small and medium dictionary
            publishers that might not have in-house solutions for this purpose. Against this
            background we have developed Kosh,<note>
<p>
<ptr target="http://kosh.uni-koeln.de"/>
</p>
</note> an open-source framework, that processes any XML-encoded dictionary and creates
            two APIs for accessing the underlying lexical data: A REST API (<ref target="#fielding" type="bibl">Fielding 2019</ref>) and a GraphQL<note>
<p>
<ptr target="https://graphql.org"/>
</p>
</note> API. The purpose of this presentation is to show how to use Kosh with data
            publicly available on GitHub, in order to demonstrate how the edition of digitized
            dictionaries and the compilation of digital-born dictionaries can be supported with an
            efficient access to the underlying data via APIs.</p>
<p>Kosh is an open-source framework developed to access multiple XML-encoded dictionaries.
            It is generic and flexible, designed to handle dictionaries of different structures and
            size with a minimal configuration effort.</p>
<p>Kosh processes as input data in XML format that is parsed and indexed into an elasticsearch<note>
<p>
<ptr target="https://www.elastic.co"/>
</p>
</note> server. In a JSON (JavaScript Object Notation) configuration file, the
            paths to the elements to be indexed are defined<note>
<p>In XPath 1.0</p>
</note> as also the elasticsearch datatypes of the fields to be
            indexed e.g., keyword or text. Finally, a Kosh data module requires a dot file (.kosh)
            containing the index name, the paths to the XML files to be indexed, and the path to the
            configuration file. With this information, Kosh indexes one or multiple XML files into
            one index that is accessed by two APIs, a GraphQL and a REST API. If the XML source
            files are modified, the index is updated automatically. Kosh can be deployed via Docker<note>
<p>
<ptr target="https://hub.docker.com/r/cceh/kosh"/>
</p>
</note> or natively on Unix systems and a single Kosh instance can provide access
            to multiple dictionaries.</p>
<p>In a GitHub repository, Kosh Data<note>
<p>
<ptr target="https://cceh.github.io/kosh_data"/>
</p>
</note> , there are different datasets that show the structure of a data module
            for Kosh. One of them contains the <emph rend="italic">Diccionario Geográfico-Histórico de
               las Indias Occidentales ó América</emph>, a five-volume dictionary compiled by Antonio
            de Alcedo (De Alcedo <ref target="#de_alcedo_1" type="bibl">1786</ref>, <ref target="#de_alcedo_2" type="bibl">1787</ref>, <ref target="#de_alcedo_3" type="bibl">1788a</ref>,
               <ref target="#de_alcedo_4" type="bibl">1788b</ref>
<ref target="#de_alcedo_5" type="bibl">1789</ref>), which offers a wide description of
            American toponyms and also, on its fifth volume, a vocabulary with a pioneer approach to
            descriptive word usage in the Spanish Americas (<ref target="#lenz" type="bibl">Lenz
               1905–1910:7f</ref>). An XML version of this dictionary has been employed in digital
            gazetteer projects such as HGIS de las Indias<note>
<p>
<ptr target="http://www.hgis-indias.net"/>
</p>
</note> and later in Pelagios Commons<note>
<p>
<ptr target="http://commons.pelagios.org"/>
</p>
</note>
</p>
<p>Based on this XML-encoded version we created a TEI-P5 compliant version. This data can
            be accessed in two ways: First, through Kosh Data,<note>
<p>
<ptr target="https://github.com/cceh/kosh_data/tree/master/de_alcedo"/>
</p>
</note> where modifications to the data can be proposed through pull-requests. Second,
            via APIs<note>
<p>GraphiQL:<ptr target="http://kosh.uni-koeln.de/api/de_alcedo/graphql"/>
</p>
<p>Swagger UI (REST):<ptr target="http://kosh.uni-koeln.de/api/de_alcedo/restful"/>
</p>
</note> provided by a Kosh instance deployed with a clone of this repository.</p>
<p>As data modifications are done at source-file level, and the changes tracked with git<note>
<p>
<ptr target="https://git-scm.com"/>
</p>
</note> , the edition process is open and also reversible. In Kosh the publisher defines
            which fields should be indexed. For the digitization of printed dictionaries this means
            that direct computational access can be provided with a coarse-grained encoding. When
            compiling born-digital dictionaries a few fields can be available at an early
            compilation stage and as the data gains complexity more fields can be added to the
            index. This flexible approach to lexical data access allows to unveil datasets that are
            currently hidden from computer applications and thus users.</p>
</body>